{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle\n",
    "## Competição DSA de Machine Learning - Dezembro 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versão 1.0.0: LB = 0.48866 CV = 0.463102\n",
    "- modelo: LightGBM (com algumas otimizações)\n",
    "- features engineering: gerado através do Auto_ViML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar os principais pacotes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "# Evitar que aparece os warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Seta algumas opções no Jupyter para exibição dos datasets\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# Variavel para controlar o treinamento no Kaggle\n",
    "TRAIN_OFFLINE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa os pacotes de algoritmos\n",
    "import lightgbm as lgb\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "\n",
    "# Importa pacotes do sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, log_loss\n",
    "from sklearn.preprocessing import scale, MinMaxScaler, StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregando os dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    if TRAIN_OFFLINE:\n",
    "        print('Carregando arquivo dataset_treino.csv....')\n",
    "        train = pd.read_csv('../dataset/dataset_treino_modificado.csv')\n",
    "        print('dataset_treino.csv tem {} linhas and {} colunas'.format(train.shape[0], train.shape[1]))\n",
    "        \n",
    "        print('Carregando arquivo dataset_teste.csv....')\n",
    "        test = pd.read_csv('../dataset/dataset_teste_modificado.csv')\n",
    "        print('dataset_teste.csv tem {} linhas and {} colunas'.format(test.shape[0], test.shape[1]))\n",
    "        \n",
    "    else:\n",
    "        print('Carregando arquivo dataset_treino.csv....')\n",
    "        train = pd.read_csv('/kaggle/input/competicao-dsa-machine-learning-dec-2019/dataset_treino.csv')\n",
    "        print('dataset_treino.csv tem {} linhas and {} colunas'.format(train.shape[0], train.shape[1]))\n",
    "        \n",
    "        print('Carregando arquivo dataset_treino.csv....')\n",
    "        test = pd.read_csv('/kaggle/input/competicao-dsa-machine-learning-dec-2019/dataset_teste.csv')\n",
    "        print('dataset_teste.csv tem {} linhas and {} colunas'.format(test.shape[0], test.shape[1]))\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando arquivo dataset_treino.csv....\n",
      "dataset_treino.csv tem 114321 linhas and 44 colunas\n",
      "Carregando arquivo dataset_teste.csv....\n",
      "dataset_teste.csv tem 114393 linhas and 51 colunas\n"
     ]
    }
   ],
   "source": [
    "# Leitura dos dados\n",
    "train, test = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v31</th>\n",
       "      <th>v129</th>\n",
       "      <th>v50</th>\n",
       "      <th>v110</th>\n",
       "      <th>v66</th>\n",
       "      <th>v47</th>\n",
       "      <th>v38</th>\n",
       "      <th>v113</th>\n",
       "      <th>v56</th>\n",
       "      <th>v79</th>\n",
       "      <th>v24</th>\n",
       "      <th>v71</th>\n",
       "      <th>v74</th>\n",
       "      <th>v101</th>\n",
       "      <th>v3</th>\n",
       "      <th>v62</th>\n",
       "      <th>v30</th>\n",
       "      <th>v85</th>\n",
       "      <th>v72</th>\n",
       "      <th>v67</th>\n",
       "      <th>v100</th>\n",
       "      <th>v94</th>\n",
       "      <th>v84</th>\n",
       "      <th>v111</th>\n",
       "      <th>v95</th>\n",
       "      <th>v106</th>\n",
       "      <th>v108</th>\n",
       "      <th>v22</th>\n",
       "      <th>v125</th>\n",
       "      <th>v112</th>\n",
       "      <th>v52</th>\n",
       "      <th>v91</th>\n",
       "      <th>v107</th>\n",
       "      <th>v10_bin</th>\n",
       "      <th>v14_bin</th>\n",
       "      <th>v26_bin</th>\n",
       "      <th>v28_bin</th>\n",
       "      <th>v34_bin</th>\n",
       "      <th>v46_bin</th>\n",
       "      <th>v55_bin</th>\n",
       "      <th>v57_bin</th>\n",
       "      <th>v58_bin</th>\n",
       "      <th>v65_bin</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.386152</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.269716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.598997</td>\n",
       "      <td>0.141689</td>\n",
       "      <td>0.281723</td>\n",
       "      <td>0.139374</td>\n",
       "      <td>0.338176</td>\n",
       "      <td>0.212921</td>\n",
       "      <td>0.495177</td>\n",
       "      <td>0.131094</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>122</td>\n",
       "      <td>175</td>\n",
       "      <td>141</td>\n",
       "      <td>251</td>\n",
       "      <td>138</td>\n",
       "      <td>9</td>\n",
       "      <td>106</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.163392</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.233377</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.328590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.441279</td>\n",
       "      <td>0.764561</td>\n",
       "      <td>0.239724</td>\n",
       "      <td>0.172676</td>\n",
       "      <td>0.340090</td>\n",
       "      <td>0.163506</td>\n",
       "      <td>0.407940</td>\n",
       "      <td>0.135128</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>175</td>\n",
       "      <td>62</td>\n",
       "      <td>124</td>\n",
       "      <td>138</td>\n",
       "      <td>21</td>\n",
       "      <td>54</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053418</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171427</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.398321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>6</td>\n",
       "      <td>0.506923</td>\n",
       "      <td>0.973248</td>\n",
       "      <td>0.197568</td>\n",
       "      <td>0.128673</td>\n",
       "      <td>0.236744</td>\n",
       "      <td>0.170047</td>\n",
       "      <td>0.612259</td>\n",
       "      <td>0.132526</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>137</td>\n",
       "      <td>54</td>\n",
       "      <td>69</td>\n",
       "      <td>120</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>61</td>\n",
       "      <td>22</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v31  v129       v50  v110  v66  v47  v38  v113  v56  v79  v24  v71  v74  \\\n",
       "0    0     0  0.111270     0    0    0    0     0    0    0    0    0    0   \n",
       "1    0     0  0.163392     0    1    1    0     1    1    1    1    1    0   \n",
       "2    0     0  0.146414     0    0    2    0     0    2    2    2    1    0   \n",
       "3    0     0  0.053418     0    2    1    0     0   -1    3    1    1    0   \n",
       "4    1     0  0.171427     1    1    3    6    -1    3    4    0    1    1   \n",
       "\n",
       "       v101  v3  v62  v30       v85  v72       v67      v100       v94  \\\n",
       "0  0.386152   0    1    0  0.269716    1  0.598997  0.141689  0.281723   \n",
       "1  0.000000   0    1    1  0.000000    1  0.000000  0.000000  0.000000   \n",
       "2  0.233377   0    1   -1  0.328590    1  0.441279  0.764561  0.239724   \n",
       "3  0.000000   0    2   -1  0.000000    2  0.000000  0.000000  0.000000   \n",
       "4  0.398321   0    0   -1  0.114583    6  0.506923  0.973248  0.197568   \n",
       "\n",
       "        v84      v111       v95      v106      v108  v22  v125  v112  v52  \\\n",
       "0  0.139374  0.338176  0.212921  0.495177  0.131094    0     0     0    0   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000    1     1     0    1   \n",
       "2  0.172676  0.340090  0.163506  0.407940  0.135128    2     2     1    0   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000    3     3     2    2   \n",
       "4  0.128673  0.236744  0.170047  0.612259  0.132526    4     4     3    3   \n",
       "\n",
       "   v91  v107  v10_bin  v14_bin  v26_bin  v28_bin  v34_bin  v46_bin  v55_bin  \\\n",
       "0    0     0       49       45      122      175      141      251      138   \n",
       "1    0     0       61       35        0        0      175        0        0   \n",
       "2    0     0       61       58       30      175       62      124      138   \n",
       "3    1     1       38       43        0        0       62        0        0   \n",
       "4    0     0       55      137       54       69      120       15       32   \n",
       "\n",
       "   v57_bin  v58_bin  v65_bin  target  \n",
       "0        9      106      128       0  \n",
       "1        0        0        0       1  \n",
       "2       21       54       37       1  \n",
       "3        0        0        0       0  \n",
       "4       61       22      151       1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v31</th>\n",
       "      <th>v129</th>\n",
       "      <th>v50</th>\n",
       "      <th>v110</th>\n",
       "      <th>v66</th>\n",
       "      <th>v47</th>\n",
       "      <th>v38</th>\n",
       "      <th>v113</th>\n",
       "      <th>v56</th>\n",
       "      <th>v79</th>\n",
       "      <th>v24</th>\n",
       "      <th>v71</th>\n",
       "      <th>v74</th>\n",
       "      <th>v101</th>\n",
       "      <th>v3</th>\n",
       "      <th>v62</th>\n",
       "      <th>v30</th>\n",
       "      <th>v85</th>\n",
       "      <th>v72</th>\n",
       "      <th>v67</th>\n",
       "      <th>v100</th>\n",
       "      <th>v94</th>\n",
       "      <th>v84</th>\n",
       "      <th>v111</th>\n",
       "      <th>v95</th>\n",
       "      <th>v106</th>\n",
       "      <th>v108</th>\n",
       "      <th>v22</th>\n",
       "      <th>v125</th>\n",
       "      <th>v112</th>\n",
       "      <th>v52</th>\n",
       "      <th>v91</th>\n",
       "      <th>v107</th>\n",
       "      <th>v10_bin</th>\n",
       "      <th>v14_bin</th>\n",
       "      <th>v26_bin</th>\n",
       "      <th>v28_bin</th>\n",
       "      <th>v34_bin</th>\n",
       "      <th>v46_bin</th>\n",
       "      <th>v55_bin</th>\n",
       "      <th>v57_bin</th>\n",
       "      <th>v58_bin</th>\n",
       "      <th>v65_bin</th>\n",
       "      <th>target_Logistic Regression_predictions</th>\n",
       "      <th>target_Linear Discriminant_predictions</th>\n",
       "      <th>target_Naive Bayes_predictions</th>\n",
       "      <th>target_Bagging_predictions</th>\n",
       "      <th>target_CatBoost_predictions</th>\n",
       "      <th>Class_proba_0</th>\n",
       "      <th>Class_proba_1</th>\n",
       "      <th>target_Ensembled_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053278</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246990</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.136213</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429988</td>\n",
       "      <td>0.986097</td>\n",
       "      <td>0.199456</td>\n",
       "      <td>0.090104</td>\n",
       "      <td>0.217561</td>\n",
       "      <td>0.174763</td>\n",
       "      <td>0.604196</td>\n",
       "      <td>0.119166</td>\n",
       "      <td>10794</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>62</td>\n",
       "      <td>16</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707753</td>\n",
       "      <td>0.292247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.096527</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>113</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.119297</td>\n",
       "      <td>0.880703</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087654</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.358836</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.136213</td>\n",
       "      <td>1</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.208014</td>\n",
       "      <td>0.084725</td>\n",
       "      <td>0.196042</td>\n",
       "      <td>0.159372</td>\n",
       "      <td>0.607002</td>\n",
       "      <td>0.104227</td>\n",
       "      <td>18210</td>\n",
       "      <td>66</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>158</td>\n",
       "      <td>163</td>\n",
       "      <td>16</td>\n",
       "      <td>158</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.293546</td>\n",
       "      <td>0.706454</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220365</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.447680</td>\n",
       "      <td>0.053150</td>\n",
       "      <td>0.303320</td>\n",
       "      <td>0.248601</td>\n",
       "      <td>0.234898</td>\n",
       "      <td>0.200637</td>\n",
       "      <td>0.331290</td>\n",
       "      <td>0.175756</td>\n",
       "      <td>2444</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>175</td>\n",
       "      <td>114</td>\n",
       "      <td>207</td>\n",
       "      <td>182</td>\n",
       "      <td>95</td>\n",
       "      <td>131</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.357478</td>\n",
       "      <td>0.642522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118745</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.362228</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.092971</td>\n",
       "      <td>2</td>\n",
       "      <td>0.498549</td>\n",
       "      <td>0.963224</td>\n",
       "      <td>0.244056</td>\n",
       "      <td>0.073417</td>\n",
       "      <td>0.134688</td>\n",
       "      <td>0.140762</td>\n",
       "      <td>0.746046</td>\n",
       "      <td>0.165096</td>\n",
       "      <td>7527</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>153</td>\n",
       "      <td>152</td>\n",
       "      <td>69</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>141</td>\n",
       "      <td>36</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267498</td>\n",
       "      <td>0.732502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v31  v129       v50  v110  v66  v47  v38  v113  v56  v79  v24  v71  v74  \\\n",
       "0    0     0  0.053278     0    2    2    0    -1    2    2    1    1    0   \n",
       "1    0     0  0.096527     1    1    3    4    -1    4    6    3    1    0   \n",
       "2    0     0  0.087654     0    1    1    0     1   28    3    0    1    0   \n",
       "3    0     0  0.092684     0    0    1    0     0    0    3    1    1    0   \n",
       "4    0     0  0.118745     0    0    1    0    13   -1    3    1    1    0   \n",
       "\n",
       "       v101  v3  v62  v30       v85  v72       v67      v100       v94  \\\n",
       "0  0.246990   0    1   -1  0.136213    1  0.429988  0.986097  0.199456   \n",
       "1  0.000000   0    1    4  0.000000    5  0.000000  0.000000  0.000000   \n",
       "2  0.358836   0    1    1  0.136213    1  0.480519  0.990476  0.208014   \n",
       "3  0.220365   0    1    5  0.333333    1  0.447680  0.053150  0.303320   \n",
       "4  0.362228   0    2    1  0.092971    2  0.498549  0.963224  0.244056   \n",
       "\n",
       "        v84      v111       v95      v106      v108    v22  v125  v112  v52  \\\n",
       "0  0.090104  0.217561  0.174763  0.604196  0.119166  10794    19     7    7   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000    113    53    14   10   \n",
       "2  0.084725  0.196042  0.159372  0.607002  0.104227  18210    66    17   10   \n",
       "3  0.248601  0.234898  0.200637  0.331290  0.175756   2444    65     5   10   \n",
       "4  0.073417  0.134688  0.140762  0.746046  0.165096   7527    36    16    8   \n",
       "\n",
       "   v91  v107  v10_bin  v14_bin  v26_bin  v28_bin  v34_bin  v46_bin  v55_bin  \\\n",
       "0    3     3       49      100       30       43       62       16       52   \n",
       "1    2     2       48       44        0        0      212        0        0   \n",
       "2    2     2       55      158      163       16      158        2       21   \n",
       "3    3     3       55       38       49      175      114      207      182   \n",
       "4    3     3       38       45      153      152       69       27       21   \n",
       "\n",
       "   v57_bin  v58_bin  v65_bin  target_Logistic Regression_predictions  \\\n",
       "0        9       10      129                                       1   \n",
       "1        0        0        0                                       1   \n",
       "2      141        0      129                                       1   \n",
       "3       95      131       21                                       1   \n",
       "4      141       36      170                                       1   \n",
       "\n",
       "   target_Linear Discriminant_predictions  target_Naive Bayes_predictions  \\\n",
       "0                                       1                               0   \n",
       "1                                       1                               1   \n",
       "2                                       1                               1   \n",
       "3                                       1                               1   \n",
       "4                                       1                               1   \n",
       "\n",
       "   target_Bagging_predictions  target_CatBoost_predictions  Class_proba_0  \\\n",
       "0                           0                            0       0.707753   \n",
       "1                           1                            1       0.119297   \n",
       "2                           1                            1       0.293546   \n",
       "3                           1                            1       0.357478   \n",
       "4                           1                            1       0.267498   \n",
       "\n",
       "   Class_proba_1  target_Ensembled_predictions  \n",
       "0       0.292247                             0  \n",
       "1       0.880703                             1  \n",
       "2       0.706454                             1  \n",
       "3       0.642522                             1  \n",
       "4       0.732502                             1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test.columns[:-8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>v100</th>\n",
       "      <th>v101</th>\n",
       "      <th>v106</th>\n",
       "      <th>v107</th>\n",
       "      <th>v108</th>\n",
       "      <th>v10_bin</th>\n",
       "      <th>v110</th>\n",
       "      <th>v111</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v125</th>\n",
       "      <th>v129</th>\n",
       "      <th>v14_bin</th>\n",
       "      <th>v22</th>\n",
       "      <th>v24</th>\n",
       "      <th>v26_bin</th>\n",
       "      <th>v28_bin</th>\n",
       "      <th>v3</th>\n",
       "      <th>v30</th>\n",
       "      <th>v31</th>\n",
       "      <th>v34_bin</th>\n",
       "      <th>v38</th>\n",
       "      <th>v46_bin</th>\n",
       "      <th>v47</th>\n",
       "      <th>v50</th>\n",
       "      <th>v52</th>\n",
       "      <th>v55_bin</th>\n",
       "      <th>v56</th>\n",
       "      <th>v57_bin</th>\n",
       "      <th>v58_bin</th>\n",
       "      <th>v62</th>\n",
       "      <th>v65_bin</th>\n",
       "      <th>v66</th>\n",
       "      <th>v67</th>\n",
       "      <th>v71</th>\n",
       "      <th>v72</th>\n",
       "      <th>v74</th>\n",
       "      <th>v79</th>\n",
       "      <th>v84</th>\n",
       "      <th>v85</th>\n",
       "      <th>v91</th>\n",
       "      <th>v94</th>\n",
       "      <th>v95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141689</td>\n",
       "      <td>0.386152</td>\n",
       "      <td>0.495177</td>\n",
       "      <td>0</td>\n",
       "      <td>0.131094</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.338176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111270</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.598997</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139374</td>\n",
       "      <td>0.269716</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281723</td>\n",
       "      <td>0.212921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.163392</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.764561</td>\n",
       "      <td>0.233377</td>\n",
       "      <td>0.407940</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135128</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0.340090</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "      <td>0.146414</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441279</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.172676</td>\n",
       "      <td>0.328590</td>\n",
       "      <td>0</td>\n",
       "      <td>0.239724</td>\n",
       "      <td>0.163506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053418</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973248</td>\n",
       "      <td>0.398321</td>\n",
       "      <td>0.612259</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132526</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0.236744</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.171427</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506923</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.128673</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197568</td>\n",
       "      <td>0.170047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target      v100      v101      v106  v107      v108  v10_bin  v110  \\\n",
       "0     0.0  0.141689  0.386152  0.495177     0  0.131094       49     0   \n",
       "1     1.0  0.000000  0.000000  0.000000     0  0.000000       61     0   \n",
       "2     1.0  0.764561  0.233377  0.407940     0  0.135128       61     0   \n",
       "3     0.0  0.000000  0.000000  0.000000     1  0.000000       38     0   \n",
       "4     1.0  0.973248  0.398321  0.612259     0  0.132526       55     1   \n",
       "\n",
       "       v111  v112  v113  v125  v129  v14_bin  v22  v24  v26_bin  v28_bin  v3  \\\n",
       "0  0.338176     0     0     0     0       45    0    0      122      175   0   \n",
       "1  0.000000     0     1     1     0       35    1    1        0        0   0   \n",
       "2  0.340090     1     0     2     0       58    2    2       30      175   0   \n",
       "3  0.000000     2     0     3     0       43    3    1        0        0   0   \n",
       "4  0.236744     3    -1     4     0      137    4    0       54       69   0   \n",
       "\n",
       "   v30  v31  v34_bin  v38  v46_bin  v47       v50  v52  v55_bin  v56  v57_bin  \\\n",
       "0    0    0      141    0      251    0  0.111270    0      138    0        9   \n",
       "1    1    0      175    0        0    1  0.163392    1        0    1        0   \n",
       "2   -1    0       62    0      124    2  0.146414    0      138    2       21   \n",
       "3   -1    0       62    0        0    1  0.053418    2        0   -1        0   \n",
       "4   -1    1      120    6       15    3  0.171427    3       32    3       61   \n",
       "\n",
       "   v58_bin  v62  v65_bin  v66       v67  v71  v72  v74  v79       v84  \\\n",
       "0      106    1      128    0  0.598997    0    1    0    0  0.139374   \n",
       "1        0    1        0    1  0.000000    1    1    0    1  0.000000   \n",
       "2       54    1       37    0  0.441279    1    1    0    2  0.172676   \n",
       "3        0    2        0    2  0.000000    1    2    0    3  0.000000   \n",
       "4       22    0      151    1  0.506923    1    6    1    4  0.128673   \n",
       "\n",
       "        v85  v91       v94       v95  \n",
       "0  0.269716    0  0.281723  0.212921  \n",
       "1  0.000000    0  0.000000  0.000000  \n",
       "2  0.328590    0  0.239724  0.163506  \n",
       "3  0.000000    1  0.000000  0.000000  \n",
       "4  0.114583    0  0.197568  0.170047  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Criar e avaliar alguns algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Algoritmo LigthGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações Gerais\n",
    "\n",
    "GENERATE_SUBMISSION_FILES = True\n",
    "SUBMISSION_SUFIX = \"_lgbm_v.1.0.0\"\n",
    "STRATIFIED_KFOLD = False\n",
    "RANDOM_SEED = 737851\n",
    "NUM_THREADS = 4\n",
    "NUM_FOLDS = 10\n",
    "EARLY_STOPPING = 100\n",
    "\n",
    "LIGHTGBM_PARAMS = {\n",
    "    'boosting_type': 'goss',\n",
    "    'n_estimators': 10000,\n",
    "    'learning_rate': 0.005134,\n",
    "    'num_leaves': 54,\n",
    "    'max_depth': 10,\n",
    "    'subsample_for_bin': 240000,\n",
    "    'reg_alpha': 0.436193,\n",
    "    'reg_lambda': 0.479169,\n",
    "    'colsample_bytree': 0.508716,\n",
    "    'min_split_gain': 0.024766,\n",
    "    'subsample': 1,\n",
    "    'is_unbalance': False,\n",
    "    'silent':-1,\n",
    "    'verbose':-1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- LIGHTGBM MODEL -------------------------\n",
    "\n",
    "def run_model(data, categorical_feature = None):\n",
    "    df = data[data['target'].notnull()]\n",
    "    test = data[data['target'].isnull()]\n",
    "    del_features = ['target']\n",
    "    predictors = list(filter(lambda v: v not in del_features, df.columns))\n",
    "    \n",
    "    print(\"Train/valid shape: {}, test shape: {}\".format(df.shape, test.shape))\n",
    "\n",
    "    if not STRATIFIED_KFOLD:\n",
    "        folds = KFold(n_splits= NUM_FOLDS, shuffle=True, random_state= RANDOM_SEED)\n",
    "    else:\n",
    "        folds = StratifiedKFold(n_splits= NUM_FOLDS, shuffle=True, random_state= RANDOM_SEED)\n",
    "\n",
    "    # Hold oof predictions, test predictions, feature importance and training/valid auc\n",
    "    oof_preds = np.zeros(df.shape[0])\n",
    "    sub_preds = np.zeros(test.shape[0])\n",
    "    importance_df = pd.DataFrame()\n",
    "    eval_results = dict()\n",
    "\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(df[predictors], df['target'])):\n",
    "        train_x, train_y = df[predictors].iloc[train_idx], df['target'].iloc[train_idx]\n",
    "        valid_x, valid_y = df[predictors].iloc[valid_idx], df['target'].iloc[valid_idx]\n",
    "\n",
    "        params = {'random_state': RANDOM_SEED, 'nthread': NUM_THREADS}\n",
    "        clf = LGBMClassifier(**{**params, **LIGHTGBM_PARAMS})\n",
    "        if not categorical_feature:\n",
    "            clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                    eval_metric='logloss', verbose=400, early_stopping_rounds= EARLY_STOPPING)\n",
    "        else:\n",
    "            clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                    eval_metric='logloss', verbose=400, early_stopping_rounds=EARLY_STOPPING,\n",
    "                    feature_name= list(df[predictors].columns), categorical_feature= categorical_feature)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test[predictors], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        # Feature importance by GAIN and SPLIT\n",
    "        fold_importance = pd.DataFrame()\n",
    "        fold_importance[\"feature\"] = predictors\n",
    "        fold_importance[\"gain\"] = clf.booster_.feature_importance(importance_type='gain')\n",
    "        fold_importance[\"split\"] = clf.booster_.feature_importance(importance_type='split')\n",
    "        importance_df = pd.concat([importance_df, fold_importance], axis=0)\n",
    "        eval_results['train_{}'.format(n_fold+1)]  = clf.evals_result_['training']['binary_logloss']\n",
    "        eval_results['valid_{}'.format(n_fold+1)] = clf.evals_result_['valid_1']['binary_logloss']\n",
    "\n",
    "        print('Fold %2d Log Loss : %.6f' % (n_fold + 1, log_loss(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full Log Loss score %.6f' % log_loss(df['target'], oof_preds))\n",
    "    test['target'] = sub_preds.copy()\n",
    "\n",
    "    # Get the average feature importance between folds\n",
    "    mean_importance = importance_df.groupby('feature').mean().reset_index()\n",
    "    mean_importance.sort_values(by= 'gain', ascending=False, inplace=True)\n",
    "    # Save feature importance, test predictions and oof predictions as csv\n",
    "    if GENERATE_SUBMISSION_FILES:\n",
    "\n",
    "        # Save submission (test data) and feature importance\n",
    "        submission = pd.read_csv('../dataset/sample_submission.csv')\n",
    "        submission['PredictedProb'] = sub_preds.copy()\n",
    "        submission.to_csv('../submission/submission{}.csv'.format(SUBMISSION_SUFIX), index=False)\n",
    "        \n",
    "        mean_importance.to_csv('feature_importance{}.csv'.format(SUBMISSION_SUFIX), index=False)\n",
    "        plt.hist(submission.PredictedProb)\n",
    "        plt.show()\n",
    "    return mean_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/valid shape: (114321, 44), test shape: (114393, 44)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.472541\tvalid_1's binary_logloss: 0.483575\n",
      "[800]\ttraining's binary_logloss: 0.456789\tvalid_1's binary_logloss: 0.474793\n",
      "[1200]\ttraining's binary_logloss: 0.447137\tvalid_1's binary_logloss: 0.472385\n",
      "[1600]\ttraining's binary_logloss: 0.439081\tvalid_1's binary_logloss: 0.470907\n",
      "[2000]\ttraining's binary_logloss: 0.431718\tvalid_1's binary_logloss: 0.470128\n",
      "[2400]\ttraining's binary_logloss: 0.424954\tvalid_1's binary_logloss: 0.469402\n",
      "[2800]\ttraining's binary_logloss: 0.418593\tvalid_1's binary_logloss: 0.468991\n",
      "Early stopping, best iteration is:\n",
      "[2717]\ttraining's binary_logloss: 0.419845\tvalid_1's binary_logloss: 0.468917\n",
      "Fold  1 Log Loss : 0.468917\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.472502\tvalid_1's binary_logloss: 0.481706\n",
      "[800]\ttraining's binary_logloss: 0.456544\tvalid_1's binary_logloss: 0.473255\n",
      "[1200]\ttraining's binary_logloss: 0.446935\tvalid_1's binary_logloss: 0.470623\n",
      "[1600]\ttraining's binary_logloss: 0.438902\tvalid_1's binary_logloss: 0.469497\n",
      "[2000]\ttraining's binary_logloss: 0.431621\tvalid_1's binary_logloss: 0.468673\n",
      "Early stopping, best iteration is:\n",
      "[2093]\ttraining's binary_logloss: 0.430016\tvalid_1's binary_logloss: 0.468598\n",
      "Fold  2 Log Loss : 0.468598\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.473971\tvalid_1's binary_logloss: 0.470571\n",
      "[800]\ttraining's binary_logloss: 0.458073\tvalid_1's binary_logloss: 0.462428\n",
      "[1200]\ttraining's binary_logloss: 0.448408\tvalid_1's binary_logloss: 0.45983\n",
      "[1600]\ttraining's binary_logloss: 0.440358\tvalid_1's binary_logloss: 0.458619\n",
      "[2000]\ttraining's binary_logloss: 0.433035\tvalid_1's binary_logloss: 0.457526\n",
      "Early stopping, best iteration is:\n",
      "[2155]\ttraining's binary_logloss: 0.43041\tvalid_1's binary_logloss: 0.457229\n",
      "Fold  3 Log Loss : 0.457229\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.472335\tvalid_1's binary_logloss: 0.48329\n",
      "[800]\ttraining's binary_logloss: 0.456568\tvalid_1's binary_logloss: 0.474897\n",
      "[1200]\ttraining's binary_logloss: 0.447009\tvalid_1's binary_logloss: 0.472314\n",
      "[1600]\ttraining's binary_logloss: 0.43892\tvalid_1's binary_logloss: 0.47077\n",
      "[2000]\ttraining's binary_logloss: 0.431578\tvalid_1's binary_logloss: 0.469541\n",
      "[2400]\ttraining's binary_logloss: 0.424785\tvalid_1's binary_logloss: 0.468697\n",
      "[2800]\ttraining's binary_logloss: 0.418402\tvalid_1's binary_logloss: 0.467971\n",
      "Early stopping, best iteration is:\n",
      "[2939]\ttraining's binary_logloss: 0.416278\tvalid_1's binary_logloss: 0.467847\n",
      "Fold  4 Log Loss : 0.467847\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.472697\tvalid_1's binary_logloss: 0.483429\n",
      "[800]\ttraining's binary_logloss: 0.456977\tvalid_1's binary_logloss: 0.473874\n",
      "[1200]\ttraining's binary_logloss: 0.447455\tvalid_1's binary_logloss: 0.470591\n",
      "[1600]\ttraining's binary_logloss: 0.439374\tvalid_1's binary_logloss: 0.468833\n",
      "[2000]\ttraining's binary_logloss: 0.432112\tvalid_1's binary_logloss: 0.467645\n",
      "[2400]\ttraining's binary_logloss: 0.425355\tvalid_1's binary_logloss: 0.466771\n",
      "[2800]\ttraining's binary_logloss: 0.419002\tvalid_1's binary_logloss: 0.466135\n",
      "[3200]\ttraining's binary_logloss: 0.412902\tvalid_1's binary_logloss: 0.465702\n",
      "[3600]\ttraining's binary_logloss: 0.407076\tvalid_1's binary_logloss: 0.465269\n",
      "Early stopping, best iteration is:\n",
      "[3595]\ttraining's binary_logloss: 0.407151\tvalid_1's binary_logloss: 0.465235\n",
      "Fold  5 Log Loss : 0.465235\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.473367\tvalid_1's binary_logloss: 0.475758\n",
      "[800]\ttraining's binary_logloss: 0.457579\tvalid_1's binary_logloss: 0.465974\n",
      "[1200]\ttraining's binary_logloss: 0.448018\tvalid_1's binary_logloss: 0.462784\n",
      "[1600]\ttraining's binary_logloss: 0.440029\tvalid_1's binary_logloss: 0.461118\n",
      "[2000]\ttraining's binary_logloss: 0.432765\tvalid_1's binary_logloss: 0.460098\n",
      "[2400]\ttraining's binary_logloss: 0.425927\tvalid_1's binary_logloss: 0.459233\n",
      "[2800]\ttraining's binary_logloss: 0.419603\tvalid_1's binary_logloss: 0.458549\n",
      "[3200]\ttraining's binary_logloss: 0.413526\tvalid_1's binary_logloss: 0.45789\n",
      "[3600]\ttraining's binary_logloss: 0.407784\tvalid_1's binary_logloss: 0.457335\n",
      "[4000]\ttraining's binary_logloss: 0.402257\tvalid_1's binary_logloss: 0.456871\n",
      "[4400]\ttraining's binary_logloss: 0.396961\tvalid_1's binary_logloss: 0.456589\n",
      "[4800]\ttraining's binary_logloss: 0.391855\tvalid_1's binary_logloss: 0.456265\n",
      "[5200]\ttraining's binary_logloss: 0.386938\tvalid_1's binary_logloss: 0.455939\n",
      "[5600]\ttraining's binary_logloss: 0.38218\tvalid_1's binary_logloss: 0.455569\n",
      "[6000]\ttraining's binary_logloss: 0.377577\tvalid_1's binary_logloss: 0.455198\n",
      "Early stopping, best iteration is:\n",
      "[5971]\ttraining's binary_logloss: 0.377906\tvalid_1's binary_logloss: 0.455168\n",
      "Fold  6 Log Loss : 0.455168\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.473499\tvalid_1's binary_logloss: 0.4764\n",
      "[800]\ttraining's binary_logloss: 0.457615\tvalid_1's binary_logloss: 0.466859\n",
      "[1200]\ttraining's binary_logloss: 0.448091\tvalid_1's binary_logloss: 0.463954\n",
      "[1600]\ttraining's binary_logloss: 0.440084\tvalid_1's binary_logloss: 0.462691\n",
      "[2000]\ttraining's binary_logloss: 0.432759\tvalid_1's binary_logloss: 0.461704\n",
      "[2400]\ttraining's binary_logloss: 0.426033\tvalid_1's binary_logloss: 0.461013\n",
      "[2800]\ttraining's binary_logloss: 0.419677\tvalid_1's binary_logloss: 0.460199\n",
      "[3200]\ttraining's binary_logloss: 0.413694\tvalid_1's binary_logloss: 0.459793\n",
      "Early stopping, best iteration is:\n",
      "[3437]\ttraining's binary_logloss: 0.41022\tvalid_1's binary_logloss: 0.459602\n",
      "Fold  7 Log Loss : 0.459602\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.472754\tvalid_1's binary_logloss: 0.481793\n",
      "[800]\ttraining's binary_logloss: 0.456917\tvalid_1's binary_logloss: 0.472852\n",
      "[1200]\ttraining's binary_logloss: 0.447252\tvalid_1's binary_logloss: 0.469779\n",
      "[1600]\ttraining's binary_logloss: 0.439297\tvalid_1's binary_logloss: 0.468314\n",
      "[2000]\ttraining's binary_logloss: 0.431994\tvalid_1's binary_logloss: 0.467179\n",
      "[2400]\ttraining's binary_logloss: 0.425209\tvalid_1's binary_logloss: 0.466219\n",
      "[2800]\ttraining's binary_logloss: 0.41878\tvalid_1's binary_logloss: 0.46565\n",
      "[3200]\ttraining's binary_logloss: 0.412789\tvalid_1's binary_logloss: 0.464973\n",
      "[3600]\ttraining's binary_logloss: 0.406904\tvalid_1's binary_logloss: 0.464539\n",
      "[4000]\ttraining's binary_logloss: 0.401359\tvalid_1's binary_logloss: 0.464125\n",
      "Early stopping, best iteration is:\n",
      "[4117]\ttraining's binary_logloss: 0.399764\tvalid_1's binary_logloss: 0.464001\n",
      "Fold  8 Log Loss : 0.464001\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.47277\tvalid_1's binary_logloss: 0.48029\n",
      "[800]\ttraining's binary_logloss: 0.456786\tvalid_1's binary_logloss: 0.472711\n",
      "[1200]\ttraining's binary_logloss: 0.447102\tvalid_1's binary_logloss: 0.470552\n",
      "[1600]\ttraining's binary_logloss: 0.43911\tvalid_1's binary_logloss: 0.469681\n",
      "[2000]\ttraining's binary_logloss: 0.431858\tvalid_1's binary_logloss: 0.469138\n",
      "[2400]\ttraining's binary_logloss: 0.425037\tvalid_1's binary_logloss: 0.468722\n",
      "[2800]\ttraining's binary_logloss: 0.418667\tvalid_1's binary_logloss: 0.468234\n",
      "[3200]\ttraining's binary_logloss: 0.412581\tvalid_1's binary_logloss: 0.467972\n",
      "[3600]\ttraining's binary_logloss: 0.406799\tvalid_1's binary_logloss: 0.467548\n",
      "Early stopping, best iteration is:\n",
      "[3883]\ttraining's binary_logloss: 0.402835\tvalid_1's binary_logloss: 0.467348\n",
      "Fold  9 Log Loss : 0.467348\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.47346\tvalid_1's binary_logloss: 0.474452\n",
      "[800]\ttraining's binary_logloss: 0.457648\tvalid_1's binary_logloss: 0.465233\n",
      "[1200]\ttraining's binary_logloss: 0.448123\tvalid_1's binary_logloss: 0.462629\n",
      "[1600]\ttraining's binary_logloss: 0.44013\tvalid_1's binary_logloss: 0.460999\n",
      "[2000]\ttraining's binary_logloss: 0.432866\tvalid_1's binary_logloss: 0.460057\n",
      "[2400]\ttraining's binary_logloss: 0.426112\tvalid_1's binary_logloss: 0.45935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2800]\ttraining's binary_logloss: 0.419584\tvalid_1's binary_logloss: 0.458665\n",
      "[3200]\ttraining's binary_logloss: 0.413472\tvalid_1's binary_logloss: 0.458277\n",
      "[3600]\ttraining's binary_logloss: 0.407714\tvalid_1's binary_logloss: 0.457647\n",
      "[4000]\ttraining's binary_logloss: 0.402174\tvalid_1's binary_logloss: 0.457237\n",
      "Early stopping, best iteration is:\n",
      "[4115]\ttraining's binary_logloss: 0.400611\tvalid_1's binary_logloss: 0.457072\n",
      "Fold 10 Log Loss : 0.457072\n",
      "Full Log Loss score 0.463102\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>v50</td>\n",
       "      <td>1.069258e+06</td>\n",
       "      <td>14800.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>v22</td>\n",
       "      <td>2.967359e+05</td>\n",
       "      <td>10396.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>v56</td>\n",
       "      <td>2.897258e+05</td>\n",
       "      <td>8728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>v66</td>\n",
       "      <td>2.767922e+05</td>\n",
       "      <td>3622.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>v10_bin</td>\n",
       "      <td>2.592728e+05</td>\n",
       "      <td>8304.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>v34_bin</td>\n",
       "      <td>2.313032e+05</td>\n",
       "      <td>6983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>v125</td>\n",
       "      <td>2.195386e+05</td>\n",
       "      <td>7770.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>v14_bin</td>\n",
       "      <td>2.111776e+05</td>\n",
       "      <td>7327.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>v100</td>\n",
       "      <td>1.707931e+05</td>\n",
       "      <td>6172.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>v108</td>\n",
       "      <td>1.674346e+05</td>\n",
       "      <td>6124.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>v95</td>\n",
       "      <td>1.620588e+05</td>\n",
       "      <td>5964.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>v94</td>\n",
       "      <td>1.618875e+05</td>\n",
       "      <td>5983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>v67</td>\n",
       "      <td>1.606739e+05</td>\n",
       "      <td>5921.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>v31</td>\n",
       "      <td>1.597759e+05</td>\n",
       "      <td>1066.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>v85</td>\n",
       "      <td>1.589341e+05</td>\n",
       "      <td>5886.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>v101</td>\n",
       "      <td>1.570285e+05</td>\n",
       "      <td>5678.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>v84</td>\n",
       "      <td>1.546017e+05</td>\n",
       "      <td>5737.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>v111</td>\n",
       "      <td>1.542363e+05</td>\n",
       "      <td>5692.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>v106</td>\n",
       "      <td>1.499664e+05</td>\n",
       "      <td>5488.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>v112</td>\n",
       "      <td>1.354661e+05</td>\n",
       "      <td>4855.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>v52</td>\n",
       "      <td>1.338572e+05</td>\n",
       "      <td>4791.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>v113</td>\n",
       "      <td>1.317725e+05</td>\n",
       "      <td>4782.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>v79</td>\n",
       "      <td>1.193328e+05</td>\n",
       "      <td>3524.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>v46_bin</td>\n",
       "      <td>1.179523e+05</td>\n",
       "      <td>4388.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>v110</td>\n",
       "      <td>9.686201e+04</td>\n",
       "      <td>1130.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>v24</td>\n",
       "      <td>9.625886e+04</td>\n",
       "      <td>3255.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>v107</td>\n",
       "      <td>8.055673e+04</td>\n",
       "      <td>2926.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>v129</td>\n",
       "      <td>7.810457e+04</td>\n",
       "      <td>1398.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>v30</td>\n",
       "      <td>7.450030e+04</td>\n",
       "      <td>2714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>v28_bin</td>\n",
       "      <td>7.435304e+04</td>\n",
       "      <td>2819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>v47</td>\n",
       "      <td>7.372963e+04</td>\n",
       "      <td>1954.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>v26_bin</td>\n",
       "      <td>7.066499e+04</td>\n",
       "      <td>2622.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>v55_bin</td>\n",
       "      <td>6.761552e+04</td>\n",
       "      <td>2513.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>v58_bin</td>\n",
       "      <td>6.542274e+04</td>\n",
       "      <td>2524.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>v57_bin</td>\n",
       "      <td>6.402669e+04</td>\n",
       "      <td>2371.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>v65_bin</td>\n",
       "      <td>5.266683e+04</td>\n",
       "      <td>1945.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>v62</td>\n",
       "      <td>4.835412e+04</td>\n",
       "      <td>1350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>v72</td>\n",
       "      <td>4.711608e+04</td>\n",
       "      <td>1673.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>v91</td>\n",
       "      <td>3.924709e+04</td>\n",
       "      <td>1407.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>v71</td>\n",
       "      <td>3.897099e+04</td>\n",
       "      <td>1431.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>v38</td>\n",
       "      <td>3.444692e+04</td>\n",
       "      <td>1069.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>v74</td>\n",
       "      <td>1.058837e+04</td>\n",
       "      <td>361.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>v3</td>\n",
       "      <td>3.558924e+03</td>\n",
       "      <td>133.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature          gain    split\n",
       "24      v50  1.069258e+06  14800.2\n",
       "13      v22  2.967359e+05  10396.1\n",
       "27      v56  2.897258e+05   8728.0\n",
       "32      v66  2.767922e+05   3622.4\n",
       "5   v10_bin  2.592728e+05   8304.6\n",
       "20  v34_bin  2.313032e+05   6983.0\n",
       "10     v125  2.195386e+05   7770.6\n",
       "12  v14_bin  2.111776e+05   7327.7\n",
       "0      v100  1.707931e+05   6172.1\n",
       "4      v108  1.674346e+05   6124.2\n",
       "42      v95  1.620588e+05   5964.7\n",
       "41      v94  1.618875e+05   5983.0\n",
       "33      v67  1.606739e+05   5921.9\n",
       "19      v31  1.597759e+05   1066.6\n",
       "39      v85  1.589341e+05   5886.8\n",
       "1      v101  1.570285e+05   5678.9\n",
       "38      v84  1.546017e+05   5737.8\n",
       "7      v111  1.542363e+05   5692.2\n",
       "2      v106  1.499664e+05   5488.7\n",
       "8      v112  1.354661e+05   4855.5\n",
       "25      v52  1.338572e+05   4791.6\n",
       "9      v113  1.317725e+05   4782.2\n",
       "37      v79  1.193328e+05   3524.9\n",
       "22  v46_bin  1.179523e+05   4388.2\n",
       "6      v110  9.686201e+04   1130.4\n",
       "14      v24  9.625886e+04   3255.7\n",
       "3      v107  8.055673e+04   2926.7\n",
       "11     v129  7.810457e+04   1398.4\n",
       "18      v30  7.450030e+04   2714.0\n",
       "16  v28_bin  7.435304e+04   2819.0\n",
       "23      v47  7.372963e+04   1954.4\n",
       "15  v26_bin  7.066499e+04   2622.1\n",
       "26  v55_bin  6.761552e+04   2513.3\n",
       "29  v58_bin  6.542274e+04   2524.7\n",
       "28  v57_bin  6.402669e+04   2371.3\n",
       "31  v65_bin  5.266683e+04   1945.2\n",
       "30      v62  4.835412e+04   1350.0\n",
       "35      v72  4.711608e+04   1673.8\n",
       "40      v91  3.924709e+04   1407.3\n",
       "34      v71  3.897099e+04   1431.2\n",
       "21      v38  3.444692e+04   1069.7\n",
       "36      v74  1.058837e+04    361.8\n",
       "17       v3  3.558924e+03    133.8"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03f293c5aaf34fd7a50a3b2bf14dab7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0af695c1d5e24a17b3a2aebc133ddd39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6782fd7c22664c55904d66122a64843b",
        "IPY_MODEL_9163f58ecd4f4a84922abc60cc69d789"
       ],
       "layout": "IPY_MODEL_d8264eeec6af442097559d8923081902"
      }
     },
     "1c88767c318e4d86a9ab43245f5daa77": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "219092655bed428f83aeb751ccaa2a4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "44521ec2de994d5186cdf7d1e445d158": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6782fd7c22664c55904d66122a64843b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c5e6acfe3f654e7ca86e4cddf862e984",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_219092655bed428f83aeb751ccaa2a4d",
       "value": 1000
      }
     },
     "9163f58ecd4f4a84922abc60cc69d789": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9a5c32201e5c447b829c604d757794df",
       "placeholder": "​",
       "style": "IPY_MODEL_b90e11ceb23b4a84a2f4908689dff66f",
       "value": " 1000/1000 [01:50&lt;00:00,  9.06it/s]"
      }
     },
     "9a5c32201e5c447b829c604d757794df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a8bfc018378d49efa1570fcb43b496f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b90e11ceb23b4a84a2f4908689dff66f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c5e6acfe3f654e7ca86e4cddf862e984": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c95734415f404758ba787c86b58e7cc2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d0cb9d8667c340c4b49fb7cf32acaf7c",
        "IPY_MODEL_e1aabb08150346cc9871c9f6b3bb5d36"
       ],
       "layout": "IPY_MODEL_1c88767c318e4d86a9ab43245f5daa77"
      }
     },
     "d0cb9d8667c340c4b49fb7cf32acaf7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_44521ec2de994d5186cdf7d1e445d158",
       "max": 17000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_eec34a1f17e2477fb10e7c11419a1382",
       "value": 17000
      }
     },
     "d8264eeec6af442097559d8923081902": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e1aabb08150346cc9871c9f6b3bb5d36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a8bfc018378d49efa1570fcb43b496f3",
       "placeholder": "​",
       "style": "IPY_MODEL_03f293c5aaf34fd7a50a3b2bf14dab7d",
       "value": " 17000/17000 [11:01&lt;00:00, 25.68it/s]"
      }
     },
     "eec34a1f17e2477fb10e7c11419a1382": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
