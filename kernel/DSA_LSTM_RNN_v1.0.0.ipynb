{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle\n",
    "## Competição DSA de Machine Learning - Dezembro 2019\n",
    "\n",
    "Versão 1.0.0: LB = ???\n",
    "- modelo: LSTM com 1 camadas\n",
    "- features categoricas: removido\n",
    "- dados missing: atribuído o valor medio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar os principais pacotes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re\n",
    "import codecs\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "from numba import jit\n",
    "from collections import Counter\n",
    "import copy\n",
    "from typing import Any\n",
    "\n",
    "# Evitar que aparece os warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Seta algumas opções no Jupyter para exibição dos datasets\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# Variavel para controlar o treinamento no Kaggle\n",
    "TRAIN_OFFLINE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa os pacotes de algoritmos de redes neurais (Keras)\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, SpatialDropout1D, Masking, Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Importa pacotes do sklearn\n",
    "from sklearn import preprocessing\n",
    "import sklearn.metrics as mtr\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    if TRAIN_OFFLINE:\n",
    "        print('Carregando arquivo dataset_treino.csv....')\n",
    "        train = pd.read_csv('../dataset/dataset_treino_modificado.csv')\n",
    "        print('dataset_treino.csv tem {} linhas and {} colunas'.format(train.shape[0], train.shape[1]))\n",
    "        \n",
    "        print('Carregando arquivo dataset_teste.csv....')\n",
    "        test = pd.read_csv('../dataset/dataset_teste_modificado.csv')\n",
    "        print('dataset_teste.csv tem {} linhas and {} colunas'.format(test.shape[0], test.shape[1]))\n",
    "        \n",
    "    else:\n",
    "        print('Carregando arquivo dataset_treino.csv....')\n",
    "        train = pd.read_csv('/kaggle/input/competicao-dsa-machine-learning-dec-2019/dataset_treino.csv')\n",
    "        print('dataset_treino.csv tem {} linhas and {} colunas'.format(train.shape[0], train.shape[1]))\n",
    "        \n",
    "        print('Carregando arquivo dataset_treino.csv....')\n",
    "        test = pd.read_csv('/kaggle/input/competicao-dsa-machine-learning-dec-2019/dataset_teste.csv')\n",
    "        print('dataset_teste.csv tem {} linhas and {} colunas'.format(test.shape[0], test.shape[1]))\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura dos dados\n",
    "train, test = read_data()\n",
    "\n",
    "# Diminuindo os dados para testar\n",
    "#train = train[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando valores median para Na\n",
    "train.fillna(train.median(),inplace=True)\n",
    "\n",
    "# Removendo todas as variaveis categoricas\n",
    "#drop_features = []\n",
    "#for col in train.columns:\n",
    "#    if train[col].dtype =='object':\n",
    "#        drop_features.append(col)\n",
    "\n",
    "# Deixando somente features preditoras\n",
    "#train = train.drop(drop_features, axis=1)\n",
    "#train.drop(['ID'], axis=1, inplace=True)\n",
    "train_x = train.drop('target', axis=1)\n",
    "\n",
    "# Padronizando os dados (0 para a média, 1 para o desvio padrão)\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "\n",
    "# Separando a variavel target\n",
    "train_y = train['target']\n",
    "\n",
    "# Para criar o Modelo RNN LSTM com o Keras nossos dados precisam estar no formato [samples, seq_length, stepsize]   \n",
    "seq_length = 43\n",
    "X = np.asarray(np.reshape(train_x, (train_x.shape[0], seq_length, 1)))\n",
    "\n",
    "# One-Hot Encoding para as variáveis de saída\n",
    "y = to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelos de Deep Learning (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para controlar as iteraçoes da rede neural LSTM\n",
    "class CyclicLR(Callback):\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "        print(self.clr())\n",
    "\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(self.clr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_LSTM(x_tr, y_tr, x_val, y_val, shape, epochs, batch_size):\n",
    "    \n",
    "    #model = Sequential()\n",
    "    #model.add(LSTM(256, input_shape=(x_tr.shape[1], 1), return_sequences=True))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(LSTM(256))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(Dense(y_tr.shape[1], activation='softmax'))\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model = Sequential()   \n",
    "    model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5, input_shape=(shape, 1)))\n",
    "    model.add(Dense(2, activation='softmax'))  \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', \n",
    "                       mode='min',\n",
    "                       restore_best_weights=True, \n",
    "                       verbose=1, \n",
    "                       patience=5)\n",
    "\n",
    "    mc = ModelCheckpoint('best_model.h5',\n",
    "                         monitor='val_loss',\n",
    "                         mode='min',\n",
    "                         save_best_only=True, \n",
    "                         verbose=1, \n",
    "                         save_weights_only=True)\n",
    "\n",
    "    #cl = CyclicLR(base_lr=0.00001, \n",
    "    #              max_lr=0.01,\n",
    "    #              step_size=70., \n",
    "    #              mode='triangular2')\n",
    "\n",
    "    #clr = CyclicLR(base_lr=0.00001, max_lr=0.01,step_size=5, mode='exp_range',gamma=0.99994)\n",
    "    \n",
    "    model.fit(x_tr, y_tr,\n",
    "              validation_data=[x_val, y_val],\n",
    "              callbacks=[es,mc],\n",
    "              epochs=epochs, \n",
    "              batch_size=batch_size,\n",
    "              verbose=1,\n",
    "              shuffle=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando a memoria\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup para a execucao do modelo\n",
    "\n",
    "# Variaveis de controle de epochs e batch_size\n",
    "epochs = 200\n",
    "batch_size = 1024\n",
    "\n",
    "# Cross validation folds\n",
    "kf = 2\n",
    "folds = KFold(n_splits=kf, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "nn = build_LSTM(X_train, y_train, X_test, y_test, seq_length, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Rodando o modelo usando KFold\n",
    "models_nn = []\n",
    "\n",
    "for fold_, (train_index, test_index) in enumerate(folds.split(X, y)):\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    nn = build_LSTM(X_train, y_train, X_test, y_test, seq_length, epochs, batch_size)\n",
    "    \n",
    "    models_nn.append(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico mostrando a acuracia do modelo no primeiro KFold\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(models_nn[0].history.history[\"loss\"], \"o-\", alpha=.9, label=\"loss\")\n",
    "plt.plot(models_nn[0].history.history[\"val_loss\"], \"o-\", alpha=.9, label=\"val_loss\")\n",
    "plt.axhline(1, linestyle=\"--\", c=\"C2\")\n",
    "plt.legend()\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(models_nn[0].history.history[\"accuracy\"], \"o-\", alpha=.9, label=\"accuracy\")\n",
    "plt.plot(models_nn[0].history.history[\"val_accuracy\"], \"o-\", alpha=.9, label=\"val_accuracy\")\n",
    "plt.axhline(.7, linestyle=\"--\", c=\"C2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para percorrer todos os modelos e fazer previsoes\n",
    "def predict(x_te, models_nn):\n",
    "    \n",
    "    model_num_nn = len(models_nn)\n",
    "\n",
    "    for k,m in enumerate(models_nn):\n",
    "        if k==0:\n",
    "            y_pred_nn = m.predict_proba(x_te, batch_size=1024)[:,1]\n",
    "        else:\n",
    "            y_pred_nn += m.predict_proba(x_te, batch_size=1024)[:,1]\n",
    "            \n",
    "    y_pred_nn = y_pred_nn / model_num_nn\n",
    "    \n",
    "    return y_pred_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo todas as variaveis categoricas\n",
    "drop_features = []\n",
    "for col in test.columns:\n",
    "    if test[col].dtype =='object':\n",
    "        drop_features.append(col)\n",
    "\n",
    "new_test = test.drop(drop_features, axis=1)\n",
    "\n",
    "new_test.fillna(-999,inplace=True)\n",
    "new_test.drop(['ID'], axis=1, inplace=True)\n",
    "\n",
    "# Padronizando os dados (0 para a média, 1 para o desvio padrão)\n",
    "new_test = scaler.fit_transform(new_test)\n",
    "\n",
    "# Reshape para o padrao da LSTM\n",
    "new_test = np.asarray(np.reshape(new_test, (new_test.shape[0], seq_length, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando as previsoes\n",
    "pred_test = predict(new_test, models_nn)\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ID': test[\"ID\"], 'PredictedProb': pred_test.reshape((pred_test.shape[0]))})\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../submission/submission_lstm_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['PredictedProb'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(submission.PredictedProb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
