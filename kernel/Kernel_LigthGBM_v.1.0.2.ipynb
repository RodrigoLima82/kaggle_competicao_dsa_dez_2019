{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle\n",
    "## Competição DSA de Machine Learning - Dezembro 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versão 1.0.0: LB = 0.48866 CV = 0.463102\n",
    "- modelo: LightGBM (com algumas otimizações)\n",
    "- features engineering: gerado através do Auto_ViML\n",
    "\n",
    "Versão 1.0.1: LB = 0.48991 CV = 0.462946\n",
    "- modelo: LightGBM (com algumas otimizações)\n",
    "- features engineering: gerado através do Auto_ViML (com novas features)\n",
    "\n",
    "Versão 1.0.2: LB = ???? CV = 0.464442\n",
    "- modelo: LightGBM (com algumas otimizações)\n",
    "- features engineering: gerado através do Auto_ViML (com agrupamento pela coluna v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar os principais pacotes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "# Evitar que aparece os warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Seta algumas opções no Jupyter para exibição dos datasets\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# Variavel para controlar o treinamento no Kaggle\n",
    "TRAIN_OFFLINE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa os pacotes de algoritmos\n",
    "import lightgbm as lgb\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "\n",
    "# Importa pacotes do sklearn\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "#from sklearn.preprocessing import scale, MinMaxScaler, StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando os dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    if TRAIN_OFFLINE:\n",
    "        print('Carregando arquivo dataset_treino.csv....')\n",
    "        train = pd.read_csv('../dataset/dataset_treino_modificado_v2.csv')\n",
    "        print('dataset_treino.csv tem {} linhas and {} colunas'.format(train.shape[0], train.shape[1]))\n",
    "        \n",
    "        print('Carregando arquivo dataset_teste.csv....')\n",
    "        test = pd.read_csv('../dataset/dataset_teste_modificado_v2.csv')\n",
    "        print('dataset_teste.csv tem {} linhas and {} colunas'.format(test.shape[0], test.shape[1]))\n",
    "        \n",
    "    else:\n",
    "        print('Carregando arquivo dataset_treino.csv....')\n",
    "        train = pd.read_csv('/kaggle/input/competicao-dsa-machine-learning-dec-2019/dataset_treino.csv')\n",
    "        print('dataset_treino.csv tem {} linhas and {} colunas'.format(train.shape[0], train.shape[1]))\n",
    "        \n",
    "        print('Carregando arquivo dataset_treino.csv....')\n",
    "        test = pd.read_csv('/kaggle/input/competicao-dsa-machine-learning-dec-2019/dataset_teste.csv')\n",
    "        print('dataset_teste.csv tem {} linhas and {} colunas'.format(test.shape[0], test.shape[1]))\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando arquivo dataset_treino.csv....\n",
      "dataset_treino.csv tem 114321 linhas and 59 colunas\n",
      "Carregando arquivo dataset_teste.csv....\n",
      "dataset_teste.csv tem 114393 linhas and 66 colunas\n"
     ]
    }
   ],
   "source": [
    "# Leitura dos dados\n",
    "train, test = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo algumas colunas do dataset de test\n",
    "test = test[test.columns[:-8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntando os dois dataset (treino e teste)\n",
    "df = train.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>v105_mean</th>\n",
       "      <th>v105_median</th>\n",
       "      <th>v108_min</th>\n",
       "      <th>v10_bin</th>\n",
       "      <th>v110</th>\n",
       "      <th>v111_median</th>\n",
       "      <th>v111_min</th>\n",
       "      <th>v113</th>\n",
       "      <th>v119_min</th>\n",
       "      <th>v121_max</th>\n",
       "      <th>v121_median</th>\n",
       "      <th>v129</th>\n",
       "      <th>v20_median_bin</th>\n",
       "      <th>v24</th>\n",
       "      <th>v26_median_bin</th>\n",
       "      <th>v3</th>\n",
       "      <th>v30</th>\n",
       "      <th>v31</th>\n",
       "      <th>v34_bin</th>\n",
       "      <th>v34_max_bin</th>\n",
       "      <th>v34_min_bin</th>\n",
       "      <th>v38</th>\n",
       "      <th>v39_min_bin</th>\n",
       "      <th>v40_bin</th>\n",
       "      <th>v40_max_bin</th>\n",
       "      <th>v40_min</th>\n",
       "      <th>v41_max</th>\n",
       "      <th>v46_max</th>\n",
       "      <th>v47</th>\n",
       "      <th>v50_bin</th>\n",
       "      <th>v50_max</th>\n",
       "      <th>v51_min</th>\n",
       "      <th>v54_max</th>\n",
       "      <th>v55_max</th>\n",
       "      <th>v56</th>\n",
       "      <th>v62</th>\n",
       "      <th>v63_max</th>\n",
       "      <th>v64_max</th>\n",
       "      <th>v64_median</th>\n",
       "      <th>v66</th>\n",
       "      <th>v67_max</th>\n",
       "      <th>v69_median</th>\n",
       "      <th>v71</th>\n",
       "      <th>v73_max</th>\n",
       "      <th>v74</th>\n",
       "      <th>v76_mean</th>\n",
       "      <th>v76_min</th>\n",
       "      <th>v79</th>\n",
       "      <th>v81_min</th>\n",
       "      <th>v85_median</th>\n",
       "      <th>v85_min</th>\n",
       "      <th>v89_min</th>\n",
       "      <th>v92_max</th>\n",
       "      <th>v92_median</th>\n",
       "      <th>v93_max</th>\n",
       "      <th>v94_median</th>\n",
       "      <th>v97_median</th>\n",
       "      <th>v98_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433874</td>\n",
       "      <td>0.433874</td>\n",
       "      <td>0.087649</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0</td>\n",
       "      <td>4.362469e-02</td>\n",
       "      <td>0.193461</td>\n",
       "      <td>0.193461</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>151</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>170</td>\n",
       "      <td>113</td>\n",
       "      <td>0.461923</td>\n",
       "      <td>0.441124</td>\n",
       "      <td>0.530565</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>0.066833</td>\n",
       "      <td>0.371055</td>\n",
       "      <td>0.239243</td>\n",
       "      <td>0.103033</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.554319</td>\n",
       "      <td>0.231768</td>\n",
       "      <td>0.231768</td>\n",
       "      <td>0</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.403141</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082698</td>\n",
       "      <td>0.082698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.347083</td>\n",
       "      <td>0.233202</td>\n",
       "      <td>0.233202</td>\n",
       "      <td>0.234489</td>\n",
       "      <td>0.109197</td>\n",
       "      <td>0.109197</td>\n",
       "      <td>0.268864</td>\n",
       "      <td>0.243951</td>\n",
       "      <td>0.603015</td>\n",
       "      <td>0.269968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.053497</td>\n",
       "      <td>0.054048</td>\n",
       "      <td>0.024281</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.168266</td>\n",
       "      <td>0.168266</td>\n",
       "      <td>1</td>\n",
       "      <td>1.584485e-01</td>\n",
       "      <td>0.136880</td>\n",
       "      <td>0.136880</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>153</td>\n",
       "      <td>224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077978</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.317186</td>\n",
       "      <td>0.317186</td>\n",
       "      <td>1</td>\n",
       "      <td>0.464364</td>\n",
       "      <td>0.472467</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.120253</td>\n",
       "      <td>0.120253</td>\n",
       "      <td>1</td>\n",
       "      <td>0.122814</td>\n",
       "      <td>0.141113</td>\n",
       "      <td>0.141113</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.065260</td>\n",
       "      <td>0.065260</td>\n",
       "      <td>0.273759</td>\n",
       "      <td>0.202609</td>\n",
       "      <td>0.381128</td>\n",
       "      <td>0.032490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011025</td>\n",
       "      <td>0.011025</td>\n",
       "      <td>0.091884</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307095</td>\n",
       "      <td>0.307095</td>\n",
       "      <td>0</td>\n",
       "      <td>6.085414e-02</td>\n",
       "      <td>0.250472</td>\n",
       "      <td>0.250472</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>211</td>\n",
       "      <td>127</td>\n",
       "      <td>0.737386</td>\n",
       "      <td>0.319449</td>\n",
       "      <td>0.016759</td>\n",
       "      <td>2</td>\n",
       "      <td>375</td>\n",
       "      <td>0.103734</td>\n",
       "      <td>0.548206</td>\n",
       "      <td>0.012371</td>\n",
       "      <td>0.118602</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017624</td>\n",
       "      <td>0.165429</td>\n",
       "      <td>0.165429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.413343</td>\n",
       "      <td>0.435798</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150334</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054539</td>\n",
       "      <td>0.054539</td>\n",
       "      <td>2</td>\n",
       "      <td>0.450263</td>\n",
       "      <td>0.295019</td>\n",
       "      <td>0.295019</td>\n",
       "      <td>0.015960</td>\n",
       "      <td>0.054982</td>\n",
       "      <td>0.054982</td>\n",
       "      <td>0.201919</td>\n",
       "      <td>0.199744</td>\n",
       "      <td>0.263333</td>\n",
       "      <td>0.571295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053497</td>\n",
       "      <td>0.054048</td>\n",
       "      <td>0.024281</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.168266</td>\n",
       "      <td>0.168266</td>\n",
       "      <td>0</td>\n",
       "      <td>1.584485e-01</td>\n",
       "      <td>0.136880</td>\n",
       "      <td>0.136880</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>211</td>\n",
       "      <td>224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077978</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.317186</td>\n",
       "      <td>0.317186</td>\n",
       "      <td>2</td>\n",
       "      <td>0.464364</td>\n",
       "      <td>0.472467</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.120253</td>\n",
       "      <td>0.120253</td>\n",
       "      <td>3</td>\n",
       "      <td>0.122814</td>\n",
       "      <td>0.141113</td>\n",
       "      <td>0.141113</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.065260</td>\n",
       "      <td>0.065260</td>\n",
       "      <td>0.273759</td>\n",
       "      <td>0.202609</td>\n",
       "      <td>0.381128</td>\n",
       "      <td>0.032490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.089153</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.891533e-08</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>117</td>\n",
       "      <td>198</td>\n",
       "      <td>127</td>\n",
       "      <td>0.518561</td>\n",
       "      <td>0.401891</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>3</td>\n",
       "      <td>390</td>\n",
       "      <td>0.129998</td>\n",
       "      <td>0.328848</td>\n",
       "      <td>0.006728</td>\n",
       "      <td>0.056738</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.279553</td>\n",
       "      <td>0.279553</td>\n",
       "      <td>1</td>\n",
       "      <td>0.482270</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1</td>\n",
       "      <td>0.081699</td>\n",
       "      <td>1</td>\n",
       "      <td>0.093716</td>\n",
       "      <td>0.093716</td>\n",
       "      <td>4</td>\n",
       "      <td>0.405371</td>\n",
       "      <td>0.070313</td>\n",
       "      <td>0.070313</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.071066</td>\n",
       "      <td>0.071066</td>\n",
       "      <td>0.263183</td>\n",
       "      <td>0.155371</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.368675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  v105_mean  v105_median  v108_min  v10_bin  v110  v111_median  \\\n",
       "0     0.0   0.433874     0.433874  0.087649       46     0     0.305085   \n",
       "1     1.0   0.053497     0.054048  0.024281       58     0     0.168266   \n",
       "2     1.0   0.011025     0.011025  0.091884       58     0     0.307095   \n",
       "3     0.0   0.053497     0.054048  0.024281       35     0     0.168266   \n",
       "4     1.0   0.000471     0.000471  0.089153       52     1     0.198582   \n",
       "\n",
       "   v111_min  v113      v119_min  v121_max  v121_median  v129  v20_median_bin  \\\n",
       "0  0.305085     0  4.362469e-02  0.193461     0.193461     0             168   \n",
       "1  0.168266     1  1.584485e-01  0.136880     0.136880     0             140   \n",
       "2  0.307095     0  6.085414e-02  0.250472     0.250472     0              68   \n",
       "3  0.168266     0  1.584485e-01  0.136880     0.136880     0             140   \n",
       "4  0.198582    -1  6.891533e-08  0.115385     0.115385     0             171   \n",
       "\n",
       "   v24  v26_median_bin  v3  v30  v31  v34_bin  v34_max_bin  v34_min_bin  v38  \\\n",
       "0    0             186   0    0    0      163          151           84    0   \n",
       "1    1             158   0    1    0      197          195            0    0   \n",
       "2    2               3   0   -1    0       97           97           48    0   \n",
       "3    1             158   0   -1    0       97          195            0    0   \n",
       "4    0              12   0   -1    1      142          142           80    6   \n",
       "\n",
       "   v39_min_bin  v40_bin  v40_max_bin   v40_min   v41_max   v46_max  v47  \\\n",
       "0          228      170          113  0.461923  0.441124  0.530565    0   \n",
       "1          228      153          224  0.000000  0.359128  1.000000    1   \n",
       "2          228      211          127  0.737386  0.319449  0.016759    2   \n",
       "3          228      211          224  0.000000  0.359128  1.000000    1   \n",
       "4          117      198          127  0.518561  0.401891  0.001554    3   \n",
       "\n",
       "   v50_bin   v50_max   v51_min   v54_max   v55_max  v56  v62   v63_max  \\\n",
       "0      267  0.066833  0.371055  0.239243  0.103033    0    1  0.554319   \n",
       "1      390  1.000000  0.359908  1.000000  0.077978    1    1  1.000000   \n",
       "2      375  0.103734  0.548206  0.012371  0.118602    2    1  0.017624   \n",
       "3       27  1.000000  0.359908  1.000000  0.077978   -1    2  1.000000   \n",
       "4      390  0.129998  0.328848  0.006728  0.056738    3    0  0.003511   \n",
       "\n",
       "    v64_max  v64_median  v66   v67_max  v69_median  v71   v73_max  v74  \\\n",
       "0  0.231768    0.231768    0  0.578947    0.403141    0  0.140440    0   \n",
       "1  0.317186    0.317186    1  0.464364    0.472467    1  0.121665    0   \n",
       "2  0.165429    0.165429    0  0.413343    0.435798    1  0.150334    0   \n",
       "3  0.317186    0.317186    2  0.464364    0.472467    1  0.121665    0   \n",
       "4  0.279553    0.279553    1  0.482270    0.363636    1  0.081699    1   \n",
       "\n",
       "   v76_mean   v76_min  v79   v81_min  v85_median   v85_min   v89_min  \\\n",
       "0  0.082698  0.082698    0  0.347083    0.233202  0.233202  0.234489   \n",
       "1  0.120253  0.120253    1  0.122814    0.141113  0.141113  0.001503   \n",
       "2  0.054539  0.054539    2  0.450263    0.295019  0.295019  0.015960   \n",
       "3  0.120253  0.120253    3  0.122814    0.141113  0.141113  0.001503   \n",
       "4  0.093716  0.093716    4  0.405371    0.070313  0.070313  0.001603   \n",
       "\n",
       "    v92_max  v92_median   v93_max  v94_median  v97_median   v98_min  \n",
       "0  0.109197    0.109197  0.268864    0.243951    0.603015  0.269968  \n",
       "1  0.065260    0.065260  0.273759    0.202609    0.381128  0.032490  \n",
       "2  0.054982    0.054982  0.201919    0.199744    0.263333  0.571295  \n",
       "3  0.065260    0.065260  0.273759    0.202609    0.381128  0.032490  \n",
       "4  0.071066    0.071066  0.263183    0.155371    0.333333  0.368675  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo LigthGBM com Hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>loss</td>\n",
       "      <td>0.263423</td>\n",
       "      <td>0.26411</td>\n",
       "      <td>0.264141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iteration</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>train_time</td>\n",
       "      <td>1.99563</td>\n",
       "      <td>0.874582</td>\n",
       "      <td>0.860642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>status</td>\n",
       "      <td>ok</td>\n",
       "      <td>ok</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hyperparameters.boosting_type</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hyperparameters.colsample_bytree</td>\n",
       "      <td>0.881783</td>\n",
       "      <td>0.972798</td>\n",
       "      <td>0.895936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hyperparameters.is_unbalance</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hyperparameters.learning_rate</td>\n",
       "      <td>0.0129388</td>\n",
       "      <td>0.0408052</td>\n",
       "      <td>0.0361298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hyperparameters.min_child_samples</td>\n",
       "      <td>315</td>\n",
       "      <td>450</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hyperparameters.num_leaves</td>\n",
       "      <td>139</td>\n",
       "      <td>48</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hyperparameters.reg_alpha</td>\n",
       "      <td>0.484807</td>\n",
       "      <td>0.53263</td>\n",
       "      <td>0.67764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hyperparameters.reg_lambda</td>\n",
       "      <td>0.515065</td>\n",
       "      <td>0.651517</td>\n",
       "      <td>0.635415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hyperparameters.subsample_for_bin</td>\n",
       "      <td>280000</td>\n",
       "      <td>60000</td>\n",
       "      <td>280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hyperparameters.subsample</td>\n",
       "      <td>0.635119</td>\n",
       "      <td>0.61263</td>\n",
       "      <td>0.681794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hyperparameters.n_estimators</td>\n",
       "      <td>255</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0          1          2\n",
       "loss                                0.263423    0.26411   0.264141\n",
       "iteration                                 17         15          2\n",
       "train_time                           1.99563   0.874582   0.860642\n",
       "status                                    ok         ok         ok\n",
       "hyperparameters.boosting_type           gbdt       gbdt       gbdt\n",
       "hyperparameters.colsample_bytree    0.881783   0.972798   0.895936\n",
       "hyperparameters.is_unbalance            True       True       True\n",
       "hyperparameters.learning_rate      0.0129388  0.0408052  0.0361298\n",
       "hyperparameters.min_child_samples        315        450        415\n",
       "hyperparameters.num_leaves               139         48         87\n",
       "hyperparameters.reg_alpha           0.484807    0.53263    0.67764\n",
       "hyperparameters.reg_lambda          0.515065   0.651517   0.635415\n",
       "hyperparameters.subsample_for_bin     280000      60000     280000\n",
       "hyperparameters.subsample           0.635119    0.61263   0.681794\n",
       "hyperparameters.n_estimators             255         85         86"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buscando os melhores parametros\n",
    "# Utilizei o Hyperopt para otimizacao e o metodo Bayesian Optimization Primer\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "with open('trials.json') as file_data:\n",
    "    trial_json = json.load(file_data)\n",
    "\n",
    "data = json_normalize(trial_json)\n",
    "data.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LIGHTGBM_PARAMS = {\\n    'boosting_type': 'goss',\\n    'n_estimators': 10000,\\n    'learning_rate': 0.005134,\\n    'num_leaves': 54,\\n    'max_depth': 10,\\n    'subsample_for_bin': 240000,\\n    'reg_alpha': 0.436193,\\n    'reg_lambda': 0.479169,\\n    'colsample_bytree': 0.508716,\\n    'min_split_gain': 0.024766,\\n    'subsample': 1,\\n    'is_unbalance': False,\\n    'silent':-1,\\n    'verbose':-1\\n}\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configurações Gerais\n",
    "\n",
    "GENERATE_SUBMISSION_FILES = True\n",
    "SUBMISSION_SUFIX = \"_lgbm_v.1.0.2\"\n",
    "STRATIFIED_KFOLD = False\n",
    "RANDOM_SEED = np.random.seed(737851)\n",
    "NUM_THREADS = 4\n",
    "NUM_FOLDS = 10\n",
    "EARLY_STOPPING = 100\n",
    "\n",
    "# Selecionando os melhores parametros\n",
    "LIGHTGBM_PARAMS: {'boosting_type': 'gbdt', \n",
    "                  'colsample_bytree': 0.881783, \n",
    "                  'is_unbalance': False, \n",
    "                  'learning_rate': 0.0129388, \n",
    "                  'min_child_samples': 315, \n",
    "                  'num_leaves': 139, \n",
    "                  'reg_alpha': 0.484807, \n",
    "                  'reg_lambda': 0.515065, \n",
    "                  'subsample_for_bin': 280000, \n",
    "                  'subsample': 0.635119, \n",
    "                  'n_estimators': 10000\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- LIGHTGBM MODEL -------------------------\n",
    "# Funcao para processar todo o pipeline do treinamento e gerar a submissao\n",
    "def run_model(data, categorical_feature = None):\n",
    "    df = data[data['target'].notnull()]\n",
    "    test = data[data['target'].isnull()]\n",
    "    del_features = ['target']\n",
    "    predictors = list(filter(lambda v: v not in del_features, df.columns))\n",
    "    \n",
    "    print(\"Train/valid shape: {}, test shape: {}\".format(df.shape, test.shape))\n",
    "\n",
    "    if not STRATIFIED_KFOLD:\n",
    "        folds = KFold(n_splits= NUM_FOLDS, shuffle=True, random_state= RANDOM_SEED)\n",
    "    else:\n",
    "        folds = StratifiedKFold(n_splits= NUM_FOLDS, shuffle=True, random_state= RANDOM_SEED)\n",
    "\n",
    "    # Hold oof predictions, test predictions, feature importance and training/valid auc\n",
    "    oof_preds = np.zeros(df.shape[0])\n",
    "    sub_preds = np.zeros(test.shape[0])\n",
    "    importance_df = pd.DataFrame()\n",
    "    eval_results = dict()\n",
    "\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(df[predictors], df['target'])):\n",
    "        train_x, train_y = df[predictors].iloc[train_idx], df['target'].iloc[train_idx]\n",
    "        valid_x, valid_y = df[predictors].iloc[valid_idx], df['target'].iloc[valid_idx]\n",
    "\n",
    "        params = {'random_state': RANDOM_SEED, 'nthread': NUM_THREADS}\n",
    "        \n",
    "        clf = LGBMClassifier(**{**params, **LIGHTGBM_PARAMS})\n",
    "        \n",
    "        if not categorical_feature:\n",
    "            clf.fit(train_x, train_y, \n",
    "                    eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                    eval_metric='logloss', \n",
    "                    verbose=400, \n",
    "                    early_stopping_rounds= EARLY_STOPPING)\n",
    "        else:\n",
    "            clf.fit(train_x, train_y, \n",
    "                    eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                    eval_metric='logloss', \n",
    "                    verbose=400, \n",
    "                    early_stopping_rounds=EARLY_STOPPING,\n",
    "                    feature_name= list(df[predictors].columns), \n",
    "                    categorical_feature= categorical_feature)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test[predictors], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        # Feature importance by GAIN and SPLIT\n",
    "        fold_importance = pd.DataFrame()\n",
    "        fold_importance[\"feature\"] = predictors\n",
    "        fold_importance[\"gain\"] = clf.booster_.feature_importance(importance_type='gain')\n",
    "        fold_importance[\"split\"] = clf.booster_.feature_importance(importance_type='split')\n",
    "        importance_df = pd.concat([importance_df, fold_importance], axis=0)\n",
    "        eval_results['train_{}'.format(n_fold+1)]  = clf.evals_result_['training']['binary_logloss']\n",
    "        eval_results['valid_{}'.format(n_fold+1)] = clf.evals_result_['valid_1']['binary_logloss']\n",
    "\n",
    "        print('Fold %2d Log Loss : %.6f' % (n_fold + 1, log_loss(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full Log Loss score %.6f' % log_loss(df['target'], oof_preds))\n",
    "    test['target'] = sub_preds.copy()\n",
    "\n",
    "    # Get the average feature importance between folds\n",
    "    mean_importance = importance_df.groupby('feature').mean().reset_index()\n",
    "    mean_importance.sort_values(by= 'gain', ascending=False, inplace=True)\n",
    "    \n",
    "    # Save feature importance, test predictions and oof predictions as csv\n",
    "    if GENERATE_SUBMISSION_FILES:\n",
    "\n",
    "        # Save submission (test data) and feature importance\n",
    "        submission = pd.read_csv('../dataset/sample_submission.csv')\n",
    "        submission['PredictedProb'] = sub_preds.copy()\n",
    "        submission.to_csv('../submission/submission{}.csv'.format(SUBMISSION_SUFIX), index=False)\n",
    "        \n",
    "        mean_importance.to_csv('feature_importance{}.csv'.format(SUBMISSION_SUFIX), index=False)\n",
    "        plt.hist(submission.PredictedProb)\n",
    "        plt.show()\n",
    "    \n",
    "    return mean_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/valid shape: (114321, 59), test shape: (114393, 59)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.470441\tvalid_1's binary_logloss: 0.482471\n",
      "[800]\ttraining's binary_logloss: 0.455049\tvalid_1's binary_logloss: 0.475194\n",
      "[1200]\ttraining's binary_logloss: 0.445318\tvalid_1's binary_logloss: 0.472863\n",
      "[1600]\ttraining's binary_logloss: 0.437121\tvalid_1's binary_logloss: 0.471791\n",
      "[2000]\ttraining's binary_logloss: 0.429802\tvalid_1's binary_logloss: 0.471196\n",
      "[2400]\ttraining's binary_logloss: 0.42309\tvalid_1's binary_logloss: 0.470535\n",
      "Early stopping, best iteration is:\n",
      "[2461]\ttraining's binary_logloss: 0.422099\tvalid_1's binary_logloss: 0.470458\n",
      "Fold  1 Log Loss : 0.470458\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.470424\tvalid_1's binary_logloss: 0.479882\n",
      "[800]\ttraining's binary_logloss: 0.4551\tvalid_1's binary_logloss: 0.472734\n",
      "[1200]\ttraining's binary_logloss: 0.445393\tvalid_1's binary_logloss: 0.470888\n",
      "[1600]\ttraining's binary_logloss: 0.437243\tvalid_1's binary_logloss: 0.469846\n",
      "[2000]\ttraining's binary_logloss: 0.429783\tvalid_1's binary_logloss: 0.468962\n",
      "[2400]\ttraining's binary_logloss: 0.423031\tvalid_1's binary_logloss: 0.468562\n",
      "[2800]\ttraining's binary_logloss: 0.416677\tvalid_1's binary_logloss: 0.468256\n",
      "Early stopping, best iteration is:\n",
      "[3015]\ttraining's binary_logloss: 0.413478\tvalid_1's binary_logloss: 0.468101\n",
      "Fold  2 Log Loss : 0.468101\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.47193\tvalid_1's binary_logloss: 0.469214\n",
      "[800]\ttraining's binary_logloss: 0.456561\tvalid_1's binary_logloss: 0.46226\n",
      "[1200]\ttraining's binary_logloss: 0.446723\tvalid_1's binary_logloss: 0.460303\n",
      "[1600]\ttraining's binary_logloss: 0.438521\tvalid_1's binary_logloss: 0.458981\n",
      "[2000]\ttraining's binary_logloss: 0.431193\tvalid_1's binary_logloss: 0.458368\n",
      "[2400]\ttraining's binary_logloss: 0.424462\tvalid_1's binary_logloss: 0.457727\n",
      "[2800]\ttraining's binary_logloss: 0.418205\tvalid_1's binary_logloss: 0.457251\n",
      "[3200]\ttraining's binary_logloss: 0.412375\tvalid_1's binary_logloss: 0.456882\n",
      "Early stopping, best iteration is:\n",
      "[3478]\ttraining's binary_logloss: 0.408487\tvalid_1's binary_logloss: 0.456724\n",
      "Fold  3 Log Loss : 0.456724\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.470276\tvalid_1's binary_logloss: 0.482121\n",
      "[800]\ttraining's binary_logloss: 0.454851\tvalid_1's binary_logloss: 0.474903\n",
      "[1200]\ttraining's binary_logloss: 0.445161\tvalid_1's binary_logloss: 0.472647\n",
      "[1600]\ttraining's binary_logloss: 0.437076\tvalid_1's binary_logloss: 0.471415\n",
      "[2000]\ttraining's binary_logloss: 0.429742\tvalid_1's binary_logloss: 0.470548\n",
      "[2400]\ttraining's binary_logloss: 0.422876\tvalid_1's binary_logloss: 0.469812\n",
      "Early stopping, best iteration is:\n",
      "[2676]\ttraining's binary_logloss: 0.418504\tvalid_1's binary_logloss: 0.469561\n",
      "Fold  4 Log Loss : 0.469561\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.470532\tvalid_1's binary_logloss: 0.481809\n",
      "[800]\ttraining's binary_logloss: 0.455236\tvalid_1's binary_logloss: 0.473872\n",
      "[1200]\ttraining's binary_logloss: 0.445516\tvalid_1's binary_logloss: 0.471457\n",
      "[1600]\ttraining's binary_logloss: 0.437391\tvalid_1's binary_logloss: 0.470175\n",
      "[2000]\ttraining's binary_logloss: 0.429991\tvalid_1's binary_logloss: 0.469264\n",
      "[2400]\ttraining's binary_logloss: 0.423173\tvalid_1's binary_logloss: 0.468564\n",
      "[2800]\ttraining's binary_logloss: 0.416855\tvalid_1's binary_logloss: 0.468113\n",
      "[3200]\ttraining's binary_logloss: 0.410881\tvalid_1's binary_logloss: 0.467652\n",
      "[3600]\ttraining's binary_logloss: 0.405365\tvalid_1's binary_logloss: 0.467274\n",
      "Early stopping, best iteration is:\n",
      "[3842]\ttraining's binary_logloss: 0.40213\tvalid_1's binary_logloss: 0.467182\n",
      "Fold  5 Log Loss : 0.467182\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.471258\tvalid_1's binary_logloss: 0.474336\n",
      "[800]\ttraining's binary_logloss: 0.455972\tvalid_1's binary_logloss: 0.466339\n",
      "[1200]\ttraining's binary_logloss: 0.446452\tvalid_1's binary_logloss: 0.464008\n",
      "[1600]\ttraining's binary_logloss: 0.438339\tvalid_1's binary_logloss: 0.462481\n",
      "[2000]\ttraining's binary_logloss: 0.431011\tvalid_1's binary_logloss: 0.461384\n",
      "[2400]\ttraining's binary_logloss: 0.424324\tvalid_1's binary_logloss: 0.460668\n",
      "[2800]\ttraining's binary_logloss: 0.418047\tvalid_1's binary_logloss: 0.460031\n",
      "[3200]\ttraining's binary_logloss: 0.41218\tvalid_1's binary_logloss: 0.459534\n",
      "[3600]\ttraining's binary_logloss: 0.406655\tvalid_1's binary_logloss: 0.458912\n",
      "[4000]\ttraining's binary_logloss: 0.401415\tvalid_1's binary_logloss: 0.458644\n",
      "Early stopping, best iteration is:\n",
      "[4039]\ttraining's binary_logloss: 0.400921\tvalid_1's binary_logloss: 0.458577\n",
      "Fold  6 Log Loss : 0.458577\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.47137\tvalid_1's binary_logloss: 0.474698\n",
      "[800]\ttraining's binary_logloss: 0.456178\tvalid_1's binary_logloss: 0.465975\n",
      "[1200]\ttraining's binary_logloss: 0.446383\tvalid_1's binary_logloss: 0.463124\n",
      "[1600]\ttraining's binary_logloss: 0.438275\tvalid_1's binary_logloss: 0.461882\n",
      "[2000]\ttraining's binary_logloss: 0.430899\tvalid_1's binary_logloss: 0.461147\n",
      "[2400]\ttraining's binary_logloss: 0.424078\tvalid_1's binary_logloss: 0.460329\n",
      "[2800]\ttraining's binary_logloss: 0.417834\tvalid_1's binary_logloss: 0.459662\n",
      "Early stopping, best iteration is:\n",
      "[3077]\ttraining's binary_logloss: 0.413689\tvalid_1's binary_logloss: 0.459276\n",
      "Fold  7 Log Loss : 0.459276\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.470503\tvalid_1's binary_logloss: 0.480673\n",
      "[800]\ttraining's binary_logloss: 0.455058\tvalid_1's binary_logloss: 0.472662\n",
      "[1200]\ttraining's binary_logloss: 0.445331\tvalid_1's binary_logloss: 0.470512\n",
      "[1600]\ttraining's binary_logloss: 0.437162\tvalid_1's binary_logloss: 0.469363\n",
      "[2000]\ttraining's binary_logloss: 0.429768\tvalid_1's binary_logloss: 0.468623\n",
      "[2400]\ttraining's binary_logloss: 0.422988\tvalid_1's binary_logloss: 0.467957\n",
      "[2800]\ttraining's binary_logloss: 0.416788\tvalid_1's binary_logloss: 0.467544\n",
      "Early stopping, best iteration is:\n",
      "[2950]\ttraining's binary_logloss: 0.414522\tvalid_1's binary_logloss: 0.46737\n",
      "Fold  8 Log Loss : 0.467370\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.470486\tvalid_1's binary_logloss: 0.479142\n",
      "[800]\ttraining's binary_logloss: 0.45476\tvalid_1's binary_logloss: 0.472671\n",
      "[1200]\ttraining's binary_logloss: 0.445086\tvalid_1's binary_logloss: 0.471062\n",
      "[1600]\ttraining's binary_logloss: 0.436855\tvalid_1's binary_logloss: 0.470126\n",
      "[2000]\ttraining's binary_logloss: 0.429347\tvalid_1's binary_logloss: 0.469627\n",
      "[2400]\ttraining's binary_logloss: 0.422577\tvalid_1's binary_logloss: 0.469279\n",
      "Early stopping, best iteration is:\n",
      "[2553]\ttraining's binary_logloss: 0.420155\tvalid_1's binary_logloss: 0.4691\n",
      "Fold  9 Log Loss : 0.469100\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.471309\tvalid_1's binary_logloss: 0.473107\n",
      "[800]\ttraining's binary_logloss: 0.456006\tvalid_1's binary_logloss: 0.465408\n",
      "[1200]\ttraining's binary_logloss: 0.446343\tvalid_1's binary_logloss: 0.462731\n",
      "[1600]\ttraining's binary_logloss: 0.438163\tvalid_1's binary_logloss: 0.461267\n",
      "[2000]\ttraining's binary_logloss: 0.430869\tvalid_1's binary_logloss: 0.460244\n",
      "[2400]\ttraining's binary_logloss: 0.42416\tvalid_1's binary_logloss: 0.459388\n",
      "[2800]\ttraining's binary_logloss: 0.417795\tvalid_1's binary_logloss: 0.458992\n",
      "[3200]\ttraining's binary_logloss: 0.411831\tvalid_1's binary_logloss: 0.458744\n",
      "[3600]\ttraining's binary_logloss: 0.406293\tvalid_1's binary_logloss: 0.458283\n",
      "[4000]\ttraining's binary_logloss: 0.401029\tvalid_1's binary_logloss: 0.458139\n",
      "Early stopping, best iteration is:\n",
      "[4080]\ttraining's binary_logloss: 0.400067\tvalid_1's binary_logloss: 0.458069\n",
      "Fold 10 Log Loss : 0.458069\n",
      "Full Log Loss score 0.464442\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>v50_bin</td>\n",
       "      <td>869799.033019</td>\n",
       "      <td>9639.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>v66</td>\n",
       "      <td>255882.758619</td>\n",
       "      <td>3050.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>v56</td>\n",
       "      <td>226627.105562</td>\n",
       "      <td>6335.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>v50_max</td>\n",
       "      <td>193771.280479</td>\n",
       "      <td>4525.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>v10_bin</td>\n",
       "      <td>182036.239951</td>\n",
       "      <td>5515.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>v40_bin</td>\n",
       "      <td>145499.201866</td>\n",
       "      <td>4301.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>v31</td>\n",
       "      <td>137965.984701</td>\n",
       "      <td>819.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>v69_median</td>\n",
       "      <td>131598.713927</td>\n",
       "      <td>4615.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>v73_max</td>\n",
       "      <td>130512.278291</td>\n",
       "      <td>4625.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>v119_min</td>\n",
       "      <td>129134.655203</td>\n",
       "      <td>4518.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>v94_median</td>\n",
       "      <td>125556.380953</td>\n",
       "      <td>4442.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>v85_median</td>\n",
       "      <td>124592.393747</td>\n",
       "      <td>4423.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>v97_median</td>\n",
       "      <td>124307.738771</td>\n",
       "      <td>4381.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>v92_max</td>\n",
       "      <td>122880.394163</td>\n",
       "      <td>4368.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>v34_bin</td>\n",
       "      <td>122321.248813</td>\n",
       "      <td>3489.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>v40_min</td>\n",
       "      <td>117826.595671</td>\n",
       "      <td>4031.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>v67_max</td>\n",
       "      <td>114098.497380</td>\n",
       "      <td>4012.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>v98_min</td>\n",
       "      <td>113617.346067</td>\n",
       "      <td>3932.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>v111_median</td>\n",
       "      <td>111101.964412</td>\n",
       "      <td>3911.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>v41_max</td>\n",
       "      <td>109315.640546</td>\n",
       "      <td>3838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>v55_max</td>\n",
       "      <td>109242.220954</td>\n",
       "      <td>3844.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>v51_min</td>\n",
       "      <td>109178.190673</td>\n",
       "      <td>3780.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>v121_max</td>\n",
       "      <td>104176.647588</td>\n",
       "      <td>3677.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>v108_min</td>\n",
       "      <td>102984.079534</td>\n",
       "      <td>3573.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>v81_min</td>\n",
       "      <td>100337.423765</td>\n",
       "      <td>3522.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>v113</td>\n",
       "      <td>99661.665501</td>\n",
       "      <td>3417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>v110</td>\n",
       "      <td>98789.498247</td>\n",
       "      <td>1038.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>v93_max</td>\n",
       "      <td>97059.084291</td>\n",
       "      <td>3390.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>v79</td>\n",
       "      <td>95871.687239</td>\n",
       "      <td>2573.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>v89_min</td>\n",
       "      <td>94524.951977</td>\n",
       "      <td>3316.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>v105_mean</td>\n",
       "      <td>89752.096162</td>\n",
       "      <td>3177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>v129</td>\n",
       "      <td>86757.848791</td>\n",
       "      <td>1172.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>v64_max</td>\n",
       "      <td>83453.137020</td>\n",
       "      <td>2912.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>v76_mean</td>\n",
       "      <td>83311.227433</td>\n",
       "      <td>2911.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>v54_max</td>\n",
       "      <td>83181.774028</td>\n",
       "      <td>2879.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>v46_max</td>\n",
       "      <td>81880.182026</td>\n",
       "      <td>2849.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>v63_max</td>\n",
       "      <td>76599.177045</td>\n",
       "      <td>2647.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>v24</td>\n",
       "      <td>74196.067553</td>\n",
       "      <td>2408.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>v47</td>\n",
       "      <td>60645.238341</td>\n",
       "      <td>1474.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>v85_min</td>\n",
       "      <td>60626.481460</td>\n",
       "      <td>2153.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>v105_median</td>\n",
       "      <td>60457.453568</td>\n",
       "      <td>2123.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>v92_median</td>\n",
       "      <td>58870.408261</td>\n",
       "      <td>2075.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>v26_median_bin</td>\n",
       "      <td>55458.576774</td>\n",
       "      <td>2009.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>v30</td>\n",
       "      <td>54815.894616</td>\n",
       "      <td>1895.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>v111_min</td>\n",
       "      <td>53766.037123</td>\n",
       "      <td>1899.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>v121_median</td>\n",
       "      <td>51407.653613</td>\n",
       "      <td>1783.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>v39_min_bin</td>\n",
       "      <td>45452.350295</td>\n",
       "      <td>1642.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>v34_max_bin</td>\n",
       "      <td>41694.693912</td>\n",
       "      <td>1446.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>v20_median_bin</td>\n",
       "      <td>41553.645148</td>\n",
       "      <td>1529.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>v64_median</td>\n",
       "      <td>40683.152790</td>\n",
       "      <td>1421.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>v76_min</td>\n",
       "      <td>39539.575541</td>\n",
       "      <td>1378.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>v62</td>\n",
       "      <td>36204.137087</td>\n",
       "      <td>1011.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>v40_max_bin</td>\n",
       "      <td>35497.277113</td>\n",
       "      <td>1242.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>v34_min_bin</td>\n",
       "      <td>34441.064874</td>\n",
       "      <td>1182.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>v38</td>\n",
       "      <td>33753.339740</td>\n",
       "      <td>931.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>v71</td>\n",
       "      <td>27569.784227</td>\n",
       "      <td>966.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>v74</td>\n",
       "      <td>9487.222575</td>\n",
       "      <td>332.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>v3</td>\n",
       "      <td>3346.212391</td>\n",
       "      <td>108.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature           gain   split\n",
       "29         v50_bin  869799.033019  9639.4\n",
       "39             v66  255882.758619  3050.6\n",
       "34             v56  226627.105562  6335.9\n",
       "30         v50_max  193771.280479  4525.4\n",
       "3          v10_bin  182036.239951  5515.2\n",
       "23         v40_bin  145499.201866  4301.8\n",
       "17             v31  137965.984701   819.7\n",
       "41      v69_median  131598.713927  4615.0\n",
       "43         v73_max  130512.278291  4625.2\n",
       "8         v119_min  129134.655203  4518.7\n",
       "55      v94_median  125556.380953  4442.4\n",
       "49      v85_median  124592.393747  4423.1\n",
       "56      v97_median  124307.738771  4381.4\n",
       "52         v92_max  122880.394163  4368.9\n",
       "18         v34_bin  122321.248813  3489.7\n",
       "25         v40_min  117826.595671  4031.6\n",
       "40         v67_max  114098.497380  4012.7\n",
       "57         v98_min  113617.346067  3932.4\n",
       "5      v111_median  111101.964412  3911.8\n",
       "26         v41_max  109315.640546  3838.0\n",
       "33         v55_max  109242.220954  3844.9\n",
       "31         v51_min  109178.190673  3780.1\n",
       "9         v121_max  104176.647588  3677.7\n",
       "2         v108_min  102984.079534  3573.0\n",
       "48         v81_min  100337.423765  3522.5\n",
       "7             v113   99661.665501  3417.0\n",
       "4             v110   98789.498247  1038.5\n",
       "54         v93_max   97059.084291  3390.2\n",
       "47             v79   95871.687239  2573.2\n",
       "51         v89_min   94524.951977  3316.4\n",
       "0        v105_mean   89752.096162  3177.0\n",
       "11            v129   86757.848791  1172.6\n",
       "37         v64_max   83453.137020  2912.8\n",
       "45        v76_mean   83311.227433  2911.7\n",
       "32         v54_max   83181.774028  2879.6\n",
       "27         v46_max   81880.182026  2849.6\n",
       "36         v63_max   76599.177045  2647.9\n",
       "13             v24   74196.067553  2408.7\n",
       "28             v47   60645.238341  1474.3\n",
       "50         v85_min   60626.481460  2153.4\n",
       "1      v105_median   60457.453568  2123.9\n",
       "53      v92_median   58870.408261  2075.2\n",
       "14  v26_median_bin   55458.576774  2009.8\n",
       "16             v30   54815.894616  1895.0\n",
       "6         v111_min   53766.037123  1899.6\n",
       "10     v121_median   51407.653613  1783.2\n",
       "22     v39_min_bin   45452.350295  1642.1\n",
       "19     v34_max_bin   41694.693912  1446.1\n",
       "12  v20_median_bin   41553.645148  1529.1\n",
       "38      v64_median   40683.152790  1421.6\n",
       "46         v76_min   39539.575541  1378.4\n",
       "35             v62   36204.137087  1011.9\n",
       "24     v40_max_bin   35497.277113  1242.5\n",
       "20     v34_min_bin   34441.064874  1182.1\n",
       "21             v38   33753.339740   931.6\n",
       "42             v71   27569.784227   966.6\n",
       "44             v74    9487.222575   332.7\n",
       "15              v3    3346.212391   108.2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03f293c5aaf34fd7a50a3b2bf14dab7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0af695c1d5e24a17b3a2aebc133ddd39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6782fd7c22664c55904d66122a64843b",
        "IPY_MODEL_9163f58ecd4f4a84922abc60cc69d789"
       ],
       "layout": "IPY_MODEL_d8264eeec6af442097559d8923081902"
      }
     },
     "1c88767c318e4d86a9ab43245f5daa77": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "219092655bed428f83aeb751ccaa2a4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "44521ec2de994d5186cdf7d1e445d158": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6782fd7c22664c55904d66122a64843b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c5e6acfe3f654e7ca86e4cddf862e984",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_219092655bed428f83aeb751ccaa2a4d",
       "value": 1000
      }
     },
     "9163f58ecd4f4a84922abc60cc69d789": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9a5c32201e5c447b829c604d757794df",
       "placeholder": "​",
       "style": "IPY_MODEL_b90e11ceb23b4a84a2f4908689dff66f",
       "value": " 1000/1000 [01:50&lt;00:00,  9.06it/s]"
      }
     },
     "9a5c32201e5c447b829c604d757794df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a8bfc018378d49efa1570fcb43b496f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b90e11ceb23b4a84a2f4908689dff66f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c5e6acfe3f654e7ca86e4cddf862e984": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c95734415f404758ba787c86b58e7cc2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d0cb9d8667c340c4b49fb7cf32acaf7c",
        "IPY_MODEL_e1aabb08150346cc9871c9f6b3bb5d36"
       ],
       "layout": "IPY_MODEL_1c88767c318e4d86a9ab43245f5daa77"
      }
     },
     "d0cb9d8667c340c4b49fb7cf32acaf7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_44521ec2de994d5186cdf7d1e445d158",
       "max": 17000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_eec34a1f17e2477fb10e7c11419a1382",
       "value": 17000
      }
     },
     "d8264eeec6af442097559d8923081902": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e1aabb08150346cc9871c9f6b3bb5d36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a8bfc018378d49efa1570fcb43b496f3",
       "placeholder": "​",
       "style": "IPY_MODEL_03f293c5aaf34fd7a50a3b2bf14dab7d",
       "value": " 17000/17000 [11:01&lt;00:00, 25.68it/s]"
      }
     },
     "eec34a1f17e2477fb10e7c11419a1382": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
