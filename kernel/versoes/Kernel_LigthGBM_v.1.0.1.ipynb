{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle\n",
    "## Competição DSA de Machine Learning - Dezembro 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versão 1.0.0: LB = 0.48866 CV = 0.463102\n",
    "- modelo: LightGBM (com algumas otimizações)\n",
    "- features engineering: gerado através do Auto_ViML\n",
    "\n",
    "Versão 1.0.1: LB = 0.48991 CV = 0.462946\n",
    "- modelo: LightGBM (com algumas otimizações)\n",
    "- features engineering: gerado através do Auto_ViML (com novas features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar os principais pacotes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "# Evitar que aparece os warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Seta algumas opções no Jupyter para exibição dos datasets\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# Variavel para controlar o treinamento no Kaggle\n",
    "TRAIN_OFFLINE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa os pacotes de algoritmos\n",
    "import lightgbm as lgb\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "\n",
    "# Importa pacotes do sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, log_loss\n",
    "from sklearn.preprocessing import scale, MinMaxScaler, StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregando os dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    if TRAIN_OFFLINE:\n",
    "        print('Carregando arquivo dataset_treino.csv....')\n",
    "        train = pd.read_csv('../dataset/dataset_treino_reduce.csv')\n",
    "        print('dataset_treino.csv tem {} linhas and {} colunas'.format(train.shape[0], train.shape[1]))\n",
    "        \n",
    "        print('Carregando arquivo dataset_teste.csv....')\n",
    "        test = pd.read_csv('../dataset/dataset_teste_reduce.csv')\n",
    "        print('dataset_teste.csv tem {} linhas and {} colunas'.format(test.shape[0], test.shape[1]))\n",
    "        \n",
    "    else:\n",
    "        print('Carregando arquivo dataset_treino.csv....')\n",
    "        train = pd.read_csv('/kaggle/input/competicao-dsa-machine-learning-dec-2019/dataset_treino.csv')\n",
    "        print('dataset_treino.csv tem {} linhas and {} colunas'.format(train.shape[0], train.shape[1]))\n",
    "        \n",
    "        print('Carregando arquivo dataset_treino.csv....')\n",
    "        test = pd.read_csv('/kaggle/input/competicao-dsa-machine-learning-dec-2019/dataset_teste.csv')\n",
    "        print('dataset_teste.csv tem {} linhas and {} colunas'.format(test.shape[0], test.shape[1]))\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando arquivo dataset_treino.csv....\n",
      "dataset_treino.csv tem 114321 linhas and 47 colunas\n",
      "Carregando arquivo dataset_teste.csv....\n",
      "dataset_teste.csv tem 114393 linhas and 49 colunas\n"
     ]
    }
   ],
   "source": [
    "# Leitura dos dados\n",
    "train, test = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v31</th>\n",
       "      <th>v50</th>\n",
       "      <th>v110</th>\n",
       "      <th>v66</th>\n",
       "      <th>v129</th>\n",
       "      <th>v79</th>\n",
       "      <th>v47</th>\n",
       "      <th>v62</th>\n",
       "      <th>v56</th>\n",
       "      <th>v38</th>\n",
       "      <th>v74</th>\n",
       "      <th>v71</th>\n",
       "      <th>v24</th>\n",
       "      <th>v113</th>\n",
       "      <th>v3</th>\n",
       "      <th>v72</th>\n",
       "      <th>v30</th>\n",
       "      <th>v70</th>\n",
       "      <th>v57</th>\n",
       "      <th>v88</th>\n",
       "      <th>v69</th>\n",
       "      <th>v97</th>\n",
       "      <th>v125</th>\n",
       "      <th>v6</th>\n",
       "      <th>v102</th>\n",
       "      <th>v19</th>\n",
       "      <th>v90</th>\n",
       "      <th>v131</th>\n",
       "      <th>v22</th>\n",
       "      <th>v91</th>\n",
       "      <th>v120</th>\n",
       "      <th>v52</th>\n",
       "      <th>v107</th>\n",
       "      <th>v112</th>\n",
       "      <th>v10_bin</th>\n",
       "      <th>v14_bin</th>\n",
       "      <th>v17_bin</th>\n",
       "      <th>v34_bin</th>\n",
       "      <th>v46_bin</th>\n",
       "      <th>v51_bin</th>\n",
       "      <th>v54_bin</th>\n",
       "      <th>v58_bin</th>\n",
       "      <th>v64_bin</th>\n",
       "      <th>v65_bin</th>\n",
       "      <th>Naive Bayes0</th>\n",
       "      <th>Naive Bayes1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.667133</td>\n",
       "      <td>0.136931</td>\n",
       "      <td>0.229260</td>\n",
       "      <td>0.403141</td>\n",
       "      <td>0.603015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.134523</td>\n",
       "      <td>0.017569</td>\n",
       "      <td>0.094969</td>\n",
       "      <td>0.073298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>57</td>\n",
       "      <td>163</td>\n",
       "      <td>247</td>\n",
       "      <td>170</td>\n",
       "      <td>151</td>\n",
       "      <td>148</td>\n",
       "      <td>83</td>\n",
       "      <td>127</td>\n",
       "      <td>9.929674e-01</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121561</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.610796</td>\n",
       "      <td>0.203891</td>\n",
       "      <td>0.096209</td>\n",
       "      <td>0.472467</td>\n",
       "      <td>0.381128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121820</td>\n",
       "      <td>0.144514</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>0.153338</td>\n",
       "      <td>0.086969</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124224</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>34</td>\n",
       "      <td>168</td>\n",
       "      <td>197</td>\n",
       "      <td>131</td>\n",
       "      <td>152</td>\n",
       "      <td>100</td>\n",
       "      <td>130</td>\n",
       "      <td>235</td>\n",
       "      <td>184</td>\n",
       "      <td>8.728069e-01</td>\n",
       "      <td>0.127193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103734</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.440164</td>\n",
       "      <td>0.160960</td>\n",
       "      <td>0.080480</td>\n",
       "      <td>0.435798</td>\n",
       "      <td>0.263333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.113660</td>\n",
       "      <td>0.090351</td>\n",
       "      <td>0.012057</td>\n",
       "      <td>0.137807</td>\n",
       "      <td>0.070039</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>248</td>\n",
       "      <td>31</td>\n",
       "      <td>79</td>\n",
       "      <td>83</td>\n",
       "      <td>34</td>\n",
       "      <td>9.859166e-01</td>\n",
       "      <td>0.014083</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006089</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.610796</td>\n",
       "      <td>0.203891</td>\n",
       "      <td>0.096209</td>\n",
       "      <td>0.472467</td>\n",
       "      <td>0.381128</td>\n",
       "      <td>3</td>\n",
       "      <td>0.121820</td>\n",
       "      <td>0.144514</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>0.153338</td>\n",
       "      <td>0.086969</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124224</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>168</td>\n",
       "      <td>97</td>\n",
       "      <td>131</td>\n",
       "      <td>152</td>\n",
       "      <td>100</td>\n",
       "      <td>130</td>\n",
       "      <td>235</td>\n",
       "      <td>184</td>\n",
       "      <td>8.686117e-01</td>\n",
       "      <td>0.131388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.129998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.662712</td>\n",
       "      <td>0.179669</td>\n",
       "      <td>0.122931</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>0.160757</td>\n",
       "      <td>0.092970</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.171870</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183766</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>135</td>\n",
       "      <td>124</td>\n",
       "      <td>142</td>\n",
       "      <td>30</td>\n",
       "      <td>151</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>213</td>\n",
       "      <td>228</td>\n",
       "      <td>2.806852e-53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v31       v50  v110  v66  v129  v79  v47  v62  v56  v38  v74  v71  v24  \\\n",
       "0    0  0.066833     0    0   0.0    0    0  1.0    0  0.0    0    0    0   \n",
       "1    0  0.121561     0    1   0.0    1    1  1.0    1  0.0    0    1    1   \n",
       "2    0  0.103734     0    0   0.0    2    2  1.0    2  0.0    0    1    2   \n",
       "3    0  0.006089     0    2   0.0    3    1  2.0   -1  0.0    0    1    1   \n",
       "4    1  0.129998     1    1   0.0    4    3  0.0    3  6.0    1    1    0   \n",
       "\n",
       "   v113  v3  v72  v30       v70       v57       v88       v69       v97  v125  \\\n",
       "0     0   0  1.0    0  0.667133  0.136931  0.229260  0.403141  0.603015     0   \n",
       "1     1   0  1.0    1  0.610796  0.203891  0.096209  0.472467  0.381128     1   \n",
       "2     0   0  1.0   -1  0.440164  0.160960  0.080480  0.435798  0.263333     2   \n",
       "3     0   0  2.0   -1  0.610796  0.203891  0.096209  0.472467  0.381128     3   \n",
       "4    -1   0  6.0   -1  0.662712  0.179669  0.122931  0.363636  0.333333     4   \n",
       "\n",
       "         v6      v102       v19       v90      v131  v22  v91      v120  v52  \\\n",
       "0  0.101695  0.134523  0.017569  0.094969  0.073298    0    0  0.170179    0   \n",
       "1  0.121820  0.144514  0.011115  0.153338  0.086969    1    0  0.124224    1   \n",
       "2  0.113660  0.090351  0.012057  0.137807  0.070039    2    0  0.280203    0   \n",
       "3  0.121820  0.144514  0.011115  0.153338  0.086969    3    1  0.124224    2   \n",
       "4  0.160757  0.092970  0.008752  0.171870  0.090909    4    0  0.183766    3   \n",
       "\n",
       "   v107  v112  v10_bin  v14_bin  v17_bin  v34_bin  v46_bin  v51_bin  v54_bin  \\\n",
       "0     0     0       46       44       57      163      247      170      151   \n",
       "1     0     0       58       34      168      197      131      152      100   \n",
       "2     0     1       58       60       57       97       66      248       31   \n",
       "3     1     2       35       42      168       97      131      152      100   \n",
       "4     0     3       52      135      124      142       30      151       31   \n",
       "\n",
       "   v58_bin  v64_bin  v65_bin  Naive Bayes0  Naive Bayes1  target  \n",
       "0      148       83      127  9.929674e-01      0.007033       0  \n",
       "1      130      235      184  8.728069e-01      0.127193       1  \n",
       "2       79       83       34  9.859166e-01      0.014083       1  \n",
       "3      130      235      184  8.686117e-01      0.131388       0  \n",
       "4       32      213      228  2.806852e-53      1.000000       1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v31</th>\n",
       "      <th>v50</th>\n",
       "      <th>v110</th>\n",
       "      <th>v66</th>\n",
       "      <th>v129</th>\n",
       "      <th>v79</th>\n",
       "      <th>v47</th>\n",
       "      <th>v62</th>\n",
       "      <th>v56</th>\n",
       "      <th>v38</th>\n",
       "      <th>v74</th>\n",
       "      <th>v71</th>\n",
       "      <th>v24</th>\n",
       "      <th>v113</th>\n",
       "      <th>v3</th>\n",
       "      <th>v72</th>\n",
       "      <th>v30</th>\n",
       "      <th>v70</th>\n",
       "      <th>v57</th>\n",
       "      <th>v88</th>\n",
       "      <th>v69</th>\n",
       "      <th>v97</th>\n",
       "      <th>v125</th>\n",
       "      <th>v6</th>\n",
       "      <th>v102</th>\n",
       "      <th>v19</th>\n",
       "      <th>v90</th>\n",
       "      <th>v131</th>\n",
       "      <th>v22</th>\n",
       "      <th>v91</th>\n",
       "      <th>v120</th>\n",
       "      <th>v52</th>\n",
       "      <th>v107</th>\n",
       "      <th>v112</th>\n",
       "      <th>v10_bin</th>\n",
       "      <th>v14_bin</th>\n",
       "      <th>v17_bin</th>\n",
       "      <th>v34_bin</th>\n",
       "      <th>v46_bin</th>\n",
       "      <th>v51_bin</th>\n",
       "      <th>v54_bin</th>\n",
       "      <th>v58_bin</th>\n",
       "      <th>v64_bin</th>\n",
       "      <th>v65_bin</th>\n",
       "      <th>Naive Bayes0</th>\n",
       "      <th>Naive Bayes1</th>\n",
       "      <th>Class_proba_0</th>\n",
       "      <th>Class_proba_1</th>\n",
       "      <th>target_Stacked_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.556759</td>\n",
       "      <td>0.130112</td>\n",
       "      <td>0.089219</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>19</td>\n",
       "      <td>0.104089</td>\n",
       "      <td>0.093697</td>\n",
       "      <td>0.011274</td>\n",
       "      <td>0.156837</td>\n",
       "      <td>7.142865e-02</td>\n",
       "      <td>10794</td>\n",
       "      <td>3</td>\n",
       "      <td>0.140448</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>98</td>\n",
       "      <td>168</td>\n",
       "      <td>97</td>\n",
       "      <td>31</td>\n",
       "      <td>238</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>214</td>\n",
       "      <td>133</td>\n",
       "      <td>8.839028e-01</td>\n",
       "      <td>0.116097</td>\n",
       "      <td>0.342483</td>\n",
       "      <td>0.657517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051354</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.610828</td>\n",
       "      <td>0.203882</td>\n",
       "      <td>0.096218</td>\n",
       "      <td>0.472541</td>\n",
       "      <td>0.381237</td>\n",
       "      <td>53</td>\n",
       "      <td>0.121794</td>\n",
       "      <td>0.144778</td>\n",
       "      <td>0.011138</td>\n",
       "      <td>0.153290</td>\n",
       "      <td>8.681284e-02</td>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124691</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>168</td>\n",
       "      <td>234</td>\n",
       "      <td>133</td>\n",
       "      <td>152</td>\n",
       "      <td>101</td>\n",
       "      <td>136</td>\n",
       "      <td>235</td>\n",
       "      <td>182</td>\n",
       "      <td>3.922881e-25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140785</td>\n",
       "      <td>0.859215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042037</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.383383</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>66</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.038148</td>\n",
       "      <td>0.008620</td>\n",
       "      <td>0.145697</td>\n",
       "      <td>1.809556e-08</td>\n",
       "      <td>18210</td>\n",
       "      <td>2</td>\n",
       "      <td>0.057724</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>52</td>\n",
       "      <td>156</td>\n",
       "      <td>126</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "      <td>133</td>\n",
       "      <td>7.963420e-01</td>\n",
       "      <td>0.203658</td>\n",
       "      <td>0.256234</td>\n",
       "      <td>0.743766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047319</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.706434</td>\n",
       "      <td>0.217826</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>0.659751</td>\n",
       "      <td>0.430168</td>\n",
       "      <td>65</td>\n",
       "      <td>0.103917</td>\n",
       "      <td>0.144778</td>\n",
       "      <td>0.023828</td>\n",
       "      <td>0.237100</td>\n",
       "      <td>7.468887e-02</td>\n",
       "      <td>2444</td>\n",
       "      <td>3</td>\n",
       "      <td>0.223477</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>37</td>\n",
       "      <td>50</td>\n",
       "      <td>136</td>\n",
       "      <td>110</td>\n",
       "      <td>238</td>\n",
       "      <td>131</td>\n",
       "      <td>183</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>9.952730e-01</td>\n",
       "      <td>0.004727</td>\n",
       "      <td>0.365814</td>\n",
       "      <td>0.634186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.656029</td>\n",
       "      <td>0.262980</td>\n",
       "      <td>0.111738</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.382637</td>\n",
       "      <td>36</td>\n",
       "      <td>0.115124</td>\n",
       "      <td>0.074694</td>\n",
       "      <td>0.007441</td>\n",
       "      <td>0.157507</td>\n",
       "      <td>1.132076e-01</td>\n",
       "      <td>7527</td>\n",
       "      <td>3</td>\n",
       "      <td>0.081987</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>35</td>\n",
       "      <td>44</td>\n",
       "      <td>168</td>\n",
       "      <td>98</td>\n",
       "      <td>43</td>\n",
       "      <td>151</td>\n",
       "      <td>30</td>\n",
       "      <td>53</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>9.452363e-01</td>\n",
       "      <td>0.054764</td>\n",
       "      <td>0.347751</td>\n",
       "      <td>0.652249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v31       v50  v110  v66  v129  v79  v47  v62  v56  v38  v74  v71  v24  \\\n",
       "0    0  0.005942     0    2   0.0    2    2  1.0    2  0.0    0    1    1   \n",
       "1    0  0.051354     1    1   0.0    6    3  1.0    4  4.0    0    1    3   \n",
       "2    0  0.042037     0    1   0.0    3    1  1.0   28  0.0    0    1    0   \n",
       "3    0  0.047319     0    0   0.0    3    1  1.0    0  0.0    0    1    1   \n",
       "4    0  0.074683     0    0   0.0    3    1  2.0   -1  0.0    0    1    1   \n",
       "\n",
       "   v113  v3  v72  v30       v70       v57       v88       v69       v97  v125  \\\n",
       "0    -1   0  1.0   -1  0.556759  0.130112  0.089219  0.428571  0.250000    19   \n",
       "1    -1   0  5.0    4  0.610828  0.203882  0.096218  0.472541  0.381237    53   \n",
       "2     1   0  1.0    1  0.383383  0.272727  0.285714  0.333333  0.631579    66   \n",
       "3     0   0  1.0    5  0.706434  0.217826  0.021583  0.659751  0.430168    65   \n",
       "4    13   0  2.0    1  0.656029  0.262980  0.111738  0.490566  0.382637    36   \n",
       "\n",
       "         v6      v102       v19       v90          v131    v22  v91      v120  \\\n",
       "0  0.104089  0.093697  0.011274  0.156837  7.142865e-02  10794    3  0.140448   \n",
       "1  0.121794  0.144778  0.011138  0.153290  8.681284e-02    113    2  0.124691   \n",
       "2  0.077922  0.038148  0.008620  0.145697  1.809556e-08  18210    2  0.057724   \n",
       "3  0.103917  0.144778  0.023828  0.237100  7.468887e-02   2444    3  0.223477   \n",
       "4  0.115124  0.074694  0.007441  0.157507  1.132076e-01   7527    3  0.081987   \n",
       "\n",
       "   v52  v107  v112  v10_bin  v14_bin  v17_bin  v34_bin  v46_bin  v51_bin  \\\n",
       "0    7     3     7       46       98      168       97       31      238   \n",
       "1   10     2    14       45       43      168      234      133      152   \n",
       "2   10     2    17       52      156      126      180        0      248   \n",
       "3   10     3     5       52       37       50      136      110      238   \n",
       "4    8     3    16       35       44      168       98       43      151   \n",
       "\n",
       "   v54_bin  v58_bin  v64_bin  v65_bin  Naive Bayes0  Naive Bayes1  \\\n",
       "0       25       17      214      133  8.839028e-01      0.116097   \n",
       "1      101      136      235      182  3.922881e-25      1.000000   \n",
       "2       13        0      213      133  7.963420e-01      0.203658   \n",
       "3      131      183       12       15  9.952730e-01      0.004727   \n",
       "4       30       53      242      242  9.452363e-01      0.054764   \n",
       "\n",
       "   Class_proba_0  Class_proba_1  target_Stacked_predictions  \n",
       "0       0.342483       0.657517                           1  \n",
       "1       0.140785       0.859215                           1  \n",
       "2       0.256234       0.743766                           1  \n",
       "3       0.365814       0.634186                           1  \n",
       "4       0.347751       0.652249                           1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test.columns[:-3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive Bayes0</th>\n",
       "      <th>Naive Bayes1</th>\n",
       "      <th>target</th>\n",
       "      <th>v102</th>\n",
       "      <th>v107</th>\n",
       "      <th>v10_bin</th>\n",
       "      <th>v110</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v120</th>\n",
       "      <th>v125</th>\n",
       "      <th>v129</th>\n",
       "      <th>v131</th>\n",
       "      <th>v14_bin</th>\n",
       "      <th>v17_bin</th>\n",
       "      <th>v19</th>\n",
       "      <th>v22</th>\n",
       "      <th>v24</th>\n",
       "      <th>v3</th>\n",
       "      <th>v30</th>\n",
       "      <th>v31</th>\n",
       "      <th>v34_bin</th>\n",
       "      <th>v38</th>\n",
       "      <th>v46_bin</th>\n",
       "      <th>v47</th>\n",
       "      <th>v50</th>\n",
       "      <th>v51_bin</th>\n",
       "      <th>v52</th>\n",
       "      <th>v54_bin</th>\n",
       "      <th>v56</th>\n",
       "      <th>v57</th>\n",
       "      <th>v58_bin</th>\n",
       "      <th>v6</th>\n",
       "      <th>v62</th>\n",
       "      <th>v64_bin</th>\n",
       "      <th>v65_bin</th>\n",
       "      <th>v66</th>\n",
       "      <th>v69</th>\n",
       "      <th>v70</th>\n",
       "      <th>v71</th>\n",
       "      <th>v72</th>\n",
       "      <th>v74</th>\n",
       "      <th>v79</th>\n",
       "      <th>v88</th>\n",
       "      <th>v90</th>\n",
       "      <th>v91</th>\n",
       "      <th>v97</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.929674e-01</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134523</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073298</td>\n",
       "      <td>44</td>\n",
       "      <td>57</td>\n",
       "      <td>0.017569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066833</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136931</td>\n",
       "      <td>148</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0.403141</td>\n",
       "      <td>0.667133</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229260</td>\n",
       "      <td>0.094969</td>\n",
       "      <td>0</td>\n",
       "      <td>0.603015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.728069e-01</td>\n",
       "      <td>0.127193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.144514</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124224</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086969</td>\n",
       "      <td>34</td>\n",
       "      <td>168</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121561</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.203891</td>\n",
       "      <td>130</td>\n",
       "      <td>0.121820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>235</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472467</td>\n",
       "      <td>0.610796</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096209</td>\n",
       "      <td>0.153338</td>\n",
       "      <td>0</td>\n",
       "      <td>0.381128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.859166e-01</td>\n",
       "      <td>0.014083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090351</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280203</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070039</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>0.012057</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>0.103734</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0.160960</td>\n",
       "      <td>79</td>\n",
       "      <td>0.113660</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.435798</td>\n",
       "      <td>0.440164</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.080480</td>\n",
       "      <td>0.137807</td>\n",
       "      <td>0</td>\n",
       "      <td>0.263333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.686117e-01</td>\n",
       "      <td>0.131388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144514</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124224</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086969</td>\n",
       "      <td>42</td>\n",
       "      <td>168</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006089</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.203891</td>\n",
       "      <td>130</td>\n",
       "      <td>0.121820</td>\n",
       "      <td>2.0</td>\n",
       "      <td>235</td>\n",
       "      <td>184</td>\n",
       "      <td>2</td>\n",
       "      <td>0.472467</td>\n",
       "      <td>0.610796</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.096209</td>\n",
       "      <td>0.153338</td>\n",
       "      <td>1</td>\n",
       "      <td>0.381128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.806852e-53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.092970</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.183766</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>135</td>\n",
       "      <td>124</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.129998</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0.179669</td>\n",
       "      <td>32</td>\n",
       "      <td>0.160757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213</td>\n",
       "      <td>228</td>\n",
       "      <td>1</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.662712</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.122931</td>\n",
       "      <td>0.171870</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Naive Bayes0  Naive Bayes1  target      v102  v107  v10_bin  v110  v112  \\\n",
       "0  9.929674e-01      0.007033     0.0  0.134523     0       46     0     0   \n",
       "1  8.728069e-01      0.127193     1.0  0.144514     0       58     0     0   \n",
       "2  9.859166e-01      0.014083     1.0  0.090351     0       58     0     1   \n",
       "3  8.686117e-01      0.131388     0.0  0.144514     1       35     0     2   \n",
       "4  2.806852e-53      1.000000     1.0  0.092970     0       52     1     3   \n",
       "\n",
       "   v113      v120  v125  v129      v131  v14_bin  v17_bin       v19  v22  v24  \\\n",
       "0     0  0.170179     0   0.0  0.073298       44       57  0.017569    0    0   \n",
       "1     1  0.124224     1   0.0  0.086969       34      168  0.011115    1    1   \n",
       "2     0  0.280203     2   0.0  0.070039       60       57  0.012057    2    2   \n",
       "3     0  0.124224     3   0.0  0.086969       42      168  0.011115    3    1   \n",
       "4    -1  0.183766     4   0.0  0.090909      135      124  0.008752    4    0   \n",
       "\n",
       "   v3  v30  v31  v34_bin  v38  v46_bin  v47       v50  v51_bin  v52  v54_bin  \\\n",
       "0   0    0    0      163  0.0      247    0  0.066833      170    0      151   \n",
       "1   0    1    0      197  0.0      131    1  0.121561      152    1      100   \n",
       "2   0   -1    0       97  0.0       66    2  0.103734      248    0       31   \n",
       "3   0   -1    0       97  0.0      131    1  0.006089      152    2      100   \n",
       "4   0   -1    1      142  6.0       30    3  0.129998      151    3       31   \n",
       "\n",
       "   v56       v57  v58_bin        v6  v62  v64_bin  v65_bin  v66       v69  \\\n",
       "0    0  0.136931      148  0.101695  1.0       83      127    0  0.403141   \n",
       "1    1  0.203891      130  0.121820  1.0      235      184    1  0.472467   \n",
       "2    2  0.160960       79  0.113660  1.0       83       34    0  0.435798   \n",
       "3   -1  0.203891      130  0.121820  2.0      235      184    2  0.472467   \n",
       "4    3  0.179669       32  0.160757  0.0      213      228    1  0.363636   \n",
       "\n",
       "        v70  v71  v72  v74  v79       v88       v90  v91       v97  \n",
       "0  0.667133    0  1.0    0    0  0.229260  0.094969    0  0.603015  \n",
       "1  0.610796    1  1.0    0    1  0.096209  0.153338    0  0.381128  \n",
       "2  0.440164    1  1.0    0    2  0.080480  0.137807    0  0.263333  \n",
       "3  0.610796    1  2.0    0    3  0.096209  0.153338    1  0.381128  \n",
       "4  0.662712    1  6.0    1    4  0.122931  0.171870    0  0.333333  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Criar e avaliar alguns algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Algoritmo LigthGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações Gerais\n",
    "\n",
    "GENERATE_SUBMISSION_FILES = True\n",
    "SUBMISSION_SUFIX = \"_lgbm_v.1.0.1\"\n",
    "STRATIFIED_KFOLD = False\n",
    "RANDOM_SEED = 42 #737851\n",
    "NUM_THREADS = 4\n",
    "NUM_FOLDS = 10\n",
    "EARLY_STOPPING = 100\n",
    "\n",
    "LIGHTGBM_PARAMS = {\n",
    "    'boosting_type': 'goss',\n",
    "    'n_estimators': 10000,\n",
    "    'learning_rate': 0.005134,\n",
    "    'num_leaves': 54,\n",
    "    'max_depth': 10,\n",
    "    'subsample_for_bin': 240000,\n",
    "    'reg_alpha': 0.436193,\n",
    "    'reg_lambda': 0.479169,\n",
    "    'colsample_bytree': 0.508716,\n",
    "    'min_split_gain': 0.024766,\n",
    "    'subsample': 1,\n",
    "    'is_unbalance': False,\n",
    "    'silent':-1,\n",
    "    'verbose':-1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- LIGHTGBM MODEL -------------------------\n",
    "\n",
    "def run_model(data, categorical_feature = None):\n",
    "    df = data[data['target'].notnull()]\n",
    "    test = data[data['target'].isnull()]\n",
    "    del_features = ['target']\n",
    "    predictors = list(filter(lambda v: v not in del_features, df.columns))\n",
    "    \n",
    "    print(\"Train/valid shape: {}, test shape: {}\".format(df.shape, test.shape))\n",
    "\n",
    "    if not STRATIFIED_KFOLD:\n",
    "        folds = KFold(n_splits= NUM_FOLDS, shuffle=True, random_state= RANDOM_SEED)\n",
    "    else:\n",
    "        folds = StratifiedKFold(n_splits= NUM_FOLDS, shuffle=True, random_state= RANDOM_SEED)\n",
    "\n",
    "    # Hold oof predictions, test predictions, feature importance and training/valid auc\n",
    "    oof_preds = np.zeros(df.shape[0])\n",
    "    sub_preds = np.zeros(test.shape[0])\n",
    "    importance_df = pd.DataFrame()\n",
    "    eval_results = dict()\n",
    "\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(df[predictors], df['target'])):\n",
    "        train_x, train_y = df[predictors].iloc[train_idx], df['target'].iloc[train_idx]\n",
    "        valid_x, valid_y = df[predictors].iloc[valid_idx], df['target'].iloc[valid_idx]\n",
    "\n",
    "        params = {'random_state': RANDOM_SEED, 'nthread': NUM_THREADS}\n",
    "        clf = LGBMClassifier(**{**params, **LIGHTGBM_PARAMS})\n",
    "        if not categorical_feature:\n",
    "            clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                    eval_metric='logloss', verbose=400, early_stopping_rounds= EARLY_STOPPING)\n",
    "        else:\n",
    "            clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                    eval_metric='logloss', verbose=400, early_stopping_rounds=EARLY_STOPPING,\n",
    "                    feature_name= list(df[predictors].columns), categorical_feature= categorical_feature)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test[predictors], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        # Feature importance by GAIN and SPLIT\n",
    "        fold_importance = pd.DataFrame()\n",
    "        fold_importance[\"feature\"] = predictors\n",
    "        fold_importance[\"gain\"] = clf.booster_.feature_importance(importance_type='gain')\n",
    "        fold_importance[\"split\"] = clf.booster_.feature_importance(importance_type='split')\n",
    "        importance_df = pd.concat([importance_df, fold_importance], axis=0)\n",
    "        eval_results['train_{}'.format(n_fold+1)]  = clf.evals_result_['training']['binary_logloss']\n",
    "        eval_results['valid_{}'.format(n_fold+1)] = clf.evals_result_['valid_1']['binary_logloss']\n",
    "\n",
    "        print('Fold %2d Log Loss : %.6f' % (n_fold + 1, log_loss(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full Log Loss score %.6f' % log_loss(df['target'], oof_preds))\n",
    "    test['target'] = sub_preds.copy()\n",
    "\n",
    "    # Get the average feature importance between folds\n",
    "    mean_importance = importance_df.groupby('feature').mean().reset_index()\n",
    "    mean_importance.sort_values(by= 'gain', ascending=False, inplace=True)\n",
    "    # Save feature importance, test predictions and oof predictions as csv\n",
    "    if GENERATE_SUBMISSION_FILES:\n",
    "\n",
    "        # Save submission (test data) and feature importance\n",
    "        submission = pd.read_csv('../dataset/sample_submission.csv')\n",
    "        submission['PredictedProb'] = sub_preds.copy()\n",
    "        submission.to_csv('../submission/submission{}.csv'.format(SUBMISSION_SUFIX), index=False)\n",
    "        \n",
    "        mean_importance.to_csv('feature_importance{}.csv'.format(SUBMISSION_SUFIX), index=False)\n",
    "        plt.hist(submission.PredictedProb)\n",
    "        plt.show()\n",
    "    return mean_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/valid shape: (114321, 47), test shape: (114393, 47)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.472187\tvalid_1's binary_logloss: 0.482554\n",
      "[800]\ttraining's binary_logloss: 0.456463\tvalid_1's binary_logloss: 0.472124\n",
      "[1200]\ttraining's binary_logloss: 0.44667\tvalid_1's binary_logloss: 0.468767\n",
      "[1600]\ttraining's binary_logloss: 0.438357\tvalid_1's binary_logloss: 0.466909\n",
      "[2000]\ttraining's binary_logloss: 0.430807\tvalid_1's binary_logloss: 0.46582\n",
      "[2400]\ttraining's binary_logloss: 0.423854\tvalid_1's binary_logloss: 0.465083\n",
      "[2800]\ttraining's binary_logloss: 0.417358\tvalid_1's binary_logloss: 0.464512\n",
      "[3200]\ttraining's binary_logloss: 0.411196\tvalid_1's binary_logloss: 0.464106\n",
      "[3600]\ttraining's binary_logloss: 0.405219\tvalid_1's binary_logloss: 0.46348\n",
      "Early stopping, best iteration is:\n",
      "[3887]\ttraining's binary_logloss: 0.40116\tvalid_1's binary_logloss: 0.46319\n",
      "Fold  1 Log Loss : 0.463190\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.47215\tvalid_1's binary_logloss: 0.480258\n",
      "[800]\ttraining's binary_logloss: 0.456223\tvalid_1's binary_logloss: 0.472304\n",
      "[1200]\ttraining's binary_logloss: 0.446277\tvalid_1's binary_logloss: 0.469391\n",
      "[1600]\ttraining's binary_logloss: 0.438115\tvalid_1's binary_logloss: 0.467959\n",
      "[2000]\ttraining's binary_logloss: 0.430627\tvalid_1's binary_logloss: 0.466834\n",
      "[2400]\ttraining's binary_logloss: 0.423723\tvalid_1's binary_logloss: 0.465987\n",
      "[2800]\ttraining's binary_logloss: 0.417171\tvalid_1's binary_logloss: 0.465482\n",
      "[3200]\ttraining's binary_logloss: 0.410984\tvalid_1's binary_logloss: 0.464994\n",
      "[3600]\ttraining's binary_logloss: 0.405134\tvalid_1's binary_logloss: 0.464639\n",
      "[4000]\ttraining's binary_logloss: 0.399598\tvalid_1's binary_logloss: 0.464252\n",
      "[4400]\ttraining's binary_logloss: 0.394177\tvalid_1's binary_logloss: 0.464098\n",
      "Early stopping, best iteration is:\n",
      "[4338]\ttraining's binary_logloss: 0.39501\tvalid_1's binary_logloss: 0.46406\n",
      "Fold  2 Log Loss : 0.464060\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.472899\tvalid_1's binary_logloss: 0.474688\n",
      "[800]\ttraining's binary_logloss: 0.456935\tvalid_1's binary_logloss: 0.465408\n",
      "[1200]\ttraining's binary_logloss: 0.44707\tvalid_1's binary_logloss: 0.462776\n",
      "[1600]\ttraining's binary_logloss: 0.438722\tvalid_1's binary_logloss: 0.461185\n",
      "[2000]\ttraining's binary_logloss: 0.43126\tvalid_1's binary_logloss: 0.460437\n",
      "[2400]\ttraining's binary_logloss: 0.424357\tvalid_1's binary_logloss: 0.459636\n",
      "[2800]\ttraining's binary_logloss: 0.417838\tvalid_1's binary_logloss: 0.458902\n",
      "[3200]\ttraining's binary_logloss: 0.411581\tvalid_1's binary_logloss: 0.458177\n",
      "[3600]\ttraining's binary_logloss: 0.405656\tvalid_1's binary_logloss: 0.457805\n",
      "[4000]\ttraining's binary_logloss: 0.400012\tvalid_1's binary_logloss: 0.457603\n",
      "Early stopping, best iteration is:\n",
      "[3919]\ttraining's binary_logloss: 0.401136\tvalid_1's binary_logloss: 0.457564\n",
      "Fold  3 Log Loss : 0.457564\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.471674\tvalid_1's binary_logloss: 0.484219\n",
      "[800]\ttraining's binary_logloss: 0.455661\tvalid_1's binary_logloss: 0.477139\n",
      "[1200]\ttraining's binary_logloss: 0.445855\tvalid_1's binary_logloss: 0.474819\n",
      "[1600]\ttraining's binary_logloss: 0.437542\tvalid_1's binary_logloss: 0.473394\n",
      "[2000]\ttraining's binary_logloss: 0.430131\tvalid_1's binary_logloss: 0.472672\n",
      "[2400]\ttraining's binary_logloss: 0.423205\tvalid_1's binary_logloss: 0.47191\n",
      "[2800]\ttraining's binary_logloss: 0.416699\tvalid_1's binary_logloss: 0.471456\n",
      "[3200]\ttraining's binary_logloss: 0.410584\tvalid_1's binary_logloss: 0.471167\n",
      "[3600]\ttraining's binary_logloss: 0.404738\tvalid_1's binary_logloss: 0.470913\n",
      "Early stopping, best iteration is:\n",
      "[3764]\ttraining's binary_logloss: 0.402423\tvalid_1's binary_logloss: 0.470737\n",
      "Fold  4 Log Loss : 0.470737\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.472074\tvalid_1's binary_logloss: 0.480565\n",
      "[800]\ttraining's binary_logloss: 0.456067\tvalid_1's binary_logloss: 0.473127\n",
      "[1200]\ttraining's binary_logloss: 0.446293\tvalid_1's binary_logloss: 0.470772\n",
      "[1600]\ttraining's binary_logloss: 0.438097\tvalid_1's binary_logloss: 0.46942\n",
      "[2000]\ttraining's binary_logloss: 0.430646\tvalid_1's binary_logloss: 0.468558\n",
      "[2400]\ttraining's binary_logloss: 0.423747\tvalid_1's binary_logloss: 0.467883\n",
      "[2800]\ttraining's binary_logloss: 0.417259\tvalid_1's binary_logloss: 0.467353\n",
      "[3200]\ttraining's binary_logloss: 0.411034\tvalid_1's binary_logloss: 0.467002\n",
      "Early stopping, best iteration is:\n",
      "[3133]\ttraining's binary_logloss: 0.412051\tvalid_1's binary_logloss: 0.466988\n",
      "Fold  5 Log Loss : 0.466988\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.47253\tvalid_1's binary_logloss: 0.479221\n",
      "[800]\ttraining's binary_logloss: 0.456542\tvalid_1's binary_logloss: 0.471156\n",
      "[1200]\ttraining's binary_logloss: 0.446705\tvalid_1's binary_logloss: 0.468709\n",
      "[1600]\ttraining's binary_logloss: 0.438473\tvalid_1's binary_logloss: 0.467141\n",
      "[2000]\ttraining's binary_logloss: 0.431001\tvalid_1's binary_logloss: 0.466203\n",
      "[2400]\ttraining's binary_logloss: 0.424056\tvalid_1's binary_logloss: 0.465401\n",
      "[2800]\ttraining's binary_logloss: 0.417636\tvalid_1's binary_logloss: 0.464816\n",
      "[3200]\ttraining's binary_logloss: 0.41144\tvalid_1's binary_logloss: 0.464359\n",
      "[3600]\ttraining's binary_logloss: 0.405596\tvalid_1's binary_logloss: 0.463876\n",
      "[4000]\ttraining's binary_logloss: 0.400041\tvalid_1's binary_logloss: 0.463579\n",
      "Early stopping, best iteration is:\n",
      "[4093]\ttraining's binary_logloss: 0.398795\tvalid_1's binary_logloss: 0.463457\n",
      "Fold  6 Log Loss : 0.463457\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.472077\tvalid_1's binary_logloss: 0.481158\n",
      "[800]\ttraining's binary_logloss: 0.456209\tvalid_1's binary_logloss: 0.472971\n",
      "[1200]\ttraining's binary_logloss: 0.44623\tvalid_1's binary_logloss: 0.470325\n",
      "[1600]\ttraining's binary_logloss: 0.437942\tvalid_1's binary_logloss: 0.468802\n",
      "[2000]\ttraining's binary_logloss: 0.43049\tvalid_1's binary_logloss: 0.467725\n",
      "[2400]\ttraining's binary_logloss: 0.423662\tvalid_1's binary_logloss: 0.466916\n",
      "[2800]\ttraining's binary_logloss: 0.417169\tvalid_1's binary_logloss: 0.466309\n",
      "[3200]\ttraining's binary_logloss: 0.411075\tvalid_1's binary_logloss: 0.46557\n",
      "[3600]\ttraining's binary_logloss: 0.405172\tvalid_1's binary_logloss: 0.465064\n",
      "Early stopping, best iteration is:\n",
      "[3878]\ttraining's binary_logloss: 0.401269\tvalid_1's binary_logloss: 0.464775\n",
      "Fold  7 Log Loss : 0.464775\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.472343\tvalid_1's binary_logloss: 0.480849\n",
      "[800]\ttraining's binary_logloss: 0.45647\tvalid_1's binary_logloss: 0.472414\n",
      "[1200]\ttraining's binary_logloss: 0.446504\tvalid_1's binary_logloss: 0.469771\n",
      "[1600]\ttraining's binary_logloss: 0.438181\tvalid_1's binary_logloss: 0.468416\n",
      "[2000]\ttraining's binary_logloss: 0.430659\tvalid_1's binary_logloss: 0.467758\n",
      "[2400]\ttraining's binary_logloss: 0.423695\tvalid_1's binary_logloss: 0.467238\n",
      "[2800]\ttraining's binary_logloss: 0.417138\tvalid_1's binary_logloss: 0.466968\n",
      "[3200]\ttraining's binary_logloss: 0.410916\tvalid_1's binary_logloss: 0.466597\n",
      "[3600]\ttraining's binary_logloss: 0.405027\tvalid_1's binary_logloss: 0.466308\n",
      "Early stopping, best iteration is:\n",
      "[3725]\ttraining's binary_logloss: 0.403246\tvalid_1's binary_logloss: 0.466232\n",
      "Fold  8 Log Loss : 0.466232\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.473386\tvalid_1's binary_logloss: 0.47253\n",
      "[800]\ttraining's binary_logloss: 0.457441\tvalid_1's binary_logloss: 0.463534\n",
      "[1200]\ttraining's binary_logloss: 0.447615\tvalid_1's binary_logloss: 0.460726\n",
      "[1600]\ttraining's binary_logloss: 0.439324\tvalid_1's binary_logloss: 0.45922\n",
      "[2000]\ttraining's binary_logloss: 0.431937\tvalid_1's binary_logloss: 0.458252\n",
      "[2400]\ttraining's binary_logloss: 0.424914\tvalid_1's binary_logloss: 0.457405\n",
      "[2800]\ttraining's binary_logloss: 0.418438\tvalid_1's binary_logloss: 0.456779\n",
      "[3200]\ttraining's binary_logloss: 0.412282\tvalid_1's binary_logloss: 0.456219\n",
      "[3600]\ttraining's binary_logloss: 0.406404\tvalid_1's binary_logloss: 0.45581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000]\ttraining's binary_logloss: 0.40076\tvalid_1's binary_logloss: 0.455462\n",
      "Early stopping, best iteration is:\n",
      "[4171]\ttraining's binary_logloss: 0.39844\tvalid_1's binary_logloss: 0.455303\n",
      "Fold  9 Log Loss : 0.455303\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[400]\ttraining's binary_logloss: 0.47307\tvalid_1's binary_logloss: 0.47461\n",
      "[800]\ttraining's binary_logloss: 0.457152\tvalid_1's binary_logloss: 0.464988\n",
      "[1200]\ttraining's binary_logloss: 0.447301\tvalid_1's binary_logloss: 0.461744\n",
      "[1600]\ttraining's binary_logloss: 0.439065\tvalid_1's binary_logloss: 0.460304\n",
      "[2000]\ttraining's binary_logloss: 0.431518\tvalid_1's binary_logloss: 0.459087\n",
      "[2400]\ttraining's binary_logloss: 0.42451\tvalid_1's binary_logloss: 0.458354\n",
      "[2800]\ttraining's binary_logloss: 0.417941\tvalid_1's binary_logloss: 0.457886\n",
      "[3200]\ttraining's binary_logloss: 0.411705\tvalid_1's binary_logloss: 0.457414\n",
      "Early stopping, best iteration is:\n",
      "[3497]\ttraining's binary_logloss: 0.407339\tvalid_1's binary_logloss: 0.457153\n",
      "Fold 10 Log Loss : 0.457153\n",
      "Full Log Loss score 0.462946\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD7CAYAAACfQGjDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQY0lEQVR4nO3dfYxldX3H8ffMLsxM3F0Dw1CBspAi+zWlu1WBVstTmkpbk25ARR5SIGmT6qqR2GCiIdIQG5ONXVKCQNmqaShQKq2RFWNLYhqCW0JrkZUH2y+I7oOIZRyo7FZ3KzvTP+7ZzezDjzlzH86dmft+JTcz53zvnfP7zr33fO4599xzh2ZmZpAk6WiG+z0ASdLCZUhIkooMCUlSkSEhSSoyJCRJRcv7PYAuGwHOBV4E9vd5LJK0WCwDTgK+BeybXVhqIXEu8M1+D0KSFqkLgK2zZyy1kHgR4JVX/pfp6dbnP8bHVzA1taevg+qXQe4dBrt/e7f3+RgeHuK4494A1Tp0tqUWEvsBpqdnDobEgelBNci9w2D3b++DqcPej9hN7xvXkqQiQ0KSVGRISJKKDAlJUpEhIUkqMiQkSUWGhCSpaKl9TkKSWLlqjNGR/qze9u57jd2v/rwvy+4FQ0LSkjM6spz112/py7IfvPkSdvdlyb3h7iZJUpEhIUkqMiQkSUWGhCSpyJCQJBUZEpKkIkNCklRkSEiSigwJSVKRISFJKjIkJElFhoQkqWjOE/xFxDhwN3AGsA/4HvDBzJyMiBngKWC6uvo1mflUdbv1wF9Uy3gc+KPM/FknNUlSs+psScwAn83MyMx1wPPAxln138rMt1aXAwGxAvg8sD4z3wzsBj7eSU2S1Lw5tyQy82Xg4VmzHgM+NMfN3g38R2Y+V03fCdwFfLqDmiQteP/3i/1MTKxsfLl7973Wk787r++TiIhhWgHx1VmzH46I5cA/ATdl5j5gNbBj1nV2AqdWv7dbq218fMUh0/24wxaKQe4dBrv/Qe69n449ZllfvsviwZsvAbp/v8/3S4c+B+wBbqumV2fmrohYRet9ixuBT3VxfG2ZmtrD9PQM0PqHTU4upa8AqW+Qe4fB7n/Qex9k7dzvw8NDR7y4Plir+0ciYhNwJnBFZk4DZOau6uerwBeA86qr7wROm3Xz1cCuDmuSpIbVComI+AxwNnBptTuJiDguIsaq35cDlwHbqpv8M3BuRJxZTW8A7u+wJklq2JwhERFnATcAJwOPRsS2iPgK8Bbg3yLiO8CTwC9o7W4iM3cDHwC+FhHfA94IbOqkJklqXp2jm54Bhgrlda9zuy3AUd+9abcmSWqWn7iWJBUZEpKkIkNCklRkSEiSigwJSVKRISFJKjIkJElFhoQkqciQkCQVzfcssJJU28pVY4yOuJpZzLz3JPXM6Mjyvn63gjrn7iZJUpEhIUkqMiQkSUWGhCSpyJCQJBUZEpKkIkNCklRkSEiSigwJSVKRISFJKjIkJElFhoQkqciQkCQVGRKSpCJDQpJUZEhIkooMCUlSkSEhSSqa8+tLI2IcuBs4A9gHfA/4YGZORsQ7gM3AGLAduDozX6pu1/WaJKlZdbYkZoDPZmZk5jrgeWBjRAwB9wAfycw1wCPARoBe1CRJzZszJDLz5cx8eNasx4DTgHOAvZm5tZp/J3B59XsvapKkhs25u2m2iBgGPgR8FVgN7DhQy8yfRMRwRBzfi1pmvlx3nOPjKw6ZnphYOZ82l5RB7h0Gu/9B7n2Qdft+n1dIAJ8D9gC3Ae/p6ki6aGpqD9PTM0DrHzY5ubvPI+qPQe4dBrv/hdK7QdW8du734eGhI15cH6zV/SMRsQk4E7giM6eBnbR2Ox2onwDMVK/4e1GTJDWsVkhExGeAs4FLM3NfNftxYCwizq+mNwD397AmSWpYnUNgzwJuAJ4FHo0IgB9k5nsi4hpgc0SMUh2uCpCZ092uSZKaN2dIZOYzwFCh9iiwtqmaJKlZfuJaklRkSEiSigwJSVKRISFJKjIkJElFhoQkqciQkCQVGRKSpCJDQpJUZEhIkooMCUlSkSEhSSoyJCRJRYaEJKnIkJAkFc33O64lLUIrV40xOuLTXfPno0YaAKMjy1l//ZbGl/vgzZc0vkx1l7ubJElFhoQkqciQkCQVGRKSpCJDQpJUZEhIkooMCUlSkSEhSSoyJCRJRYaEJKnIkJAkFRkSkqSiWif4i4hNwPuA04G1mfl0NX87sLe6AHwiMx+qau8ANgNjwHbg6sx8qZOaJKlZdbckHgAuBHYcpXZZZr61uhwIiCHgHuAjmbkGeATY2ElNktS8WiGRmVszc9c8/u45wN7M3FpN3wlc3mFNktSwbnyfxL3VFsBW4IbM/B9gNbO2OjLzJxExHBHHt1vLzJfrDmh8fMUh0xMTK9tsbfEb5N5hsPsf5N4HWbfv905D4oLM3BURI8AtwG3A1Z0PqzNTU3uYnp4BWv+wycndfR5Rfwxy7zDY/R/eu4ExONp5zA8PDx3x4vpgrZPBHNgFlZn7gDuA86rSTuC0A9eLiBOAmWproN2aJKlhbYdERLwhIt5Y/T4EXAlsq8qPA2MRcX41vQG4v8OaJKlhdQ+BvRV4L/Am4BsRMQWsB74cEcuAZcB3gQ8DZOZ0RFwDbI6IUapDWTupSZKaVyskMvM64LqjlN72Ord5FFjbzZokqVl+4lqSVGRISJKKDAlJUpEhIUkqMiQkSUWGhCSpyJCQJBUZEpKkIkNCklRkSEiSigwJSVKRISFJKjIkJElFhoQkqciQkCQVGRKSpCJDQpJUZEhIkooMCUlSkSEhSSoyJCRJRYaEJKnIkJAkFRkSkqQiQ0KSVGRISJKKDAlJUpEhIUkqWt7vAUiDYuWqMUZHmnvKTUysbGxZWrrmfMRGxCbgfcDpwNrMfLqavwa4CxgHpoBrM/O5XtWkxW50ZDnrr9/Sl2U/ePMlfVmuFr86u5seAC4Edhw2/07g9sxcA9wObO5xTZLUsDm3JDJzK0BEHJwXEScCbwcurmbdB9wWERPAULdrmTnZboOSpPa1u4P0VOCFzNwPkJn7I+JH1fyhHtTmFRLj4ysOmR7kfbOD3DvYvwZPtx/zS/KN66mpPUxPzwCtf9jk5O4+j6g/Brl3WHj9G1hqQjuP+eHhoSNeXB+stTmOXcApEbEMoPp5cjW/FzVJUh+0FRKZ+RKwDbiqmnUV8ERmTvai1s4YJUmdq3MI7K3Ae4E3Ad+IiKnMPAvYANwVEX8GvAJcO+tmvahJkhpW5+im64DrjjL/v4DfLNym6zVJUvM8LYckqciQkCQVGRKSpCJDQpJUZEhIkooMCUlSkSEhSSoyJCRJRYaEJKnIkJAkFRkSkqQiQ0KSVGRISJKKDAlJUpEhIUkqMiQkSUWGhCSpyJCQJBUZEpKkIkNCklRkSEiSigwJSVKRISFJKjIkJElFhoQkqWh5vwcgNW3lqjFGR3zoS3X4TNHAGR1ZzvrrtzS+3AdvvqTxZUqdcneTJKnIkJAkFXW8uykitgN7qwvAJzLzoYh4B7AZGAO2A1dn5kvVbdqqSZKa1a0ticsy863V5aGIGALuAT6SmWuAR4CNAO3WJEnN69XupnOAvZm5tZq+E7i8w5okqWHdOrrp3morYCtwA7Aa2HGgmJk/iYjhiDi+3Vpmvlx3MOPjKw6ZnphY2WZbi98g9w72r8HT7cd8N0LigszcFREjwC3AbcBXuvB32zY1tYfp6Rmg9Q+bnNzdz+H0zSD3DuX+DQ4tZe0854eHh454cX2w1umAMnNX9XMfcAdwHrATOO3AdSLiBGCm2hpotyZJalhHIRERb4iIN1a/DwFXAtuAx4GxiDi/uuoG4P7q93ZrkqSGdbol8UvAwxHxJPA0sAb4cGZOA9cAfxURzwEXAZ8EaLcmSWpeR+9JZOb3gbcVao8Ca7tZkyQ1y09cS5KKDAlJUpEhIUkqMiQkSUWGhCSpyJCQJBUZEpKkIkNCklRkSEiSigwJSVKRISFJKjIkJElFhoQkqahbX18qzcvKVWOMjvT+4ee30EmdMSTUF6Mjy1l//Za+LPvBmy/py3KlxcjdTZKkIkNCklRkSEiSigwJSVKRISFJKjIkJElFhoQkqciQkCQVGRKSpCJDQpJU5Gk5BlxT51CStDi5dpilXyvMvfteY/erP298udC/cyh5/iRpcTAkZunXCvPLG/+gZ2cr9SyokjphSCwAxx6zzDOiSlqQFmRIRMQa4C5gHJgCrs3M5/o7KkkaPAv16KY7gdszcw1wO7C5z+ORpIG04LYkIuJE4O3AxdWs+4DbImIiMyfnuPkygOHhoUNmHj79ek48bqz2dbupX8vt57LteTCWPWjL7fey57O+O8ptlh1eG5qZmelwSN0VEWcDf5uZZ82a913g6sz89hw3Px/4Zi/HJ0lL2AXA1tkzFtyWRIe+RavJF4H9fR6LJC0Wy4CTaK1DD7EQQ2IXcEpELMvM/RGxDDi5mj+XfRyWgpKkWp4/2swF98Z1Zr4EbAOuqmZdBTxR4/0ISVKXLbj3JAAi4i20DoE9DniF1iGw2d9RSdLgWZAhIUlaGBbc7iZJ0sJhSEiSigwJSVKRISFJKlqIn5OYtzonBKw+b3Er8PvADLAxM7/Q9Fi7rWbvNwJXAq9Vlxsy86Gmx9oL8zkZZEQE8ARwR2Z+vLlR9kbd3iPicuBGYIjWY/9dmfnfTY6122o+7k8E/gY4FTgW+Bfgusx8reHhdlVEbALeB5wOrM3Mp49yna6t75bKlkSdEwL+IfBm4EzgncBNEXF6YyPsnTq9/ztwbmb+OvDHwJcion8nl+muWieDrJ40m4EHGhxbr83Ze0ScA9wEXJyZv0br1DU/bXKQPVLnfr8B+M/MXAesBc4G3tvcEHvmAeBCYMfrXKdr67tFHxKzTgh4XzXrPuDtETFx2FWvAD6fmdPVB/MeAN7f3Ei7r27vmflQZv6smnyS1ivK8cYG2iPzuO8BPgl8DXi2oeH11Dx6/1NgU2b+GCAzf5qZe5sbaffNo/cZYGVEDAMjtLYmXmhsoD2SmVszc64zUHRtfbfoQ4LWpuQLmbkfoPr5o2r+bKs5NHl3HuU6i03d3me7Fng+M3/YwPh6rVb/EbEO+D3gLxsfYe/Uve9/FfiViHgkIr4dEZ+KiPmfJnRhqdv7nwNraJ3L7cfAQ5n5r00OtI+6tr5bCiGhmiLiIlpPnKvmuu5SERHHAJ8HNhxYqQyY5cA6Wqfevwh4N3BNX0fUnPfT2nI+CTgFuDAiLuvvkBafpRASB08ICAf3PR/thIA7gdNmTa8+ynUWm7q9ExHvBO4BLl1Cpzip0/9JwBnA1yNiO/Ax4E8i4q+bHWrX1b3vdwD/mJn7MnM3sAX4jUZH2n11e/8ocG+1y+WntHr/7UZH2j9dW98t+pCYxwkB/4HWymG42nd5KfDl5kbafXV7j4hzgS8Bl9X4To5Fo07/mbkzM0/IzNMz83TgFlr7aj/Q+IC7aB6P+78Dfjcihqqtqt8BvtPcSLtvHr3/gNbRPUTEscC7gCOOBFqiura+W/QhUdkAfDQinqX16mEDQER8vTq6A+Bu4PvAc8BjwKcz8/v9GGyX1en9DmAM2BwR26rL2v4Mt+vq9L9U1en974GXgO/SWrE+A3yxD2Pttjq9fwy4ICKeotX7s7R2PS5qEXFrRPwQ+GXgGxHxTDW/J+s7T/AnSSpaKlsSkqQeMCQkSUWGhCSpyJCQJBUZEpKkIkNCklRkSEiSigwJSVLR/wNnSZBLfEP1HwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>v50</td>\n",
       "      <td>1.072386e+06</td>\n",
       "      <td>14070.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Naive Bayes0</td>\n",
       "      <td>3.652628e+05</td>\n",
       "      <td>8963.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Naive Bayes1</td>\n",
       "      <td>3.174988e+05</td>\n",
       "      <td>7248.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>v22</td>\n",
       "      <td>2.736729e+05</td>\n",
       "      <td>9276.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>v56</td>\n",
       "      <td>2.584525e+05</td>\n",
       "      <td>7786.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>v66</td>\n",
       "      <td>2.575983e+05</td>\n",
       "      <td>3585.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>v34_bin</td>\n",
       "      <td>2.134891e+05</td>\n",
       "      <td>6629.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>v10_bin</td>\n",
       "      <td>2.092989e+05</td>\n",
       "      <td>6845.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>v125</td>\n",
       "      <td>2.043105e+05</td>\n",
       "      <td>7025.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>v69</td>\n",
       "      <td>1.837651e+05</td>\n",
       "      <td>6753.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>v120</td>\n",
       "      <td>1.831129e+05</td>\n",
       "      <td>6709.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>v6</td>\n",
       "      <td>1.817269e+05</td>\n",
       "      <td>6615.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>v131</td>\n",
       "      <td>1.810900e+05</td>\n",
       "      <td>6631.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>v57</td>\n",
       "      <td>1.810088e+05</td>\n",
       "      <td>6642.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>v88</td>\n",
       "      <td>1.786208e+05</td>\n",
       "      <td>6563.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>v90</td>\n",
       "      <td>1.763074e+05</td>\n",
       "      <td>6467.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>v19</td>\n",
       "      <td>1.754827e+05</td>\n",
       "      <td>6426.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>v97</td>\n",
       "      <td>1.754434e+05</td>\n",
       "      <td>6453.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>v70</td>\n",
       "      <td>1.747363e+05</td>\n",
       "      <td>6412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>v14_bin</td>\n",
       "      <td>1.733123e+05</td>\n",
       "      <td>5955.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>v102</td>\n",
       "      <td>1.719324e+05</td>\n",
       "      <td>6284.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>v112</td>\n",
       "      <td>1.260728e+05</td>\n",
       "      <td>4435.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>v52</td>\n",
       "      <td>1.248996e+05</td>\n",
       "      <td>4320.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>v46_bin</td>\n",
       "      <td>1.136107e+05</td>\n",
       "      <td>4199.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>v113</td>\n",
       "      <td>1.087951e+05</td>\n",
       "      <td>4026.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>v79</td>\n",
       "      <td>9.448873e+04</td>\n",
       "      <td>3029.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>v24</td>\n",
       "      <td>8.770863e+04</td>\n",
       "      <td>2980.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>v65_bin</td>\n",
       "      <td>8.547805e+04</td>\n",
       "      <td>3155.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>v31</td>\n",
       "      <td>7.767593e+04</td>\n",
       "      <td>701.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>v58_bin</td>\n",
       "      <td>7.637835e+04</td>\n",
       "      <td>2888.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>v64_bin</td>\n",
       "      <td>7.553239e+04</td>\n",
       "      <td>2807.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>v54_bin</td>\n",
       "      <td>7.346909e+04</td>\n",
       "      <td>2747.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>v107</td>\n",
       "      <td>7.323216e+04</td>\n",
       "      <td>2585.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>v110</td>\n",
       "      <td>7.320856e+04</td>\n",
       "      <td>990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>v30</td>\n",
       "      <td>7.254271e+04</td>\n",
       "      <td>2568.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>v51_bin</td>\n",
       "      <td>6.870927e+04</td>\n",
       "      <td>2555.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>v47</td>\n",
       "      <td>5.623583e+04</td>\n",
       "      <td>1628.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>v17_bin</td>\n",
       "      <td>4.593849e+04</td>\n",
       "      <td>1725.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>v129</td>\n",
       "      <td>4.094587e+04</td>\n",
       "      <td>918.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>v71</td>\n",
       "      <td>3.607792e+04</td>\n",
       "      <td>1310.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>v72</td>\n",
       "      <td>3.564923e+04</td>\n",
       "      <td>1223.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>v91</td>\n",
       "      <td>3.505578e+04</td>\n",
       "      <td>1223.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>v62</td>\n",
       "      <td>3.164729e+04</td>\n",
       "      <td>1105.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>v38</td>\n",
       "      <td>2.082462e+04</td>\n",
       "      <td>662.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>v74</td>\n",
       "      <td>7.872314e+03</td>\n",
       "      <td>264.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>v3</td>\n",
       "      <td>3.807141e+03</td>\n",
       "      <td>128.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature          gain    split\n",
       "24           v50  1.072386e+06  14070.4\n",
       "0   Naive Bayes0  3.652628e+05   8963.9\n",
       "1   Naive Bayes1  3.174988e+05   7248.3\n",
       "15           v22  2.736729e+05   9276.6\n",
       "28           v56  2.584525e+05   7786.8\n",
       "35           v66  2.575983e+05   3585.8\n",
       "20       v34_bin  2.134891e+05   6629.1\n",
       "4        v10_bin  2.092989e+05   6845.8\n",
       "9           v125  2.043105e+05   7025.7\n",
       "36           v69  1.837651e+05   6753.8\n",
       "8           v120  1.831129e+05   6709.8\n",
       "31            v6  1.817269e+05   6615.1\n",
       "11          v131  1.810900e+05   6631.0\n",
       "29           v57  1.810088e+05   6642.1\n",
       "42           v88  1.786208e+05   6563.3\n",
       "43           v90  1.763074e+05   6467.6\n",
       "14           v19  1.754827e+05   6426.2\n",
       "45           v97  1.754434e+05   6453.4\n",
       "37           v70  1.747363e+05   6412.0\n",
       "12       v14_bin  1.733123e+05   5955.9\n",
       "2           v102  1.719324e+05   6284.2\n",
       "6           v112  1.260728e+05   4435.7\n",
       "26           v52  1.248996e+05   4320.8\n",
       "22       v46_bin  1.136107e+05   4199.5\n",
       "7           v113  1.087951e+05   4026.1\n",
       "41           v79  9.448873e+04   3029.4\n",
       "16           v24  8.770863e+04   2980.5\n",
       "34       v65_bin  8.547805e+04   3155.3\n",
       "19           v31  7.767593e+04    701.2\n",
       "30       v58_bin  7.637835e+04   2888.9\n",
       "33       v64_bin  7.553239e+04   2807.2\n",
       "27       v54_bin  7.346909e+04   2747.9\n",
       "3           v107  7.323216e+04   2585.9\n",
       "5           v110  7.320856e+04    990.0\n",
       "18           v30  7.254271e+04   2568.5\n",
       "25       v51_bin  6.870927e+04   2555.2\n",
       "23           v47  5.623583e+04   1628.1\n",
       "13       v17_bin  4.593849e+04   1725.7\n",
       "10          v129  4.094587e+04    918.1\n",
       "38           v71  3.607792e+04   1310.3\n",
       "39           v72  3.564923e+04   1223.9\n",
       "44           v91  3.505578e+04   1223.5\n",
       "32           v62  3.164729e+04   1105.3\n",
       "21           v38  2.082462e+04    662.1\n",
       "40           v74  7.872314e+03    264.3\n",
       "17            v3  3.807141e+03    128.3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03f293c5aaf34fd7a50a3b2bf14dab7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0af695c1d5e24a17b3a2aebc133ddd39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6782fd7c22664c55904d66122a64843b",
        "IPY_MODEL_9163f58ecd4f4a84922abc60cc69d789"
       ],
       "layout": "IPY_MODEL_d8264eeec6af442097559d8923081902"
      }
     },
     "1c88767c318e4d86a9ab43245f5daa77": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "219092655bed428f83aeb751ccaa2a4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "44521ec2de994d5186cdf7d1e445d158": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6782fd7c22664c55904d66122a64843b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c5e6acfe3f654e7ca86e4cddf862e984",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_219092655bed428f83aeb751ccaa2a4d",
       "value": 1000
      }
     },
     "9163f58ecd4f4a84922abc60cc69d789": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9a5c32201e5c447b829c604d757794df",
       "placeholder": "​",
       "style": "IPY_MODEL_b90e11ceb23b4a84a2f4908689dff66f",
       "value": " 1000/1000 [01:50&lt;00:00,  9.06it/s]"
      }
     },
     "9a5c32201e5c447b829c604d757794df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a8bfc018378d49efa1570fcb43b496f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b90e11ceb23b4a84a2f4908689dff66f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c5e6acfe3f654e7ca86e4cddf862e984": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c95734415f404758ba787c86b58e7cc2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d0cb9d8667c340c4b49fb7cf32acaf7c",
        "IPY_MODEL_e1aabb08150346cc9871c9f6b3bb5d36"
       ],
       "layout": "IPY_MODEL_1c88767c318e4d86a9ab43245f5daa77"
      }
     },
     "d0cb9d8667c340c4b49fb7cf32acaf7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_44521ec2de994d5186cdf7d1e445d158",
       "max": 17000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_eec34a1f17e2477fb10e7c11419a1382",
       "value": 17000
      }
     },
     "d8264eeec6af442097559d8923081902": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e1aabb08150346cc9871c9f6b3bb5d36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a8bfc018378d49efa1570fcb43b496f3",
       "placeholder": "​",
       "style": "IPY_MODEL_03f293c5aaf34fd7a50a3b2bf14dab7d",
       "value": " 17000/17000 [11:01&lt;00:00, 25.68it/s]"
      }
     },
     "eec34a1f17e2477fb10e7c11419a1382": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
