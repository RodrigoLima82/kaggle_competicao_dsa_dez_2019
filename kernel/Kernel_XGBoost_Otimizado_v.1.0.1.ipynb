{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle\n",
    "## Competição DSA de Machine Learning - Dezembro 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versão 1.0.0: LB = 0.50557\n",
    "- modelo: XGBoost (com algumas otimizações)\n",
    "- features categoricas: removido\n",
    "- dados missing: atribuído o valor medio\n",
    "\n",
    "Versão 1.0.1: LB = 0.48972 / CV = 0.469777\n",
    "- modelo: XGBoost executando todas as otimizações\n",
    "- features engineering: gerado através do Auto_ViML\n",
    "\n",
    "Versão 1.0.2: LB = 0.55264 / CV = 0.469158\n",
    "- modelo: XGBoost executando todas as otimizações\n",
    "- dados missing: removido colunas com mais de 40% de NA e as demais -999\n",
    "- features categoricas: label encoder\n",
    "- feature engineering: usando pacote Boruta\n",
    "\n",
    "Versão 1.0.3: LB = ??? / CV = ???\n",
    "- modelo: XGBoost executando todas as otimizações\n",
    "- features engineering: gerado através do Auto_ViML (modificado v1)\n",
    "\n",
    "Versão 1.0.4: LB = ??? / CV = ???\n",
    "- modelo: XGBoost executando todas as otimizações\n",
    "- features engineering: gerado através do Auto_ViML (modificado v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar os principais pacotes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "# Evitar que aparece os warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Seta algumas opções no Jupyter para exibição dos datasets\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# Variavel para controlar o treinamento no Kaggle\n",
    "TRAIN_OFFLINE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa os pacotes de algoritmos\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Importa pacotes do sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, log_loss\n",
    "from sklearn.preprocessing import scale, MinMaxScaler, StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregando os dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    if TRAIN_OFFLINE:\n",
    "        print('Carregando arquivo dataset_treino.csv....')\n",
    "        train = pd.read_csv('../dataset/dataset_treino_modificado.csv')\n",
    "        print('dataset_treino.csv tem {} linhas and {} colunas'.format(train.shape[0], train.shape[1]))\n",
    "        \n",
    "        print('Carregando arquivo dataset_teste.csv....')\n",
    "        test = pd.read_csv('../dataset/dataset_teste_modificado.csv')\n",
    "        print('dataset_teste.csv tem {} linhas and {} colunas'.format(test.shape[0], test.shape[1]))\n",
    "        \n",
    "    else:\n",
    "        print('Carregando arquivo dataset_treino.csv....')\n",
    "        train = pd.read_csv('/kaggle/input/competicao-dsa-machine-learning-dec-2019/dataset_treino.csv')\n",
    "        print('dataset_treino.csv tem {} linhas and {} colunas'.format(train.shape[0], train.shape[1]))\n",
    "        \n",
    "        print('Carregando arquivo dataset_treino.csv....')\n",
    "        test = pd.read_csv('/kaggle/input/competicao-dsa-machine-learning-dec-2019/dataset_teste.csv')\n",
    "        print('dataset_teste.csv tem {} linhas and {} colunas'.format(test.shape[0], test.shape[1]))\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Leitura dos dados\n",
    "train, test = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Removendo todas as variaveis categoricas\n",
    "drop_features = []\n",
    "for col in train.columns:\n",
    "    if train[col].dtype =='object':\n",
    "        drop_features.append(col)\n",
    "\n",
    "train = train.drop(drop_features, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Preenche os dados missing com a media\n",
    "train.fillna(train.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Criar e avaliar alguns algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando features preditoras e target\n",
    "#train_x = train.drop(['ID','target'], axis=1)\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "\n",
    "# Padronizando os dados\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Algoritmo XGBoost - Extreme Gradient Boosting\n",
    "\n",
    "Vamos dar uma olhada nas vantagens desse algoritmo:\n",
    "\n",
    "***Regularização:***\n",
    "- O XGBoost também é conhecido como uma técnica de \"reforço regularizado\", ajudando a reduzir o overfitting\n",
    "\n",
    "***Processamento paralelo:***\n",
    "- O XGBoost implementa o processamento paralelo e é incrivelmente mais rápido em comparação com o GBM. Mas, espere, sabemos que impulsionar é um processo seqüencial; portanto, como ele pode ser paralelo? Sabemos que cada árvore pode ser construída somente após a anterior, então o que nos impede de fazer uma árvore usando todos os núcleos?\n",
    "\n",
    "***Alta flexibilidade***\n",
    "- O XGBoost permite que os usuários definam objetivos de otimização personalizados e critérios de avaliação. Isso adiciona uma nova dimensão ao modelo e não há limite para o que podemos fazer.\n",
    "\n",
    "***Tratamento de valores ausentes***\n",
    "- O XGBoost possui uma rotina integrada para lidar com os valores ausentes. É necessário que o usuário forneça um valor diferente de outras observações e passe isso como um parâmetro. O XGBoost tenta coisas diferentes ao encontrar um valor ausente em cada nó e descobre qual caminho seguir para valores ausentes no futuro.\n",
    "\n",
    "***Poda de árvores:***\n",
    "- O XGBoost faz divisões até a profundidade máxima especificada e, em seguida, começa a podar a árvore para trás e remove as divisões além das quais não há ganho positivo.\n",
    "\n",
    "***Validação cruzada incorporada***\n",
    "- O XGBoost permite que o usuário execute uma validação cruzada a cada iteração do processo de otimização e, portanto, é fácil obter o número ideal exato de iterações de otimização em uma única execução.\n",
    "\n",
    "- Você pode começar a treinar um modelo XGBoost a partir da última iteração da execução anterior. Isso pode ser uma vantagem significativa em certas aplicações específicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma funcao para criação, execução e validação do modelo\n",
    "def run_model(modelo, X_tr, y_tr, test, useTrainCV=True, cv_folds=5, early_stopping_rounds=10):\n",
    "    \n",
    "    # Utilização do Cross-Validation\n",
    "    if useTrainCV:\n",
    "        xgb_param = modelo.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "        \n",
    "        print ('Start cross validation')\n",
    "        cvresult = xgb.cv(xgb_param, \n",
    "                          xgtrain, \n",
    "                          num_boost_round=modelo.get_params()['n_estimators'], \n",
    "                          nfold=cv_folds,\n",
    "                          metrics=['logloss'],\n",
    "                          stratified=True,\n",
    "                          seed=42,\n",
    "                          verbose_eval=True,\n",
    "                          early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "        modelo.set_params(n_estimators=cvresult.shape[0])\n",
    "        best_tree = cvresult.shape[0]\n",
    "        print('Best number of trees = {}'.format(best_tree))\n",
    "    \n",
    "    # Fit do modelo\n",
    "    modelo.fit(X_tr, y_tr, eval_metric='logloss')\n",
    "        \n",
    "    # Predição no dataset de treino\n",
    "    train_pred = modelo.predict(X_tr)\n",
    "    train_pred_prob = modelo.predict_proba(X_tr)[:,1]\n",
    "    \n",
    "    # Exibir o relatorio do modelo\n",
    "    print(\"Log Loss (Treino): %f\" % log_loss(y_tr, train_pred_prob))\n",
    "    print(\"Log Loss (Test): %f\" % cvresult['test-logloss-mean'][best_tree-1])\n",
    "    \n",
    "    feature_imp = pd.Series(modelo.feature_importances_.astype(float)).sort_values(ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(18,8))\n",
    "    feature_imp[:25].plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 01: criando o modelo fixando alguns hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Criando o primeiro modelo XGB\n",
    "modeloXGB = XGBClassifier(learning_rate = 0.1,\n",
    "                          n_estimators = 1000,\n",
    "                          max_depth = 5,\n",
    "                          min_child_weight = 1,\n",
    "                          gamma = 0,\n",
    "                          subsample = 0.8,\n",
    "                          colsample_bytree = 0.8,\n",
    "                          objective = 'binary:logistic',\n",
    "                          n_jobs = -1,\n",
    "                          scale_pos_weight = 1,\n",
    "                          seed = 42)\n",
    "\n",
    "run_model(modeloXGB, train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 02: otimização dos parametros: max_depth e min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Definindo os parametros que serão testados no GridSearch\n",
    "param_v1 = {\n",
    " 'max_depth':range(2,5),\n",
    " 'min_child_weight':range(1,2)\n",
    "}\n",
    "\n",
    "grid_1 = GridSearchCV(estimator = XGBClassifier(learning_rate = 0.1, \n",
    "                                                n_estimators = 1000, \n",
    "                                                max_depth = 5,\n",
    "                                                min_child_weight = 1, \n",
    "                                                gamma = 0, \n",
    "                                                subsample = 0.8, \n",
    "                                                colsample_bytree = 0.8,\n",
    "                                                objective = 'binary:logistic', \n",
    "                                                nthread = 4,\n",
    "                                                scale_pos_weight = 1, \n",
    "                                                seed = 42),\n",
    "                      param_grid = param_v1, \n",
    "                      scoring = 'neg_log_loss',\n",
    "                      n_jobs = -1,\n",
    "                      iid = False, \n",
    "                      cv = 5)\n",
    "\n",
    "# Realizando o fit e obtendo os melhores parametros do grid\n",
    "grid_1.fit(train_x, train_y)\n",
    "grid_1.best_params_, grid_1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 03: otimização dos parametros: gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Definindo os parametros que serão testados no GridSearch\n",
    "param_v2 = {\n",
    " 'gamma':[i/10.0 for i in range(0,2)]\n",
    "}\n",
    "\n",
    "grid_2 = GridSearchCV(estimator = XGBClassifier(learning_rate = 0.1, \n",
    "                                                n_estimators = 1000, \n",
    "                                                max_depth = grid_1.best_params_['max_depth'],\n",
    "                                                min_child_weight = grid_1.best_params_['min_child_weight'], \n",
    "                                                gamma = 0, \n",
    "                                                subsample = 0.8, \n",
    "                                                colsample_bytree = 0.8,\n",
    "                                                objective = 'binary:logistic', \n",
    "                                                nthread = 4, \n",
    "                                                scale_pos_weight = 1, \n",
    "                                                seed = 42),\n",
    "                      param_grid = param_v2, \n",
    "                      scoring = 'neg_log_loss',\n",
    "                      n_jobs = -1,\n",
    "                      iid = False, \n",
    "                      cv = 5)\n",
    "\n",
    "# Realizando o fit e obtendo os melhores parametros do grid\n",
    "grid_2.fit(train_x, train_y)\n",
    "grid_2.best_params_, grid_2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 04: otimização dos parametros: subsample e colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Definindo os parametros que serão testados no GridSearch\n",
    "param_v3 = {\n",
    " 'subsample':[i/10.0 for i in range(6,8)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,8)]\n",
    "}\n",
    "\n",
    "grid_3 = GridSearchCV(estimator = XGBClassifier(learning_rate = 0.1, \n",
    "                                                n_estimators = 1000, \n",
    "                                                max_depth = grid_1.best_params_['max_depth'],\n",
    "                                                min_child_weight = grid_1.best_params_['min_child_weight'], \n",
    "                                                gamma = grid_2.best_params_['gamma'], \n",
    "                                                subsample = 0.8, \n",
    "                                                colsample_bytree = 0.8,\n",
    "                                                objective = 'binary:logistic', \n",
    "                                                nthread = 4, \n",
    "                                                scale_pos_weight = 1, \n",
    "                                                seed = 42),\n",
    "                      param_grid = param_v3, \n",
    "                      scoring = 'neg_log_loss',\n",
    "                      n_jobs = -1,\n",
    "                      iid = False, \n",
    "                      cv = 5)\n",
    "\n",
    "grid_3.fit(train_x, train_y)\n",
    "grid_3.best_params_, grid_3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 05: otimização dos parametros: reg_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Definindo os parametros que serão testados no GridSearch\n",
    "param_v4 = {\n",
    " 'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "grid_4 = GridSearchCV(estimator = XGBClassifier(learning_rate = 0.1, \n",
    "                                                n_estimators = 1000, \n",
    "                                                max_depth = grid_1.best_params_['max_depth'],\n",
    "                                                min_child_weight = grid_1.best_params_['min_child_weight'], \n",
    "                                                gamma = grid_2.best_params_['gamma'], \n",
    "                                                subsample = grid_3.best_params_['subsample'], \n",
    "                                                colsample_bytree = grid_3.best_params_['colsample_bytree'],\n",
    "                                                objective = 'binary:logistic', \n",
    "                                                nthread = 4, \n",
    "                                                scale_pos_weight = 1, \n",
    "                                                seed = 42),\n",
    "                      param_grid = param_v4, \n",
    "                      scoring = 'neg_log_loss',\n",
    "                      n_jobs = -1,\n",
    "                      iid = False, \n",
    "                      cv = 5)\n",
    "\n",
    "# Realizando o fit e obtendo os melhores parametros do grid\n",
    "grid_4.fit(train_x, train_y)\n",
    "grid_4.best_params_, grid_4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 06: reduzindo Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Criando o modelo XGB com todas as otimizações\n",
    "modeloXGB_v2 = XGBClassifier(learning_rate = 0.01, \n",
    "                             n_estimators = 1000, \n",
    "                             max_depth = grid_1.best_params_['max_depth'],\n",
    "                             min_child_weight = grid_1.best_params_['min_child_weight'], \n",
    "                             gamma = grid_2.best_params_['gamma'], \n",
    "                             subsample = grid_3.best_params_['subsample'], \n",
    "                             colsample_bytree = grid_3.best_params_['colsample_bytree'],\n",
    "                             reg_alpha = grid_4.best_params_['reg_alpha'],\n",
    "                             objective = 'binary:logistic', \n",
    "                             n_jobs = -1,\n",
    "                             scale_pos_weight = 1, \n",
    "                             seed = 42)\n",
    "\n",
    "run_model(modeloXGB_v2, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o modelo XGBoost Otimizado\n",
    "print(modeloXGB_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Algoritmo LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma funcao para criação, execução e validação do modelo LGBM\n",
    "def run_model_lgb(train_x, train_y, useTrainCV=True, cv_folds=5, early_stopping_rounds=10):\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=cv_folds, shuffle = True, random_state = 42)\n",
    "\n",
    "    oof_pred = np.zeros((len(train_x), 4))\n",
    "    y_pred = np.zeros((len(train_y), 4))\n",
    "    \n",
    "    for fold, (tr_ind, val_ind) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('Fold {}'.format(fold + 1))\n",
    "        \n",
    "        x_train, x_val = train_x[tr_ind], train_x[val_ind]\n",
    "        y_train, y_val = train_y[tr_ind], train_y[val_ind]\n",
    "    \n",
    "        train_set = lgb.Dataset(x_train, y_train)#, categorical_feature=categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val)#, categorical_feature=categoricals)\n",
    "\n",
    "        params = {\n",
    "            'learning_rate': 0.1,\n",
    "            'metric': 'logloss',\n",
    "            'objective': 'binary',\n",
    "            'num_classes': 1,\n",
    "            'feature_fraction': 0.75,\n",
    "            'subsample': 0.75,\n",
    "            'n_jobs': -1,\n",
    "            'seed': 42,\n",
    "            'max_depth': 10\n",
    "        }\n",
    "\n",
    "        modelLGB = lgb.train(params, \n",
    "                             train_set, \n",
    "                             num_boost_round = 1000, \n",
    "                             valid_sets=[train_set, val_set], \n",
    "                             #early_stopping_rounds = 50, \n",
    "                             verbose_eval = 1)\n",
    "        \n",
    "        # Predição no dataset de treino\n",
    "        y_pred = modelLGB.predict(x_val)\n",
    "        print(y_pred)\n",
    "        print(x_val)\n",
    "        print(\"Log Loss (Treino): %f\" % log_loss(x_val, np.argmax(y_pred, axis = 1), eps=1e-15))\n",
    "\n",
    "        \n",
    "        oof_pred[val_ind] = modelLGB.predict(x_val)\n",
    "        y_pred += modelLGB.predict(train_x) / 5\n",
    "        \n",
    "        #loss_score = log_loss(train_y, np.argmax(oof_pred, axis = 1), eps=1e-15)\n",
    "        result = pd.Series(np.argmax(oof_pred, axis = 1))\n",
    "        #print('Our oof log loss score is: ', loss_score)\n",
    "        print(result.value_counts(normalize = True))\n",
    "\n",
    "        # Predição no dataset de teste\n",
    "        #prev_val = modelLGB.predict(y_val)\n",
    "        #print(\"Log Loss (Test): %f\" % log_loss(y_val, prev_val, eps=1e-15))\n",
    "        \n",
    "        #oof_pred[val_ind] = prev_tr\n",
    "    \n",
    "    #log_loss(y_true, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None)[source]¶\n",
    "    #loss_score = log_loss(train_y, np.argmax(oof_pred, axis = 1), eps=1e-15)\n",
    "    #result = pd.Series(np.argmax(oof_pred, axis = 1))\n",
    "    \n",
    "    #print('Our oof log loss score is: ', loss_score)\n",
    "    #print(result.value_counts(normalize = True))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run_model_lgb(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modeloXGB_v2.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(modeloXGB_v2.feature_importances_)), modeloXGB_v2.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(modeloXGB_v2.feature_importances_.astype(float)).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "feature_imp.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocando o dataset de teste conforme o modelo treinado\n",
    "# Neste caso é necessário aplicar a Feature Engineering usada para gerar o modelo\n",
    "#text_x = test.drop(['ID'], axis=1)\n",
    "\n",
    "# Removendo todas as variaveis categoricas\n",
    "#drop_features = []\n",
    "#for col in text_x.columns:\n",
    "#    if text_x[col].dtype =='object':\n",
    "#        drop_features.append(col)\n",
    "#text_x = text_x.drop(drop_features, axis=1)\n",
    "\n",
    "# Preenche os dados missing com media\n",
    "#text_x.fillna(text_x.mean(),inplace=True)\n",
    "#test = test.iloc[:, :-8]\n",
    "\n",
    "# Aplicando escala aos dados\n",
    "text_x = scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../dataset/sample_submission.csv')\n",
    "submission['PredictedProb'] = modeloXGB_v2.predict_proba(text_x)[:,1]\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../submission/submission_xgb_v.1.0.1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(submission.PredictedProb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03f293c5aaf34fd7a50a3b2bf14dab7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0af695c1d5e24a17b3a2aebc133ddd39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6782fd7c22664c55904d66122a64843b",
        "IPY_MODEL_9163f58ecd4f4a84922abc60cc69d789"
       ],
       "layout": "IPY_MODEL_d8264eeec6af442097559d8923081902"
      }
     },
     "1c88767c318e4d86a9ab43245f5daa77": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "219092655bed428f83aeb751ccaa2a4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "44521ec2de994d5186cdf7d1e445d158": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6782fd7c22664c55904d66122a64843b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c5e6acfe3f654e7ca86e4cddf862e984",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_219092655bed428f83aeb751ccaa2a4d",
       "value": 1000
      }
     },
     "9163f58ecd4f4a84922abc60cc69d789": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9a5c32201e5c447b829c604d757794df",
       "placeholder": "​",
       "style": "IPY_MODEL_b90e11ceb23b4a84a2f4908689dff66f",
       "value": " 1000/1000 [01:50&lt;00:00,  9.06it/s]"
      }
     },
     "9a5c32201e5c447b829c604d757794df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a8bfc018378d49efa1570fcb43b496f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b90e11ceb23b4a84a2f4908689dff66f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c5e6acfe3f654e7ca86e4cddf862e984": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c95734415f404758ba787c86b58e7cc2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d0cb9d8667c340c4b49fb7cf32acaf7c",
        "IPY_MODEL_e1aabb08150346cc9871c9f6b3bb5d36"
       ],
       "layout": "IPY_MODEL_1c88767c318e4d86a9ab43245f5daa77"
      }
     },
     "d0cb9d8667c340c4b49fb7cf32acaf7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_44521ec2de994d5186cdf7d1e445d158",
       "max": 17000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_eec34a1f17e2477fb10e7c11419a1382",
       "value": 17000
      }
     },
     "d8264eeec6af442097559d8923081902": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e1aabb08150346cc9871c9f6b3bb5d36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a8bfc018378d49efa1570fcb43b496f3",
       "placeholder": "​",
       "style": "IPY_MODEL_03f293c5aaf34fd7a50a3b2bf14dab7d",
       "value": " 17000/17000 [11:01&lt;00:00, 25.68it/s]"
      }
     },
     "eec34a1f17e2477fb10e7c11419a1382": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
