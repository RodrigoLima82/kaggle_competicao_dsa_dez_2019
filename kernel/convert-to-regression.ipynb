{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from catboost import CatBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "import shap\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistic lib\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, norm\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import gc\n",
    "import json\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Objective\n",
    "\n",
    "* In the last notebook we create our baseline model including a feature selection part. \n",
    "* Cohen cappa score of 0.456 (lb) with a local cv score of 0.529\n",
    "* In this notebook we are going to add more features and remove others that i think they overfitt the train set and then check if our local cv score improve.\n",
    "* Next, we will check if this improvement aligns with the lb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "* Check the distribution of the target variable of the out of folds score and the prediction distribution. A good model should more or less have the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_qwk_lgb_regr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for lgb.\n",
    "    \"\"\"\n",
    "    dist = Counter(train['target'])\n",
    "    for k in dist:\n",
    "        dist[k] /= len(train)\n",
    "    train['target'].hist()\n",
    "    \n",
    "    acum = 0\n",
    "    bound = {}\n",
    "    for i in range(3):\n",
    "        acum += dist[i]\n",
    "        bound[i] = np.percentile(y_pred, acum * 100)\n",
    "\n",
    "    def classify(x):\n",
    "        if x <= bound[0]:\n",
    "            return 0\n",
    "        elif x <= bound[1]:\n",
    "            return 1\n",
    "        elif x <= bound[2]:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    y_pred = np.array(list(map(classify, y_pred))).reshape(y_true.shape)\n",
    "\n",
    "    return 'cappa', cohen_kappa_score(y_true, y_pred, weights='quadratic'), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohenkappa(ypred, y):\n",
    "    y = y.get_label().astype(\"int\")\n",
    "    ypred = ypred.reshape((4, -1)).argmax(axis = 0)\n",
    "    loss = cohenkappascore(y, y_pred, weights = 'quadratic')\n",
    "    return \"cappa\", loss, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    print('Carregando arquivo dataset_treino_new.csv....')\n",
    "    train = pd.read_csv('../dataset/dataset_treino_new.csv')\n",
    "    print('dataset_treino.csv tem {} linhas and {} colunas'.format(train.shape[0], train.shape[1]))\n",
    "\n",
    "    print('Carregando arquivo dataset_teste_new.csv....')\n",
    "    test = pd.read_csv('../dataset/dataset_teste_new.csv')\n",
    "    print('dataset_teste.csv tem {} linhas and {} colunas'.format(test.shape[0], test.shape[1]))\n",
    "\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_Model(object):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.features = features\n",
    "        self.n_splits = n_splits\n",
    "        self.categoricals = categoricals\n",
    "        self.target = 'target'\n",
    "        self.cv = self.get_cv()\n",
    "        self.verbose = verbose\n",
    "        self.params = self.get_params()\n",
    "        self.y_pred, self.score, self.model = self.fit()\n",
    "        \n",
    "    def train_model(self, train_set, val_set):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_cv(self):\n",
    "        cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "        return cv.split(self.train_df, self.train_df[self.target])\n",
    "    \n",
    "    def get_params(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_x(self, x):\n",
    "        return x\n",
    "        \n",
    "    def fit(self):\n",
    "        oof_pred = np.zeros((len(train), ))\n",
    "        y_pred = np.zeros((len(test), ))\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv):\n",
    "            x_train, x_val = self.train_df[self.features].iloc[train_idx], self.train_df[self.features].iloc[val_idx]\n",
    "            y_train, y_val = self.train_df[self.target][train_idx], self.train_df[self.target][val_idx]\n",
    "            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n",
    "            model = self.train_model(train_set, val_set)\n",
    "            conv_x_val = self.convert_x(x_val)\n",
    "            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n",
    "            x_test = self.convert_x(self.test_df[self.features])\n",
    "            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n",
    "            print('Partial score of fold {} is: {}'.format(fold, eval_qwk_lgb_regr(y_val, oof_pred[val_idx])[1]))\n",
    "        _, loss_score, _ = eval_qwk_lgb_regr(self.train_df[self.target], oof_pred)\n",
    "        if self.verbose:\n",
    "            print('Our oof cohen kappa score is: ', loss_score)\n",
    "        return y_pred, loss_score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lgb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return lgb.train(self.params, train_set, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val, categorical_feature=self.categoricals)\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'n_estimators':5000,\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'regression',\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample': 0.75,\n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'feature_fraction': 0.9,\n",
    "                    'max_depth': 15,\n",
    "                    'lambda_l1': 1,  \n",
    "                    'lambda_l2': 1,\n",
    "                    'early_stopping_rounds': 100\n",
    "                    }\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xgb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return xgb.train(self.params, train_set, \n",
    "                         num_boost_round=5000, evals=[(train_set, 'train'), (val_set, 'val')], \n",
    "                         verbose_eval=verbosity, early_stopping_rounds=100)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = xgb.DMatrix(x_train, y_train)\n",
    "        val_set = xgb.DMatrix(x_val, y_val)\n",
    "        return train_set, val_set\n",
    "    \n",
    "    def convert_x(self, x):\n",
    "        return xgb.DMatrix(x)\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'colsample_bytree': 0.8,                 \n",
    "            'learning_rate': 0.01,\n",
    "            'max_depth': 10,\n",
    "            'subsample': 1,\n",
    "            'objective':'reg:squarederror',\n",
    "            #'eval_metric':'rmse',\n",
    "            'min_child_weight':3,\n",
    "            'gamma':0.25,\n",
    "            'n_estimators':5000}\n",
    "\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Catb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        clf = CatBoostRegressor(**self.params)\n",
    "        clf.fit(train_set['X'], \n",
    "                train_set['y'], \n",
    "                eval_set=(val_set['X'], val_set['y']),\n",
    "                verbose=verbosity, \n",
    "                cat_features=self.categoricals)\n",
    "        return clf\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = {'X': x_train, 'y': y_train}\n",
    "        val_set = {'X': x_val, 'y': y_val}\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'loss_function': 'RMSE',\n",
    "                   'task_type': \"CPU\",\n",
    "                   'iterations': 5000,\n",
    "                   'od_type': \"Iter\",\n",
    "                    'depth': 10,\n",
    "                  'colsample_bylevel': 0.5, \n",
    "                   'early_stopping_rounds': 300,\n",
    "                    'l2_leaf_reg': 18,\n",
    "                   'random_seed': 42,\n",
    "                    'use_best_model': True\n",
    "                    }\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "class Nn_Model(Base_Model):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True):\n",
    "        features = features.copy()\n",
    "        if len(categoricals) > 0:\n",
    "            for cat in categoricals:\n",
    "                enc = OneHotEncoder()\n",
    "                train_cats = enc.fit_transform(train_df[[cat]])\n",
    "                test_cats = enc.transform(test_df[[cat]])\n",
    "                cat_cols = ['{}_{}'.format(cat, str(col)) for col in enc.active_features_]\n",
    "                features += cat_cols\n",
    "                train_cats = pd.DataFrame(train_cats.toarray(), columns=cat_cols)\n",
    "                test_cats = pd.DataFrame(test_cats.toarray(), columns=cat_cols)\n",
    "                train_df = pd.concat([train_df, train_cats], axis=1)\n",
    "                test_df = pd.concat([test_df, test_cats], axis=1)\n",
    "        scalar = MinMaxScaler()\n",
    "        train_df[features] = scalar.fit_transform(train_df[features])\n",
    "        test_df[features] = scalar.transform(test_df[features])\n",
    "        print(train_df[features].shape)\n",
    "        super().__init__(train_df, test_df, features, categoricals, n_splits, verbose)\n",
    "        \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Input(shape=(train_set['X'].shape[1],)),\n",
    "            tf.keras.layers.Dense(200, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(100, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(50, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(25, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(1, activation='relu')\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=4e-4), loss='mse')\n",
    "        print(model.summary())\n",
    "        save_best = tf.keras.callbacks.ModelCheckpoint('nn_model.w8', save_weights_only=True, save_best_only=True, verbose=1)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "        model.fit(train_set['X'], \n",
    "                train_set['y'], \n",
    "                validation_data=(val_set['X'], val_set['y']),\n",
    "                epochs=100,\n",
    "                 callbacks=[save_best, early_stop])\n",
    "        model.load_weights('nn_model.w8')\n",
    "        return model\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = {'X': x_train, 'y': y_train}\n",
    "        val_set = {'X': x_val, 'y': y_val}\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "class Cnn_Model(Base_Model):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True):\n",
    "        features = features.copy()\n",
    "        if len(categoricals) > 0:\n",
    "            for cat in categoricals:\n",
    "                enc = OneHotEncoder()\n",
    "                train_cats = enc.fit_transform(train_df[[cat]])\n",
    "                test_cats = enc.transform(test_df[[cat]])\n",
    "                cat_cols = ['{}_{}'.format(cat, str(col)) for col in enc.active_features_]\n",
    "                features += cat_cols\n",
    "                train_cats = pd.DataFrame(train_cats.toarray(), columns=cat_cols)\n",
    "                test_cats = pd.DataFrame(test_cats.toarray(), columns=cat_cols)\n",
    "                train_df = pd.concat([train_df, train_cats], axis=1)\n",
    "                test_df = pd.concat([test_df, test_cats], axis=1)\n",
    "        scalar = MinMaxScaler()\n",
    "        train_df[features] = scalar.fit_transform(train_df[features])\n",
    "        test_df[features] = scalar.transform(test_df[features])\n",
    "        self.create_feat_2d(features)\n",
    "        super().__init__(train_df, test_df, features, categoricals, n_splits, verbose)\n",
    "        \n",
    "    def create_feat_2d(self, features, n_feats_repeat=50):\n",
    "        self.n_feats = len(features)\n",
    "        self.n_feats_repeat = n_feats_repeat\n",
    "        self.mask = np.zeros((self.n_feats_repeat, self.n_feats), dtype=np.int32)\n",
    "        for i in range(self.n_feats_repeat):\n",
    "            l = list(range(self.n_feats))\n",
    "            for j in range(self.n_feats):\n",
    "                c = l.pop(choice(range(len(l))))\n",
    "                self.mask[i, j] = c\n",
    "        self.mask = tf.convert_to_tensor(self.mask)\n",
    "        print(self.mask.shape)\n",
    "       \n",
    "        \n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "\n",
    "        inp = tf.keras.layers.Input(shape=(self.n_feats))\n",
    "        x = tf.keras.layers.Lambda(lambda x: tf.gather(x, self.mask, axis=1))(inp)\n",
    "        x = tf.keras.layers.Reshape((self.n_feats_repeat, self.n_feats, 1))(x)\n",
    "        x = tf.keras.layers.Conv2D(18, (50, 50), strides=50, activation='relu')(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        #x = tf.keras.layers.Dense(200, activation='relu')(x)\n",
    "        #x = tf.keras.layers.LayerNormalization()(x)\n",
    "        #x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        x = tf.keras.layers.Dense(100, activation='relu')(x)\n",
    "        x = tf.keras.layers.LayerNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        x = tf.keras.layers.Dense(50, activation='relu')(x)\n",
    "        x = tf.keras.layers.LayerNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        out = tf.keras.layers.Dense(1)(x)\n",
    "        \n",
    "        model = tf.keras.Model(inp, out)\n",
    "    \n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='mse')\n",
    "        print(model.summary())\n",
    "        save_best = tf.keras.callbacks.ModelCheckpoint('nn_model.w8', save_weights_only=True, save_best_only=True, verbose=1)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "        model.fit(train_set['X'], \n",
    "                train_set['y'], \n",
    "                validation_data=(val_set['X'], val_set['y']),\n",
    "                epochs=100,\n",
    "                 callbacks=[save_best, early_stop])\n",
    "        model.load_weights('nn_model.w8')\n",
    "        return model\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = {'X': x_train, 'y': y_train}\n",
    "        val_set = {'X': x_val, 'y': y_val}\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando arquivo dataset_treino_new.csv....\n",
      "dataset_treino.csv tem 114321 linhas and 184 colunas\n",
      "Carregando arquivo dataset_teste_new.csv....\n",
      "dataset_teste.csv tem 114393 linhas and 183 colunas\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "train, test = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando arquivo dataset_treino_new.csv....\n",
      "dataset_treino.csv tem 114321 linhas and 184 colunas\n",
      "Carregando arquivo dataset_teste_new.csv....\n",
      "dataset_teste.csv tem 114393 linhas and 183 colunas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrigolima82/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "# Leitura dos dados\n",
    "train, test = read_data()\n",
    "df = train.append(test)\n",
    "df = df.drop(columns = ['1'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"v19\"] = np.log1p(df[\"v19\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Numerical features:  164\n",
      "Number of Categorical features:  19\n"
     ]
    }
   ],
   "source": [
    "# Verificar a quantidade de features numericas e categoricas\n",
    "\n",
    "numerical_feats = df.dtypes[df.dtypes != \"object\"]\n",
    "print(\"Number of Numerical features: \", len(numerical_feats))\n",
    "\n",
    "categorical_feats = df.dtypes[df.dtypes == \"object\"].index\n",
    "print(\"Number of Categorical features: \", len(categorical_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>grp_1</th>\n",
       "      <th>grp_10</th>\n",
       "      <th>grp_11</th>\n",
       "      <th>grp_12</th>\n",
       "      <th>grp_2</th>\n",
       "      <th>grp_3</th>\n",
       "      <th>grp_4</th>\n",
       "      <th>grp_5</th>\n",
       "      <th>grp_6</th>\n",
       "      <th>grp_7</th>\n",
       "      <th>grp_8</th>\n",
       "      <th>grp_9</th>\n",
       "      <th>ica_1</th>\n",
       "      <th>ica_10</th>\n",
       "      <th>ica_11</th>\n",
       "      <th>ica_12</th>\n",
       "      <th>ica_2</th>\n",
       "      <th>ica_3</th>\n",
       "      <th>ica_4</th>\n",
       "      <th>ica_5</th>\n",
       "      <th>ica_6</th>\n",
       "      <th>ica_7</th>\n",
       "      <th>ica_8</th>\n",
       "      <th>ica_9</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_10</th>\n",
       "      <th>pca_11</th>\n",
       "      <th>pca_12</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "      <th>pca_5</th>\n",
       "      <th>pca_6</th>\n",
       "      <th>pca_7</th>\n",
       "      <th>pca_8</th>\n",
       "      <th>pca_9</th>\n",
       "      <th>srp_1</th>\n",
       "      <th>srp_10</th>\n",
       "      <th>srp_11</th>\n",
       "      <th>srp_12</th>\n",
       "      <th>srp_2</th>\n",
       "      <th>srp_3</th>\n",
       "      <th>srp_4</th>\n",
       "      <th>srp_5</th>\n",
       "      <th>srp_6</th>\n",
       "      <th>srp_7</th>\n",
       "      <th>srp_8</th>\n",
       "      <th>srp_9</th>\n",
       "      <th>target</th>\n",
       "      <th>tsvd_1</th>\n",
       "      <th>tsvd_10</th>\n",
       "      <th>tsvd_11</th>\n",
       "      <th>tsvd_12</th>\n",
       "      <th>tsvd_2</th>\n",
       "      <th>tsvd_3</th>\n",
       "      <th>tsvd_4</th>\n",
       "      <th>tsvd_5</th>\n",
       "      <th>tsvd_6</th>\n",
       "      <th>tsvd_7</th>\n",
       "      <th>tsvd_8</th>\n",
       "      <th>tsvd_9</th>\n",
       "      <th>v1</th>\n",
       "      <th>v10</th>\n",
       "      <th>v100</th>\n",
       "      <th>v101</th>\n",
       "      <th>v102</th>\n",
       "      <th>v103</th>\n",
       "      <th>v104</th>\n",
       "      <th>v105</th>\n",
       "      <th>v106</th>\n",
       "      <th>v107</th>\n",
       "      <th>v108</th>\n",
       "      <th>v109</th>\n",
       "      <th>v11</th>\n",
       "      <th>v110</th>\n",
       "      <th>v111</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v114</th>\n",
       "      <th>v115</th>\n",
       "      <th>v116</th>\n",
       "      <th>v117</th>\n",
       "      <th>v118</th>\n",
       "      <th>v119 v123</th>\n",
       "      <th>v119 v48</th>\n",
       "      <th>v119 v85</th>\n",
       "      <th>v119^2</th>\n",
       "      <th>v119_x</th>\n",
       "      <th>v119_y</th>\n",
       "      <th>v120</th>\n",
       "      <th>v121</th>\n",
       "      <th>v122</th>\n",
       "      <th>v123 v48</th>\n",
       "      <th>v123 v85</th>\n",
       "      <th>v123^2</th>\n",
       "      <th>v123_x</th>\n",
       "      <th>v123_y</th>\n",
       "      <th>v124</th>\n",
       "      <th>v125</th>\n",
       "      <th>v126</th>\n",
       "      <th>v127</th>\n",
       "      <th>v129</th>\n",
       "      <th>v130</th>\n",
       "      <th>v131</th>\n",
       "      <th>v14</th>\n",
       "      <th>v15</th>\n",
       "      <th>v16</th>\n",
       "      <th>v17</th>\n",
       "      <th>v18</th>\n",
       "      <th>v19</th>\n",
       "      <th>v2</th>\n",
       "      <th>v20</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>v29</th>\n",
       "      <th>v3</th>\n",
       "      <th>v30</th>\n",
       "      <th>v31</th>\n",
       "      <th>v35</th>\n",
       "      <th>v36</th>\n",
       "      <th>v37</th>\n",
       "      <th>v39</th>\n",
       "      <th>v4</th>\n",
       "      <th>v40</th>\n",
       "      <th>v42</th>\n",
       "      <th>v44</th>\n",
       "      <th>v45</th>\n",
       "      <th>v47</th>\n",
       "      <th>v48 v85</th>\n",
       "      <th>v48^2</th>\n",
       "      <th>v48_x</th>\n",
       "      <th>v48_y</th>\n",
       "      <th>v5</th>\n",
       "      <th>v50</th>\n",
       "      <th>v51</th>\n",
       "      <th>v52</th>\n",
       "      <th>v56</th>\n",
       "      <th>v57</th>\n",
       "      <th>v58</th>\n",
       "      <th>v59</th>\n",
       "      <th>v6</th>\n",
       "      <th>v61</th>\n",
       "      <th>v62 v119</th>\n",
       "      <th>v62 v123</th>\n",
       "      <th>v62 v48</th>\n",
       "      <th>v62 v85</th>\n",
       "      <th>v62^2</th>\n",
       "      <th>v62_x</th>\n",
       "      <th>v62_y</th>\n",
       "      <th>v66</th>\n",
       "      <th>v68</th>\n",
       "      <th>v69</th>\n",
       "      <th>v7</th>\n",
       "      <th>v70</th>\n",
       "      <th>v71</th>\n",
       "      <th>v72</th>\n",
       "      <th>v74</th>\n",
       "      <th>v75</th>\n",
       "      <th>v78</th>\n",
       "      <th>v79</th>\n",
       "      <th>v80</th>\n",
       "      <th>v81</th>\n",
       "      <th>v82</th>\n",
       "      <th>v84</th>\n",
       "      <th>v85^2</th>\n",
       "      <th>v85_x</th>\n",
       "      <th>v85_y</th>\n",
       "      <th>v86</th>\n",
       "      <th>v88</th>\n",
       "      <th>v9</th>\n",
       "      <th>v90</th>\n",
       "      <th>v91</th>\n",
       "      <th>v92</th>\n",
       "      <th>v93</th>\n",
       "      <th>v94</th>\n",
       "      <th>v98</th>\n",
       "      <th>v99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>-91.710680</td>\n",
       "      <td>27.716370</td>\n",
       "      <td>54.711456</td>\n",
       "      <td>120.17605</td>\n",
       "      <td>49.214336</td>\n",
       "      <td>39.819320</td>\n",
       "      <td>6.008493</td>\n",
       "      <td>0.239730</td>\n",
       "      <td>-2.993159</td>\n",
       "      <td>-28.929620</td>\n",
       "      <td>74.760445</td>\n",
       "      <td>96.09949</td>\n",
       "      <td>-0.003843</td>\n",
       "      <td>-0.001623</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>-0.000946</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>-0.001772</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>-0.000800</td>\n",
       "      <td>-0.000453</td>\n",
       "      <td>-0.001254</td>\n",
       "      <td>-48.164520</td>\n",
       "      <td>-0.424896</td>\n",
       "      <td>2.754712</td>\n",
       "      <td>-1.715571</td>\n",
       "      <td>1.603576</td>\n",
       "      <td>-0.998099</td>\n",
       "      <td>-14.700655</td>\n",
       "      <td>-1.278328</td>\n",
       "      <td>8.710470</td>\n",
       "      <td>2.471012</td>\n",
       "      <td>3.199084</td>\n",
       "      <td>-0.098913</td>\n",
       "      <td>-1.847689</td>\n",
       "      <td>-2.408795</td>\n",
       "      <td>-29.066944</td>\n",
       "      <td>22.876034</td>\n",
       "      <td>-31.847212</td>\n",
       "      <td>9.526614</td>\n",
       "      <td>-133.76234</td>\n",
       "      <td>5.287480</td>\n",
       "      <td>17.142406</td>\n",
       "      <td>-20.641521</td>\n",
       "      <td>-0.262313</td>\n",
       "      <td>-36.283512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153.40079</td>\n",
       "      <td>0.464463</td>\n",
       "      <td>1.347929</td>\n",
       "      <td>2.678761</td>\n",
       "      <td>-62.110138</td>\n",
       "      <td>-3.816818</td>\n",
       "      <td>7.057063</td>\n",
       "      <td>-13.019275</td>\n",
       "      <td>-1.451880</td>\n",
       "      <td>8.745543</td>\n",
       "      <td>2.470521</td>\n",
       "      <td>3.073173</td>\n",
       "      <td>1.335739</td>\n",
       "      <td>0.503281</td>\n",
       "      <td>19.470200</td>\n",
       "      <td>8.389236</td>\n",
       "      <td>2.757375</td>\n",
       "      <td>4.374296</td>\n",
       "      <td>1.574039</td>\n",
       "      <td>0.007294</td>\n",
       "      <td>12.579185</td>\n",
       "      <td>E</td>\n",
       "      <td>2.382692</td>\n",
       "      <td>3.930922</td>\n",
       "      <td>16.434109</td>\n",
       "      <td>B</td>\n",
       "      <td>0.433213</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.634908</td>\n",
       "      <td>2.857144</td>\n",
       "      <td>1.951220</td>\n",
       "      <td>6.592012</td>\n",
       "      <td>5.909091</td>\n",
       "      <td>-1.253049e-06</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-1.075170e-06</td>\n",
       "      <td>3.965754e-13</td>\n",
       "      <td>-6.297423e-07</td>\n",
       "      <td>-6.297423e-07</td>\n",
       "      <td>1.059603</td>\n",
       "      <td>0.803572</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>24.219074</td>\n",
       "      <td>3.397185</td>\n",
       "      <td>3.959225</td>\n",
       "      <td>1.989780</td>\n",
       "      <td>1.989780</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>AU</td>\n",
       "      <td>1.804126</td>\n",
       "      <td>3.113719</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>2.857144</td>\n",
       "      <td>11.636387</td>\n",
       "      <td>1.355013</td>\n",
       "      <td>8.571428</td>\n",
       "      <td>3.670350</td>\n",
       "      <td>0.106720</td>\n",
       "      <td>0.138790</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>18.869284</td>\n",
       "      <td>7.730923</td>\n",
       "      <td>XDX</td>\n",
       "      <td>-1.716131e-08</td>\n",
       "      <td>C</td>\n",
       "      <td>1.720818</td>\n",
       "      <td>3.393503</td>\n",
       "      <td>0.590122</td>\n",
       "      <td>8.880867</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>8.375452</td>\n",
       "      <td>11.326591</td>\n",
       "      <td>0.454546</td>\n",
       "      <td>4.012088</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.711453</td>\n",
       "      <td>12.707581</td>\n",
       "      <td>10.498338</td>\n",
       "      <td>9.848672</td>\n",
       "      <td>C</td>\n",
       "      <td>20.781006</td>\n",
       "      <td>148.15110</td>\n",
       "      <td>12.171734</td>\n",
       "      <td>12.171734</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>0.899420</td>\n",
       "      <td>7.277793</td>\n",
       "      <td>G</td>\n",
       "      <td>DI</td>\n",
       "      <td>3.971118</td>\n",
       "      <td>0.529802</td>\n",
       "      <td>10.890984</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>15.858151</td>\n",
       "      <td>-6.297423e-07</td>\n",
       "      <td>1.989780</td>\n",
       "      <td>12.171734</td>\n",
       "      <td>1.707317</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C</td>\n",
       "      <td>15.231789</td>\n",
       "      <td>17.142857</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>11.784549</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>E</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.528326</td>\n",
       "      <td>8.861647</td>\n",
       "      <td>1.299638</td>\n",
       "      <td>2.914931</td>\n",
       "      <td>1.707317</td>\n",
       "      <td>1.707317</td>\n",
       "      <td>0.866426</td>\n",
       "      <td>3.321300</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>0.905342</td>\n",
       "      <td>A</td>\n",
       "      <td>0.442252</td>\n",
       "      <td>5.814018</td>\n",
       "      <td>3.517721</td>\n",
       "      <td>8.877414</td>\n",
       "      <td>1.191337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>-93.247940</td>\n",
       "      <td>38.592617</td>\n",
       "      <td>54.511680</td>\n",
       "      <td>123.92817</td>\n",
       "      <td>48.573597</td>\n",
       "      <td>45.229984</td>\n",
       "      <td>7.246580</td>\n",
       "      <td>-17.264480</td>\n",
       "      <td>0.030932</td>\n",
       "      <td>-14.308875</td>\n",
       "      <td>94.821140</td>\n",
       "      <td>91.57980</td>\n",
       "      <td>-0.000614</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>-0.004100</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>-0.003999</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>-25.950914</td>\n",
       "      <td>1.779193</td>\n",
       "      <td>-2.487668</td>\n",
       "      <td>-0.286266</td>\n",
       "      <td>5.677019</td>\n",
       "      <td>-0.396850</td>\n",
       "      <td>-0.618112</td>\n",
       "      <td>12.524258</td>\n",
       "      <td>1.614324</td>\n",
       "      <td>-1.088056</td>\n",
       "      <td>-5.308384</td>\n",
       "      <td>1.685836</td>\n",
       "      <td>0.007697</td>\n",
       "      <td>2.013834</td>\n",
       "      <td>-28.929590</td>\n",
       "      <td>57.018020</td>\n",
       "      <td>-27.310768</td>\n",
       "      <td>18.562830</td>\n",
       "      <td>-157.43951</td>\n",
       "      <td>14.462655</td>\n",
       "      <td>9.338835</td>\n",
       "      <td>-19.964195</td>\n",
       "      <td>-7.352732</td>\n",
       "      <td>-38.573727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.01410</td>\n",
       "      <td>0.914076</td>\n",
       "      <td>-2.541605</td>\n",
       "      <td>-1.772064</td>\n",
       "      <td>-48.366608</td>\n",
       "      <td>-0.820012</td>\n",
       "      <td>1.806945</td>\n",
       "      <td>0.119447</td>\n",
       "      <td>12.426791</td>\n",
       "      <td>1.585607</td>\n",
       "      <td>-1.087751</td>\n",
       "      <td>-5.426009</td>\n",
       "      <td>1.469550</td>\n",
       "      <td>1.312910</td>\n",
       "      <td>14.475939</td>\n",
       "      <td>6.623713</td>\n",
       "      <td>2.462898</td>\n",
       "      <td>5.125846</td>\n",
       "      <td>2.512034</td>\n",
       "      <td>1.505335</td>\n",
       "      <td>12.085176</td>\n",
       "      <td>B</td>\n",
       "      <td>1.825361</td>\n",
       "      <td>4.247858</td>\n",
       "      <td>15.495952</td>\n",
       "      <td>A</td>\n",
       "      <td>3.108809</td>\n",
       "      <td>U</td>\n",
       "      <td>G</td>\n",
       "      <td>10.308044</td>\n",
       "      <td>10.476191</td>\n",
       "      <td>2.222223</td>\n",
       "      <td>10.595357</td>\n",
       "      <td>8.136964</td>\n",
       "      <td>4.003565e+00</td>\n",
       "      <td>18.140322</td>\n",
       "      <td>3.792658e+00</td>\n",
       "      <td>2.136160e+00</td>\n",
       "      <td>1.461561e+00</td>\n",
       "      <td>1.461561e+00</td>\n",
       "      <td>1.144708</td>\n",
       "      <td>2.436195</td>\n",
       "      <td>6.749117</td>\n",
       "      <td>33.998367</td>\n",
       "      <td>7.108153</td>\n",
       "      <td>7.503433</td>\n",
       "      <td>2.739240</td>\n",
       "      <td>2.739240</td>\n",
       "      <td>0.598896</td>\n",
       "      <td>AF</td>\n",
       "      <td>1.614802</td>\n",
       "      <td>2.963620</td>\n",
       "      <td>0</td>\n",
       "      <td>1.560137</td>\n",
       "      <td>1.589403</td>\n",
       "      <td>11.636386</td>\n",
       "      <td>1.992031</td>\n",
       "      <td>4.932127</td>\n",
       "      <td>3.554267</td>\n",
       "      <td>0.773906</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>7.023803</td>\n",
       "      <td>18.036585</td>\n",
       "      <td>6.763110</td>\n",
       "      <td>GUV</td>\n",
       "      <td>1.845672e-07</td>\n",
       "      <td>C</td>\n",
       "      <td>1.826276</td>\n",
       "      <td>2.673322</td>\n",
       "      <td>5.043831</td>\n",
       "      <td>8.296139</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>8.068506</td>\n",
       "      <td>14.579479</td>\n",
       "      <td>0.642856</td>\n",
       "      <td>0.378418</td>\n",
       "      <td>4.205991</td>\n",
       "      <td>14.305766</td>\n",
       "      <td>12.934363</td>\n",
       "      <td>10.782008</td>\n",
       "      <td>9.156046</td>\n",
       "      <td>E</td>\n",
       "      <td>32.207340</td>\n",
       "      <td>154.04800</td>\n",
       "      <td>12.411608</td>\n",
       "      <td>12.411608</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>1.379210</td>\n",
       "      <td>7.134018</td>\n",
       "      <td>G</td>\n",
       "      <td>DY</td>\n",
       "      <td>4.067039</td>\n",
       "      <td>5.330551</td>\n",
       "      <td>10.535108</td>\n",
       "      <td>2.412790</td>\n",
       "      <td>15.075894</td>\n",
       "      <td>2.923122e+00</td>\n",
       "      <td>5.478479</td>\n",
       "      <td>24.823215</td>\n",
       "      <td>5.189874</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>18.274548</td>\n",
       "      <td>9.516129</td>\n",
       "      <td>2.452166</td>\n",
       "      <td>12.053353</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>13.333334</td>\n",
       "      <td>D</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>7.277655</td>\n",
       "      <td>3.430692</td>\n",
       "      <td>1.423294</td>\n",
       "      <td>6.733697</td>\n",
       "      <td>2.594937</td>\n",
       "      <td>2.594937</td>\n",
       "      <td>1.158301</td>\n",
       "      <td>1.761547</td>\n",
       "      <td>9.059583</td>\n",
       "      <td>0.969183</td>\n",
       "      <td>B</td>\n",
       "      <td>0.542669</td>\n",
       "      <td>5.301047</td>\n",
       "      <td>3.743106</td>\n",
       "      <td>8.303966</td>\n",
       "      <td>1.235546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>-93.173170</td>\n",
       "      <td>27.098150</td>\n",
       "      <td>54.806860</td>\n",
       "      <td>122.12799</td>\n",
       "      <td>50.506966</td>\n",
       "      <td>41.667606</td>\n",
       "      <td>18.028326</td>\n",
       "      <td>-16.219355</td>\n",
       "      <td>-0.176257</td>\n",
       "      <td>-19.010742</td>\n",
       "      <td>92.564230</td>\n",
       "      <td>82.86307</td>\n",
       "      <td>-0.003126</td>\n",
       "      <td>-0.009395</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>-0.002771</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.003719</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>-0.000804</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>-0.000774</td>\n",
       "      <td>-38.115150</td>\n",
       "      <td>-9.903248</td>\n",
       "      <td>0.260174</td>\n",
       "      <td>-0.687128</td>\n",
       "      <td>17.070390</td>\n",
       "      <td>1.689260</td>\n",
       "      <td>-8.619469</td>\n",
       "      <td>-1.635108</td>\n",
       "      <td>12.980241</td>\n",
       "      <td>-0.603744</td>\n",
       "      <td>-0.164112</td>\n",
       "      <td>7.184428</td>\n",
       "      <td>1.045899</td>\n",
       "      <td>5.407090</td>\n",
       "      <td>-26.200660</td>\n",
       "      <td>33.874940</td>\n",
       "      <td>-36.593500</td>\n",
       "      <td>20.014290</td>\n",
       "      <td>-145.68756</td>\n",
       "      <td>9.170828</td>\n",
       "      <td>3.110579</td>\n",
       "      <td>-32.030480</td>\n",
       "      <td>-19.990597</td>\n",
       "      <td>-39.241848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>167.82260</td>\n",
       "      <td>3.004430</td>\n",
       "      <td>9.587715</td>\n",
       "      <td>-2.677776</td>\n",
       "      <td>-62.600937</td>\n",
       "      <td>5.930745</td>\n",
       "      <td>-1.857007</td>\n",
       "      <td>-9.216124</td>\n",
       "      <td>-1.709030</td>\n",
       "      <td>14.247915</td>\n",
       "      <td>-0.606809</td>\n",
       "      <td>-2.938097</td>\n",
       "      <td>0.943877</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>15.491329</td>\n",
       "      <td>5.879353</td>\n",
       "      <td>3.292788</td>\n",
       "      <td>5.924457</td>\n",
       "      <td>1.668401</td>\n",
       "      <td>0.008275</td>\n",
       "      <td>11.670572</td>\n",
       "      <td>C</td>\n",
       "      <td>1.375753</td>\n",
       "      <td>1.184211</td>\n",
       "      <td>14.756098</td>\n",
       "      <td>B</td>\n",
       "      <td>3.367348</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.205562</td>\n",
       "      <td>12.941177</td>\n",
       "      <td>3.129252</td>\n",
       "      <td>3.478911</td>\n",
       "      <td>6.233767</td>\n",
       "      <td>-6.919294e-07</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-6.786108e-07</td>\n",
       "      <td>7.799425e-14</td>\n",
       "      <td>-2.792745e-07</td>\n",
       "      <td>-2.792745e-07</td>\n",
       "      <td>2.138728</td>\n",
       "      <td>2.238806</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>31.493532</td>\n",
       "      <td>6.020325</td>\n",
       "      <td>6.138481</td>\n",
       "      <td>2.477596</td>\n",
       "      <td>2.477596</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>AE</td>\n",
       "      <td>1.773709</td>\n",
       "      <td>3.922193</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883118</td>\n",
       "      <td>1.176472</td>\n",
       "      <td>9.603541</td>\n",
       "      <td>1.984127</td>\n",
       "      <td>5.882352</td>\n",
       "      <td>3.170847</td>\n",
       "      <td>0.244541</td>\n",
       "      <td>0.134757</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>17.952332</td>\n",
       "      <td>5.245035</td>\n",
       "      <td>FQ</td>\n",
       "      <td>-2.785053e-07</td>\n",
       "      <td>E</td>\n",
       "      <td>2.244897</td>\n",
       "      <td>5.306122</td>\n",
       "      <td>0.836005</td>\n",
       "      <td>7.499999</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>7.959184</td>\n",
       "      <td>12.730516</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>7.378964</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>13.077201</td>\n",
       "      <td>12.346939</td>\n",
       "      <td>8.897560</td>\n",
       "      <td>5.343819</td>\n",
       "      <td>C</td>\n",
       "      <td>30.887331</td>\n",
       "      <td>161.57785</td>\n",
       "      <td>12.711328</td>\n",
       "      <td>12.711328</td>\n",
       "      <td>5.326160</td>\n",
       "      <td>0.604504</td>\n",
       "      <td>9.637628</td>\n",
       "      <td>F</td>\n",
       "      <td>AS</td>\n",
       "      <td>4.030613</td>\n",
       "      <td>4.277456</td>\n",
       "      <td>9.105481</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>16.075602</td>\n",
       "      <td>-2.792745e-07</td>\n",
       "      <td>2.477596</td>\n",
       "      <td>12.711328</td>\n",
       "      <td>2.429906</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>11.040463</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>8.460654</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>11.764705</td>\n",
       "      <td>E</td>\n",
       "      <td>3.333334</td>\n",
       "      <td>10.194432</td>\n",
       "      <td>8.266199</td>\n",
       "      <td>1.530613</td>\n",
       "      <td>5.904443</td>\n",
       "      <td>2.429906</td>\n",
       "      <td>2.429906</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>3.367346</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0.811447</td>\n",
       "      <td>G</td>\n",
       "      <td>0.271480</td>\n",
       "      <td>5.156560</td>\n",
       "      <td>4.214944</td>\n",
       "      <td>11.588858</td>\n",
       "      <td>0.841837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>-84.856930</td>\n",
       "      <td>31.718266</td>\n",
       "      <td>40.140420</td>\n",
       "      <td>119.73096</td>\n",
       "      <td>47.808308</td>\n",
       "      <td>47.343600</td>\n",
       "      <td>9.107174</td>\n",
       "      <td>-4.467571</td>\n",
       "      <td>-2.826444</td>\n",
       "      <td>-32.088654</td>\n",
       "      <td>70.519640</td>\n",
       "      <td>96.08720</td>\n",
       "      <td>-0.002676</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>-0.000576</td>\n",
       "      <td>-0.001072</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>-0.007559</td>\n",
       "      <td>-44.795555</td>\n",
       "      <td>-0.982714</td>\n",
       "      <td>6.848362</td>\n",
       "      <td>2.784330</td>\n",
       "      <td>-0.511768</td>\n",
       "      <td>-5.436988</td>\n",
       "      <td>-13.713540</td>\n",
       "      <td>-1.863892</td>\n",
       "      <td>3.849380</td>\n",
       "      <td>2.223841</td>\n",
       "      <td>-3.667469</td>\n",
       "      <td>-3.011027</td>\n",
       "      <td>-6.738361</td>\n",
       "      <td>0.335619</td>\n",
       "      <td>-15.731087</td>\n",
       "      <td>20.106495</td>\n",
       "      <td>-34.675130</td>\n",
       "      <td>1.853619</td>\n",
       "      <td>-141.46463</td>\n",
       "      <td>9.822379</td>\n",
       "      <td>10.091172</td>\n",
       "      <td>-19.457485</td>\n",
       "      <td>-6.309244</td>\n",
       "      <td>-34.524216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>155.97241</td>\n",
       "      <td>-3.106392</td>\n",
       "      <td>2.676349</td>\n",
       "      <td>6.097450</td>\n",
       "      <td>-59.753407</td>\n",
       "      <td>-9.191820</td>\n",
       "      <td>7.248538</td>\n",
       "      <td>-11.691413</td>\n",
       "      <td>-2.025400</td>\n",
       "      <td>3.205872</td>\n",
       "      <td>2.224963</td>\n",
       "      <td>-2.602192</td>\n",
       "      <td>0.797415</td>\n",
       "      <td>6.542669</td>\n",
       "      <td>18.256351</td>\n",
       "      <td>8.507280</td>\n",
       "      <td>2.503055</td>\n",
       "      <td>4.872158</td>\n",
       "      <td>2.573664</td>\n",
       "      <td>0.113967</td>\n",
       "      <td>12.554274</td>\n",
       "      <td>B</td>\n",
       "      <td>2.230754</td>\n",
       "      <td>1.990131</td>\n",
       "      <td>16.347483</td>\n",
       "      <td>B</td>\n",
       "      <td>2.643678</td>\n",
       "      <td>J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.777666</td>\n",
       "      <td>10.574713</td>\n",
       "      <td>1.511063</td>\n",
       "      <td>4.949609</td>\n",
       "      <td>7.180722</td>\n",
       "      <td>1.025151e+00</td>\n",
       "      <td>6.896295</td>\n",
       "      <td>8.974875e-01</td>\n",
       "      <td>3.198000e-01</td>\n",
       "      <td>5.655087e-01</td>\n",
       "      <td>5.655087e-01</td>\n",
       "      <td>1.166281</td>\n",
       "      <td>1.956521</td>\n",
       "      <td>7.018256</td>\n",
       "      <td>22.106771</td>\n",
       "      <td>2.876987</td>\n",
       "      <td>3.286226</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>CJ</td>\n",
       "      <td>1.415230</td>\n",
       "      <td>2.954381</td>\n",
       "      <td>1</td>\n",
       "      <td>1.677108</td>\n",
       "      <td>1.034483</td>\n",
       "      <td>14.094723</td>\n",
       "      <td>1.945044</td>\n",
       "      <td>5.517242</td>\n",
       "      <td>3.610789</td>\n",
       "      <td>1.224114</td>\n",
       "      <td>0.208339</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>18.376408</td>\n",
       "      <td>7.517125</td>\n",
       "      <td>ACUE</td>\n",
       "      <td>-4.805344e-07</td>\n",
       "      <td>D</td>\n",
       "      <td>1.308269</td>\n",
       "      <td>2.303640</td>\n",
       "      <td>8.926662</td>\n",
       "      <td>8.874520</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>8.898468</td>\n",
       "      <td>11.302795</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.287322</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.523045</td>\n",
       "      <td>12.935823</td>\n",
       "      <td>12.708574</td>\n",
       "      <td>9.670823</td>\n",
       "      <td>C</td>\n",
       "      <td>19.353779</td>\n",
       "      <td>148.71448</td>\n",
       "      <td>12.194855</td>\n",
       "      <td>12.194855</td>\n",
       "      <td>11.627439</td>\n",
       "      <td>3.329176</td>\n",
       "      <td>4.780357</td>\n",
       "      <td>H</td>\n",
       "      <td>BW</td>\n",
       "      <td>3.965517</td>\n",
       "      <td>1.732102</td>\n",
       "      <td>11.777912</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>15.927390</td>\n",
       "      <td>5.655087e-01</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>12.194855</td>\n",
       "      <td>1.587045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>18.568129</td>\n",
       "      <td>9.425287</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>13.594727</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>13.448277</td>\n",
       "      <td>B</td>\n",
       "      <td>1.947261</td>\n",
       "      <td>4.797873</td>\n",
       "      <td>13.315820</td>\n",
       "      <td>1.379310</td>\n",
       "      <td>2.518711</td>\n",
       "      <td>1.587045</td>\n",
       "      <td>1.587045</td>\n",
       "      <td>1.242817</td>\n",
       "      <td>1.408046</td>\n",
       "      <td>8.965516</td>\n",
       "      <td>1.042425</td>\n",
       "      <td>B</td>\n",
       "      <td>0.763925</td>\n",
       "      <td>5.498902</td>\n",
       "      <td>3.423944</td>\n",
       "      <td>6.942002</td>\n",
       "      <td>1.334611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>-94.072464</td>\n",
       "      <td>37.100567</td>\n",
       "      <td>46.883675</td>\n",
       "      <td>126.04482</td>\n",
       "      <td>45.960175</td>\n",
       "      <td>42.723210</td>\n",
       "      <td>9.226593</td>\n",
       "      <td>-14.774398</td>\n",
       "      <td>1.247865</td>\n",
       "      <td>-20.247840</td>\n",
       "      <td>90.882720</td>\n",
       "      <td>89.35329</td>\n",
       "      <td>-0.000492</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>-0.000739</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000297</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>-26.297642</td>\n",
       "      <td>1.164047</td>\n",
       "      <td>-1.712914</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>5.217902</td>\n",
       "      <td>-0.014489</td>\n",
       "      <td>-0.537369</td>\n",
       "      <td>-0.370327</td>\n",
       "      <td>0.801410</td>\n",
       "      <td>0.351222</td>\n",
       "      <td>0.653618</td>\n",
       "      <td>-0.431471</td>\n",
       "      <td>0.837381</td>\n",
       "      <td>-1.831667</td>\n",
       "      <td>-29.112070</td>\n",
       "      <td>42.456104</td>\n",
       "      <td>-29.633032</td>\n",
       "      <td>16.808092</td>\n",
       "      <td>-157.43951</td>\n",
       "      <td>14.462655</td>\n",
       "      <td>9.338835</td>\n",
       "      <td>-21.292480</td>\n",
       "      <td>-9.871851</td>\n",
       "      <td>-36.437650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.87088</td>\n",
       "      <td>-0.078218</td>\n",
       "      <td>-1.792219</td>\n",
       "      <td>-1.073189</td>\n",
       "      <td>-47.781850</td>\n",
       "      <td>-0.078944</td>\n",
       "      <td>0.665971</td>\n",
       "      <td>-0.354514</td>\n",
       "      <td>-0.395111</td>\n",
       "      <td>0.769250</td>\n",
       "      <td>0.351135</td>\n",
       "      <td>0.765010</td>\n",
       "      <td>1.469550</td>\n",
       "      <td>1.050328</td>\n",
       "      <td>14.475939</td>\n",
       "      <td>6.623713</td>\n",
       "      <td>2.462898</td>\n",
       "      <td>5.125846</td>\n",
       "      <td>2.512034</td>\n",
       "      <td>0.242556</td>\n",
       "      <td>12.085176</td>\n",
       "      <td>C</td>\n",
       "      <td>1.980834</td>\n",
       "      <td>3.087909</td>\n",
       "      <td>15.495952</td>\n",
       "      <td>A</td>\n",
       "      <td>3.108809</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>14.097098</td>\n",
       "      <td>10.476191</td>\n",
       "      <td>2.222223</td>\n",
       "      <td>8.070175</td>\n",
       "      <td>8.136964</td>\n",
       "      <td>4.003565e+00</td>\n",
       "      <td>18.140322</td>\n",
       "      <td>3.792658e+00</td>\n",
       "      <td>2.136160e+00</td>\n",
       "      <td>1.461561e+00</td>\n",
       "      <td>1.461561e+00</td>\n",
       "      <td>1.144708</td>\n",
       "      <td>2.436195</td>\n",
       "      <td>6.749117</td>\n",
       "      <td>33.998367</td>\n",
       "      <td>7.108153</td>\n",
       "      <td>7.503433</td>\n",
       "      <td>2.739240</td>\n",
       "      <td>2.739240</td>\n",
       "      <td>0.139864</td>\n",
       "      <td>Z</td>\n",
       "      <td>1.614802</td>\n",
       "      <td>2.963620</td>\n",
       "      <td>0</td>\n",
       "      <td>1.560137</td>\n",
       "      <td>1.589403</td>\n",
       "      <td>10.991097</td>\n",
       "      <td>1.992031</td>\n",
       "      <td>4.932127</td>\n",
       "      <td>3.554267</td>\n",
       "      <td>0.773906</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>7.023803</td>\n",
       "      <td>18.036585</td>\n",
       "      <td>6.414567</td>\n",
       "      <td>HIT</td>\n",
       "      <td>1.845672e-07</td>\n",
       "      <td>E</td>\n",
       "      <td>1.826276</td>\n",
       "      <td>2.673322</td>\n",
       "      <td>5.043831</td>\n",
       "      <td>8.296139</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>8.068506</td>\n",
       "      <td>13.765616</td>\n",
       "      <td>0.642856</td>\n",
       "      <td>0.378418</td>\n",
       "      <td>4.205991</td>\n",
       "      <td>10.138920</td>\n",
       "      <td>12.934363</td>\n",
       "      <td>10.782008</td>\n",
       "      <td>9.156046</td>\n",
       "      <td>I</td>\n",
       "      <td>32.207340</td>\n",
       "      <td>154.04800</td>\n",
       "      <td>12.411608</td>\n",
       "      <td>12.411608</td>\n",
       "      <td>8.670867</td>\n",
       "      <td>1.364536</td>\n",
       "      <td>7.134018</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.067039</td>\n",
       "      <td>5.330551</td>\n",
       "      <td>10.535108</td>\n",
       "      <td>2.412790</td>\n",
       "      <td>15.075894</td>\n",
       "      <td>1.461561e+00</td>\n",
       "      <td>2.739240</td>\n",
       "      <td>12.411608</td>\n",
       "      <td>2.594937</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C</td>\n",
       "      <td>18.274548</td>\n",
       "      <td>9.516129</td>\n",
       "      <td>2.452166</td>\n",
       "      <td>12.494872</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>13.333334</td>\n",
       "      <td>C</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>7.517742</td>\n",
       "      <td>3.688459</td>\n",
       "      <td>1.423294</td>\n",
       "      <td>6.733697</td>\n",
       "      <td>2.594937</td>\n",
       "      <td>2.594937</td>\n",
       "      <td>1.158301</td>\n",
       "      <td>1.761547</td>\n",
       "      <td>9.059583</td>\n",
       "      <td>0.969183</td>\n",
       "      <td>G</td>\n",
       "      <td>0.542669</td>\n",
       "      <td>5.301047</td>\n",
       "      <td>3.743106</td>\n",
       "      <td>7.644154</td>\n",
       "      <td>1.235546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      grp_1     grp_10     grp_11     grp_12      grp_2      grp_3  \\\n",
       "0   3 -91.710680  27.716370  54.711456  120.17605  49.214336  39.819320   \n",
       "1   4 -93.247940  38.592617  54.511680  123.92817  48.573597  45.229984   \n",
       "2   5 -93.173170  27.098150  54.806860  122.12799  50.506966  41.667606   \n",
       "3   6 -84.856930  31.718266  40.140420  119.73096  47.808308  47.343600   \n",
       "4   8 -94.072464  37.100567  46.883675  126.04482  45.960175  42.723210   \n",
       "\n",
       "       grp_4      grp_5     grp_6      grp_7      grp_8     grp_9     ica_1  \\\n",
       "0   6.008493   0.239730 -2.993159 -28.929620  74.760445  96.09949 -0.003843   \n",
       "1   7.246580 -17.264480  0.030932 -14.308875  94.821140  91.57980 -0.000614   \n",
       "2  18.028326 -16.219355 -0.176257 -19.010742  92.564230  82.86307 -0.003126   \n",
       "3   9.107174  -4.467571 -2.826444 -32.088654  70.519640  96.08720 -0.002676   \n",
       "4   9.226593 -14.774398  1.247865 -20.247840  90.882720  89.35329 -0.000492   \n",
       "\n",
       "     ica_10    ica_11    ica_12     ica_2     ica_3     ica_4     ica_5  \\\n",
       "0 -0.001623  0.000137  0.000271 -0.000946  0.002434 -0.001772 -0.000151   \n",
       "1  0.001376  0.000588 -0.004100  0.000371 -0.003999 -0.000468 -0.000084   \n",
       "2 -0.009395  0.000051  0.000103 -0.000203 -0.002771 -0.000622 -0.003719   \n",
       "3  0.001442  0.000254  0.000359  0.000605 -0.000728 -0.000576 -0.001072   \n",
       "4  0.000568  0.000501  0.000123  0.000532  0.000437 -0.000739  0.000006   \n",
       "\n",
       "      ica_6     ica_7     ica_8     ica_9      pca_1    pca_10    pca_11  \\\n",
       "0  0.003242 -0.000800 -0.000453 -0.001254 -48.164520 -0.424896  2.754712   \n",
       "1 -0.000147  0.000706 -0.000207  0.001949 -25.950914  1.779193 -2.487668   \n",
       "2  0.000614 -0.000804 -0.000271 -0.000774 -38.115150 -9.903248  0.260174   \n",
       "3  0.002642  0.000579  0.000567 -0.007559 -44.795555 -0.982714  6.848362   \n",
       "4 -0.000297  0.000705 -0.000112  0.001467 -26.297642  1.164047 -1.712914   \n",
       "\n",
       "     pca_12      pca_2     pca_3      pca_4      pca_5      pca_6     pca_7  \\\n",
       "0 -1.715571   1.603576 -0.998099 -14.700655  -1.278328   8.710470  2.471012   \n",
       "1 -0.286266   5.677019 -0.396850  -0.618112  12.524258   1.614324 -1.088056   \n",
       "2 -0.687128  17.070390  1.689260  -8.619469  -1.635108  12.980241 -0.603744   \n",
       "3  2.784330  -0.511768 -5.436988 -13.713540  -1.863892   3.849380  2.223841   \n",
       "4  0.004744   5.217902 -0.014489  -0.537369  -0.370327   0.801410  0.351222   \n",
       "\n",
       "      pca_8     pca_9     srp_1    srp_10     srp_11     srp_12      srp_2  \\\n",
       "0  3.199084 -0.098913 -1.847689 -2.408795 -29.066944  22.876034 -31.847212   \n",
       "1 -5.308384  1.685836  0.007697  2.013834 -28.929590  57.018020 -27.310768   \n",
       "2 -0.164112  7.184428  1.045899  5.407090 -26.200660  33.874940 -36.593500   \n",
       "3 -3.667469 -3.011027 -6.738361  0.335619 -15.731087  20.106495 -34.675130   \n",
       "4  0.653618 -0.431471  0.837381 -1.831667 -29.112070  42.456104 -29.633032   \n",
       "\n",
       "       srp_3      srp_4      srp_5      srp_6      srp_7      srp_8  \\\n",
       "0   9.526614 -133.76234   5.287480  17.142406 -20.641521  -0.262313   \n",
       "1  18.562830 -157.43951  14.462655   9.338835 -19.964195  -7.352732   \n",
       "2  20.014290 -145.68756   9.170828   3.110579 -32.030480 -19.990597   \n",
       "3   1.853619 -141.46463   9.822379  10.091172 -19.457485  -6.309244   \n",
       "4  16.808092 -157.43951  14.462655   9.338835 -21.292480  -9.871851   \n",
       "\n",
       "       srp_9  target     tsvd_1   tsvd_10   tsvd_11   tsvd_12     tsvd_2  \\\n",
       "0 -36.283512     1.0  153.40079  0.464463  1.347929  2.678761 -62.110138   \n",
       "1 -38.573727     1.0  171.01410  0.914076 -2.541605 -1.772064 -48.366608   \n",
       "2 -39.241848     1.0  167.82260  3.004430  9.587715 -2.677776 -62.600937   \n",
       "3 -34.524216     1.0  155.97241 -3.106392  2.676349  6.097450 -59.753407   \n",
       "4 -36.437650     1.0  169.87088 -0.078218 -1.792219 -1.073189 -47.781850   \n",
       "\n",
       "     tsvd_3    tsvd_4     tsvd_5     tsvd_6     tsvd_7    tsvd_8    tsvd_9  \\\n",
       "0 -3.816818  7.057063 -13.019275  -1.451880   8.745543  2.470521  3.073173   \n",
       "1 -0.820012  1.806945   0.119447  12.426791   1.585607 -1.087751 -5.426009   \n",
       "2  5.930745 -1.857007  -9.216124  -1.709030  14.247915 -0.606809 -2.938097   \n",
       "3 -9.191820  7.248538 -11.691413  -2.025400   3.205872  2.224963 -2.602192   \n",
       "4 -0.078944  0.665971  -0.354514  -0.395111   0.769250  0.351135  0.765010   \n",
       "\n",
       "         v1       v10       v100      v101      v102      v103      v104  \\\n",
       "0  1.335739  0.503281  19.470200  8.389236  2.757375  4.374296  1.574039   \n",
       "1  1.469550  1.312910  14.475939  6.623713  2.462898  5.125846  2.512034   \n",
       "2  0.943877  0.765864  15.491329  5.879353  3.292788  5.924457  1.668401   \n",
       "3  0.797415  6.542669  18.256351  8.507280  2.503055  4.872158  2.573664   \n",
       "4  1.469550  1.050328  14.475939  6.623713  2.462898  5.125846  2.512034   \n",
       "\n",
       "       v105       v106 v107      v108      v109        v11 v110      v111  \\\n",
       "0  0.007294  12.579185    E  2.382692  3.930922  16.434109    B  0.433213   \n",
       "1  1.505335  12.085176    B  1.825361  4.247858  15.495952    A  3.108809   \n",
       "2  0.008275  11.670572    C  1.375753  1.184211  14.756098    B  3.367348   \n",
       "3  0.113967  12.554274    B  2.230754  1.990131  16.347483    B  2.643678   \n",
       "4  0.242556  12.085176    C  1.980834  3.087909  15.495952    A  3.108809   \n",
       "\n",
       "  v112 v113       v114       v115      v116       v117      v118  \\\n",
       "0    O  NaN  15.634908   2.857144  1.951220   6.592012  5.909091   \n",
       "1    U    G  10.308044  10.476191  2.222223  10.595357  8.136964   \n",
       "2    S  NaN  11.205562  12.941177  3.129252   3.478911  6.233767   \n",
       "3    J  NaN  13.777666  10.574713  1.511063   4.949609  7.180722   \n",
       "4    T    G  14.097098  10.476191  2.222223   8.070175  8.136964   \n",
       "\n",
       "      v119 v123   v119 v48      v119 v85        v119^2        v119_x  \\\n",
       "0 -1.253049e-06  -0.000008 -1.075170e-06  3.965754e-13 -6.297423e-07   \n",
       "1  4.003565e+00  18.140322  3.792658e+00  2.136160e+00  1.461561e+00   \n",
       "2 -6.919294e-07  -0.000004 -6.786108e-07  7.799425e-14 -2.792745e-07   \n",
       "3  1.025151e+00   6.896295  8.974875e-01  3.198000e-01  5.655087e-01   \n",
       "4  4.003565e+00  18.140322  3.792658e+00  2.136160e+00  1.461561e+00   \n",
       "\n",
       "         v119_y      v120      v121      v122   v123 v48  v123 v85    v123^2  \\\n",
       "0 -6.297423e-07  1.059603  0.803572  8.000000  24.219074  3.397185  3.959225   \n",
       "1  1.461561e+00  1.144708  2.436195  6.749117  33.998367  7.108153  7.503433   \n",
       "2 -2.792745e-07  2.138728  2.238806  9.333333  31.493532  6.020325  6.138481   \n",
       "3  5.655087e-01  1.166281  1.956521  7.018256  22.106771  2.876987  3.286226   \n",
       "4  1.461561e+00  1.144708  2.436195  6.749117  33.998367  7.108153  7.503433   \n",
       "\n",
       "     v123_x    v123_y      v124 v125      v126      v127  v129      v130  \\\n",
       "0  1.989780  1.989780  0.035754   AU  1.804126  3.113719     0  0.636364   \n",
       "1  2.739240  2.739240  0.598896   AF  1.614802  2.963620     0  1.560137   \n",
       "2  2.477596  2.477596  0.013452   AE  1.773709  3.922193     2  0.883118   \n",
       "3  1.812795  1.812795  0.002267   CJ  1.415230  2.954381     1  1.677108   \n",
       "4  2.739240  2.739240  0.139864    Z  1.614802  2.963620     0  1.560137   \n",
       "\n",
       "       v131        v14       v15       v16       v17       v18       v19  \\\n",
       "0  2.857144  11.636387  1.355013  8.571428  3.670350  0.106720  0.138790   \n",
       "1  1.589403  11.636386  1.992031  4.932127  3.554267  0.773906  0.181200   \n",
       "2  1.176472   9.603541  1.984127  5.882352  3.170847  0.244541  0.134757   \n",
       "3  1.034483  14.094723  1.945044  5.517242  3.610789  1.224114  0.208339   \n",
       "4  1.589403  10.991097  1.992031  4.932127  3.554267  0.773906  0.181200   \n",
       "\n",
       "         v2        v20       v21   v22           v23 v24       v26       v27  \\\n",
       "0  8.727474  18.869284  7.730923   XDX -1.716131e-08   C  1.720818  3.393503   \n",
       "1  7.023803  18.036585  6.763110   GUV  1.845672e-07   C  1.826276  2.673322   \n",
       "2  5.310079  17.952332  5.245035    FQ -2.785053e-07   E  2.244897  5.306122   \n",
       "3  8.304757  18.376408  7.517125  ACUE -4.805344e-07   D  1.308269  2.303640   \n",
       "4  7.023803  18.036585  6.414567   HIT  1.845672e-07   E  1.826276  2.673322   \n",
       "\n",
       "        v28       v29 v3  v30 v31       v35        v36       v37       v39  \\\n",
       "0  0.590122  8.880867  C    C   A  8.375452  11.326591  0.454546  4.012088   \n",
       "1  5.043831  8.296139  C    C   A  8.068506  14.579479  0.642856  0.378418   \n",
       "2  0.836005  7.499999  C  NaN   A  7.959184  12.730516  0.259740  7.378964   \n",
       "3  8.926662  8.874520  C    C   B  8.898468  11.302795  0.433735  0.287322   \n",
       "4  5.043831  8.296139  C  NaN   A  8.068506  13.765616  0.642856  0.378418   \n",
       "\n",
       "         v4        v40        v42        v44       v45 v47    v48 v85  \\\n",
       "0  3.921026   7.711453  12.707581  10.498338  9.848672   C  20.781006   \n",
       "1  4.205991  14.305766  12.934363  10.782008  9.156046   E  32.207340   \n",
       "2  4.410969  13.077201  12.346939   8.897560  5.343819   C  30.887331   \n",
       "3  4.225930  11.523045  12.935823  12.708574  9.670823   C  19.353779   \n",
       "4  4.205991  10.138920  12.934363  10.782008  9.156046   I  32.207340   \n",
       "\n",
       "       v48^2      v48_x      v48_y         v5       v50       v51 v52  v56  \\\n",
       "0  148.15110  12.171734  12.171734   7.915266  0.899420  7.277793   G   DI   \n",
       "1  154.04800  12.411608  12.411608   9.191265  1.379210  7.134018   G   DY   \n",
       "2  161.57785  12.711328  12.711328   5.326160  0.604504  9.637628   F   AS   \n",
       "3  148.71448  12.194855  12.194855  11.627439  3.329176  4.780357   H   BW   \n",
       "4  154.04800  12.411608  12.411608   8.670867  1.364536  7.134018   H  NaN   \n",
       "\n",
       "        v57       v58        v59        v6        v61      v62 v119  v62 v123  \\\n",
       "0  3.971118  0.529802  10.890984  2.599278  15.858151 -6.297423e-07  1.989780   \n",
       "1  4.067039  5.330551  10.535108  2.412790  15.075894  2.923122e+00  5.478479   \n",
       "2  4.030613  4.277456   9.105481  3.979592  16.075602 -2.792745e-07  2.477596   \n",
       "3  3.965517  1.732102  11.777912  2.097700  15.927390  5.655087e-01  1.812795   \n",
       "4  4.067039  5.330551  10.535108  2.412790  15.075894  1.461561e+00  2.739240   \n",
       "\n",
       "     v62 v48   v62 v85  v62^2  v62_x  v62_y v66        v68        v69  \\\n",
       "0  12.171734  1.707317    1.0      1    1.0   C  15.231789  17.142857   \n",
       "1  24.823215  5.189874    4.0      2    2.0   A  18.274548   9.516129   \n",
       "2  12.711328  2.429906    1.0      1    1.0   A  11.040463   5.882353   \n",
       "3  12.194855  1.587045    1.0      1    1.0   A  18.568129   9.425287   \n",
       "4  12.411608  2.594937    1.0      1    1.0   C  18.274548   9.516129   \n",
       "\n",
       "         v7        v70 v71  v72 v74 v75        v78 v79       v80        v81  \\\n",
       "0  3.176895  11.784549   F    1   B   D   8.571429   E  3.000000   7.528326   \n",
       "1  2.452166  12.053353   F    2   B   D  13.333334   D  2.090909   7.277655   \n",
       "2  3.928571   8.460654   B    3   B   B  11.764705   E  3.333334  10.194432   \n",
       "3  1.987549  13.594727   F    2   B   D  13.448277   B  1.947261   4.797873   \n",
       "4  2.452166  12.494872   F    1   B   D  13.333334   C  2.090909   7.517742   \n",
       "\n",
       "         v82       v84     v85^2     v85_x     v85_y       v86       v88  \\\n",
       "0   8.861647  1.299638  2.914931  1.707317  1.707317  0.866426  3.321300   \n",
       "1   3.430692  1.423294  6.733697  2.594937  2.594937  1.158301  1.761547   \n",
       "2   8.266199  1.530613  5.904443  2.429906  2.429906  1.071429  3.367346   \n",
       "3  13.315820  1.379310  2.518711  1.587045  1.587045  1.242817  1.408046   \n",
       "4   3.688459  1.423294  6.733697  2.594937  2.594937  1.158301  1.761547   \n",
       "\n",
       "          v9       v90 v91       v92       v93       v94        v98       v99  \n",
       "0   9.999999  0.905342   A  0.442252  5.814018  3.517721   8.877414  1.191337  \n",
       "1   9.059583  0.969183   B  0.542669  5.301047  3.743106   8.303966  1.235546  \n",
       "2  12.666667  0.811447   G  0.271480  5.156560  4.214944  11.588858  0.841837  \n",
       "3   8.965516  1.042425   B  0.763925  5.498902  3.423944   6.942002  1.334611  \n",
       "4   9.059583  0.969183   G  0.542669  5.301047  3.743106   7.644154  1.235546  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    col_type = df[c].dtype\n",
    "    if col_type == 'object' or col_type.name == 'category':\n",
    "        df[c] =df[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "for c in df.columns:\n",
    "    col_type = df[c].dtype\n",
    "    if col_type == 'float64' and c != 'target' and c != 'ID':\n",
    "        df[c] = scaler.fit_transform(df[c].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = df[df['target'].notnull()]\n",
    "teste = df[df['target'].isnull()]\n",
    "    \n",
    "# Separando features preditoras e target\n",
    "train_x = treino.drop(['ID','target'], axis=1)\n",
    "train_y = treino['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass DataFrame with boolean values only",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-0acb949ca8e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#cat_model = Catb_Model(reduce_train, ajusted_test, features, categoricals=categoricals)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLgb_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteste\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategoricals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#xgb_model = Xgb_Model(treino, teste, train_x, categoricals=categorical_feats)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-12f21f3d704a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, train_df, test_df, features, categoricals, n_splits, verbose)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-12f21f3d704a>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2980\u001b[0m         \u001b[0;31m# Do we have a (boolean) DataFrame?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2982\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2984\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_frame\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3079\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_bool_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3081\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must pass DataFrame with boolean values only\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3082\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Must pass DataFrame with boolean values only"
     ]
    }
   ],
   "source": [
    "#cat_model = Catb_Model(reduce_train, ajusted_test, features, categoricals=categoricals)\n",
    "lgb_model = Lgb_Model(treino, teste, train_x, categoricals=categorical_feats)\n",
    "#xgb_model = Xgb_Model(treino, teste, train_x, categoricals=categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn_model = Cnn_Model(reduce_train, ajusted_test, features, categoricals=categoricals)\n",
    "nn_model = Nn_Model(train, test, features, categoricals=categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {'lbg': 0.60, 'cat': 0, 'xgb': 0.20, 'nn': 0.20}\n",
    "\n",
    "final_pred = (lgb_model.y_pred * weights['lbg']) + (xgb_model.y_pred * weights['xgb']) + (nn_model.y_pred * weights['nn'])\n",
    "#final_pred = cnn_model.y_pred\n",
    "print(final_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame([(round(a, 2), round(b, 2), round(c, 2), round(d, 2)) for a, b, c, d in zip(lgb_model.y_pred, cat_model.y_pred, xgb_model.y_pred, nn_model.y_pred)], columns=['lgb', 'cat', 'xgb', 'nn']).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = Counter(train['target'])\n",
    "for k in dist:\n",
    "    dist[k] /= len(train)\n",
    "train['target'].hist()\n",
    "\n",
    "acum = 0\n",
    "bound = {}\n",
    "for i in range(3):\n",
    "    acum += dist[i]\n",
    "    bound[i] = np.percentile(final_pred, acum * 100)\n",
    "print(bound)\n",
    "\n",
    "def classify(x):\n",
    "    if x <= bound[0]:\n",
    "        return 0\n",
    "    elif x <= bound[1]:\n",
    "        return 1\n",
    "    elif x <= bound[2]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "final_pred = np.array(list(map(classify, final_pred)))\n",
    "\n",
    "sample_submission['accuracy_group'] = final_pred.astype(int)\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission['accuracy_group'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0ba79c486d29466ea13aac5f7d1a139f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "220e8cb3625e407a818fb265a4e30f26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_526670cbb5d54cdc94baac3c9e50c133",
       "placeholder": "​",
       "style": "IPY_MODEL_6d4d45d888904192bd23c6bd2e18abfc",
       "value": " 1000/1000 [00:56&lt;00:00, 17.64it/s]"
      }
     },
     "40cab4888657466c93df33f4af9d3595": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_679c7332db3a44e3a74ef89a221c1b22",
        "IPY_MODEL_932851b9386d44aba6773c19ef9ee44b"
       ],
       "layout": "IPY_MODEL_c916fcf299f8433bb64a151f4d47eb16"
      }
     },
     "526670cbb5d54cdc94baac3c9e50c133": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5714eb38aebc48c48208508b72caa5ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "588edf668fc24f8da75dad4993a5dce0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "5efe7e6b01044be1a097c7b823a06310": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "679c7332db3a44e3a74ef89a221c1b22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5efe7e6b01044be1a097c7b823a06310",
       "max": 17000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_588edf668fc24f8da75dad4993a5dce0",
       "value": 17000
      }
     },
     "6d4d45d888904192bd23c6bd2e18abfc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "78f696eb3e204bb0a4dc09c2ac15277b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9178d74d1b474c8286efc8d2d274f343": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "932851b9386d44aba6773c19ef9ee44b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5714eb38aebc48c48208508b72caa5ae",
       "placeholder": "​",
       "style": "IPY_MODEL_0ba79c486d29466ea13aac5f7d1a139f",
       "value": " 17000/17000 [08:09&lt;00:00, 34.73it/s]"
      }
     },
     "a4a0ffd92a7449a39a188d9916de6b4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ba466e1280a74c71be69da8ef700c938",
        "IPY_MODEL_220e8cb3625e407a818fb265a4e30f26"
       ],
       "layout": "IPY_MODEL_78f696eb3e204bb0a4dc09c2ac15277b"
      }
     },
     "ba466e1280a74c71be69da8ef700c938": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c21cff89656b4c17a0be09f11ee63181",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9178d74d1b474c8286efc8d2d274f343",
       "value": 1000
      }
     },
     "c21cff89656b4c17a0be09f11ee63181": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c916fcf299f8433bb64a151f4d47eb16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
